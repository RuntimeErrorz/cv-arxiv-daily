{"MVS": {"2406.13515": "|**2024-06-19**|**MVSBoost: An Efficient Point Cloud-based 3D Reconstruction**|Umair Haroon et.al.|[2406.13515v1](http://arxiv.org/abs/2406.13515v1)|The work is under review|None|None|\n", "2406.00440": "|**2024-06-01**|**Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head Capture**|X. Li et.al.|[2406.00440v1](http://arxiv.org/abs/2406.00440v1)|None|None|None|\n", "2405.17140": "|**2024-05-27**|**SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing**|Yong-Qiang Mao et.al.|[2405.17140v1](http://arxiv.org/abs/2405.17140v1)|None|None|None|\n", "2405.15299": "|**2024-05-24**|**Transparent Object Depth Completion**|Yifan Zhou et.al.|[2405.15299v1](http://arxiv.org/abs/2405.15299v1)|None|None|None|\n", "2405.12759": "|**2024-05-21**|**Cross-spectral Gated-RGB Stereo Depth Estimation**|Samuel Brucker et.al.|[2405.12759v1](http://arxiv.org/abs/2405.12759v1)|None|None|None|\n", "2405.12218": "|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|Project page: https://mvsgaussian.github.io/|None|None|\n", "2405.09131": "|**2024-05-15**|**RobustMVS: Single Domain Generalized Deep Multi-view Stereo**|Hongbin Xu et.al.|[2405.09131v1](http://arxiv.org/abs/2405.09131v1)|Accepted to TCSVT. Code will be released at:   https://github.com/ToughStoneX/Robust-MVS. Benchmark will be released at:   https://github.com/ToughStoneX/MVS_Evaluation_Benchmark|None|**[link](https://github.com/toughstonex/mvs_evaluation_benchmark)**|\n", "2405.08816": "|**2024-05-14**|**The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition**|Lingdong Kong et.al.|[2405.08816v2](http://arxiv.org/abs/2405.08816v2)|ICRA 2024; 32 pages, 24 figures, 5 tables; Code at   https://robodrive-24.github.io/|None|None|\n", "2405.07847": "|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|None|None|None|\n", "2405.06241": "|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|This work has been submitted to the IEEE for possible publication.   Copyright may be transferred without notice, after which this version may no   longer be accessible|None|None|\n", "2405.05355": "|**2024-05-08**|**Geometry-Informed Distance Candidate Selection for Adaptive Lightweight Omnidirectional Stereo Vision with Fisheye Images**|Conner Pulling et.al.|[2405.05355v1](http://arxiv.org/abs/2405.05355v1)|None|None|None|\n", "2404.16429": "|**2024-04-25**|**Depth Supervised Neural Surface Reconstruction from Airborne Imagery**|Vincent Hackstein et.al.|[2404.16429v1](http://arxiv.org/abs/2404.16429v1)|None|None|None|\n", "2404.13541": "|**2024-04-21**|**Generalizable Novel-View Synthesis using a Stereo Camera**|Haechan Lee et.al.|[2404.13541v1](http://arxiv.org/abs/2404.13541v1)|Accepted to CVPR 2024. Project page URL:   https://jinwonjoon.github.io/stereonerf/|None|None|\n", "2404.07992": "|**2024-04-11**|**GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo**|Jiang Wu et.al.|[2404.07992v1](http://arxiv.org/abs/2404.07992v1)|CVPR 2024. Project page: https://wuuu3511.github.io/gomvs/ Code:   https://github.com/Wuuu3511/GoMVS|None|**[link](https://github.com/wuuu3511/gomvs)**|\n", "2404.06842": "|**2024-04-10**|**MoCha-Stereo: Motif Channel Attention Network for Stereo Matching**|Ziyang Chen et.al.|[2404.06842v2](http://arxiv.org/abs/2404.06842v2)|Accepted to CVPR 2024|The IEEE/CVF Conference on Computer Vision and Pattern Recognition   2024|**[link](https://github.com/zyangchen/mocha-stereo)**|\n", "2404.05606": "|**2024-04-08**|**Learning Topology Uniformed Face Mesh by Volume Rendering for Multi-view Reconstruction**|Yating Wang et.al.|[2404.05606v1](http://arxiv.org/abs/2404.05606v1)|None|None|None|\n", "2404.05181": "|**2024-04-08**|**Adaptive Learning for Multi-view Stereo Reconstruction**|Qinglu Min et.al.|[2404.05181v1](http://arxiv.org/abs/2404.05181v1)|None|None|None|\n", "2404.03656": "|**2024-04-04**|**MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation**|Hanzhe Hu et.al.|[2404.03656v1](http://arxiv.org/abs/2404.03656v1)|Project page: https://mvd-fusion.github.io/|None|None|\n", "2404.02225": "|**2024-04-02**|**CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement**|Di Qiu et.al.|[2404.02225v1](http://arxiv.org/abs/2404.02225v1)|None|None|None|\n", "2403.11899": "|**2024-03-18**|**GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors**|LI Yang et.al.|[2403.11899v1](http://arxiv.org/abs/2403.11899v1)|Accepted to ICLR 2024 Poster. For the Appendix, please see   http://yukiumi13.github.io/gnerp_page|None|None|\n", "2403.09194": "|**2024-03-14**|**Intention-driven Ego-to-Exo Video Generation**|Hongchen Luo et.al.|[2403.09194v2](http://arxiv.org/abs/2403.09194v2)|None|None|None|\n", "2403.07535": "|**2024-03-12**|**Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving**|JunDa Cheng et.al.|[2403.07535v1](http://arxiv.org/abs/2403.07535v1)|Accepted to CVPR 2024|None|**[link](https://github.com/junda24/afnet)**|\n", "2402.14650": "|**2024-02-22**|**GaussianPro: 3D Gaussian Splatting with Progressive Propagation**|Kai Cheng et.al.|[2402.14650v1](http://arxiv.org/abs/2402.14650v1)|See the project page for code, data:   https://kcheng1021.github.io/gaussianpro.github.io|None|None|\n", "2402.11791": "|**2024-02-19**|**SDGE: Stereo Guided Depth Estimation for 360$^\\circ$ Camera Sets**|Jialei Xu et.al.|[2402.11791v4](http://arxiv.org/abs/2402.11791v4)|None|None|None|\n", "2401.15616": "|**2024-01-28**|**Multi-Person 3D Pose Estimation from Multi-View Uncalibrated Depth Cameras**|Yu-Jhe Li et.al.|[2401.15616v1](http://arxiv.org/abs/2401.15616v1)|17 pages including appendix|None|None|\n", "2401.14401": "|**2024-01-25**|**Range-Agnostic Multi-View Depth Estimation With Keyframe Selection**|Andrea Conti et.al.|[2401.14401v1](http://arxiv.org/abs/2401.14401v1)|3DV 2024 Project Page   https://andreaconti.github.io/projects/range_agnostic_multi_view_depth GitHub   Page https://github.com/andreaconti/ramdepth.git|None|**[link](https://github.com/andreaconti/ramdepth)**|\n", "2401.12751": "|**2024-01-23**|**PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view Reconstruction**|Wanjuan Su et.al.|[2401.12751v1](http://arxiv.org/abs/2401.12751v1)|None|None|None|\n", "2401.11751": "|**2024-01-22**|**Boosting Multi-view Stereo with Late Cost Aggregation**|Jiang Wu et.al.|[2401.11751v2](http://arxiv.org/abs/2401.11751v2)|Code and models are available at https://github.com/Wuuu3511/LAMVSNET|None|**[link](https://github.com/wuuu3511/lamvsnet)**|\n", "2401.11673": "|**2024-01-22**|**MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo**|Chenjie Cao et.al.|[2401.11673v1](http://arxiv.org/abs/2401.11673v1)|Accepted to ICLR2024|ICLR(International Conference on Learning Representations) 2024|**[link](https://github.com/maybelx/mvsformerplusplus)**|\n", "2401.09252": "|**2024-01-17**|**3D Scene Geometry Estimation from 360$^\\circ$ Imagery: A Survey**|Thiago Lopes Trugillo da Silveira et.al.|[2401.09252v1](http://arxiv.org/abs/2401.09252v1)|Published in ACM Computing Surveys|ACM Comput. Surv. 55, 4, Article 68, 2023|None|\n", "2401.06385": "|**2024-01-12**|**SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical Refinement and EM optimization**|Zhenlong Yuan et.al.|[2401.06385v1](http://arxiv.org/abs/2401.06385v1)|10 pages, 9 figures, published to AAAI2024|None|None|\n", "2312.15970": "|**2023-12-26**|**Learning Deformable Hypothesis Sampling for Accurate PatchMatch Multi-View Stereo**|Hongjie Li et.al.|[2312.15970v1](http://arxiv.org/abs/2312.15970v1)|None|None|**[link](https://github.com/geo-tell/ds-pmnet)**|\n", "2312.15238": "|**2023-12-23**|**NoPose-NeuS: Jointly Optimizing Camera Poses with Neural Implicit Surfaces for Multi-view Reconstruction**|Mohamed Shawky Sabae et.al.|[2312.15238v1](http://arxiv.org/abs/2312.15238v1)|None|UniReps: the First Workshop on Unifying Representations in Neural   Models (2023)|None|\n", "2312.14132": "|**2023-12-21**|**DUSt3R: Geometric 3D Vision Made Easy**|Shuzhe Wang et.al.|[2312.14132v1](http://arxiv.org/abs/2312.14132v1)|None|None|**[link](https://github.com/naver/dust3r)**|\n", "2312.08594": "|**2023-12-14**|**CT-MVSNet: Efficient Multi-View Stereo with Cross-scale Transformer**|Sicheng Wang et.al.|[2312.08594v2](http://arxiv.org/abs/2312.08594v2)|Accepted at the 30th International Conference on Multimedia   Modeling(MMM'24 Oral)|None|**[link](https://github.com/wscstrive/ct-mvsnet)**|\n", "2312.04875": "|**2023-12-08**|**MVDD: Multi-View Depth Diffusion Models**|Zhen Wang et.al.|[2312.04875v3](http://arxiv.org/abs/2312.04875v3)|None|None|None|\n", "2311.10887": "|**2023-11-17**|**Point Cloud Self-supervised Learning via 3D to Multi-view Masked Autoencoder**|Zhimin Chen et.al.|[2311.10887v1](http://arxiv.org/abs/2311.10887v1)|None|None|**[link](https://github.com/zhimin-c/multiview-mae)**|\n", "2311.07600": "|**2023-11-11**|**Polarimetric PatchMatch Multi-View Stereo**|Jinyu Zhao et.al.|[2311.07600v1](http://arxiv.org/abs/2311.07600v1)|None|None|None|\n", "2311.04154": "|**2023-11-07**|**High-fidelity 3D Reconstruction of Plants using Neural Radiance Field**|Kewei Hu et.al.|[2311.04154v1](http://arxiv.org/abs/2311.04154v1)|None|None|None|\n", "2311.01065": "|**2023-11-02**|**Novel View Synthesis from a Single RGBD Image for Indoor Scenes**|Congrui Hetang et.al.|[2311.01065v1](http://arxiv.org/abs/2311.01065v1)|2nd International Conference on Image Processing, Computer Vision and   Machine Learning, November 2023|None|None|\n", "2311.00134": "|**2023-10-31**|**Joint Depth Prediction and Semantic Segmentation with Multi-View SAM**|Mykhailo Shvets et.al.|[2311.00134v1](http://arxiv.org/abs/2311.00134v1)|To appear in the 2024 IEEE/CVF Winter Conference on Applications of   Computer Vision|None|None|\n", "2310.19583": "|**2023-10-30**|**GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo**|Vibhas K. Vats et.al.|[2310.19583v3](http://arxiv.org/abs/2310.19583v3)|Accepted in WACV 2024 Link:   https://openaccess.thecvf.com/content/WACV2024/html/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.html|Proceedings of the IEEE/CVF Winter Conference on Applications of   Computer Vision (WACV) 2024|**[link](https://github.com/vkvats/GC-MVSNet)**|\n", "2310.02262": "|**2023-10-03**|**RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving**|Tong Zhao et.al.|[2310.02262v1](http://arxiv.org/abs/2310.02262v1)|None|None|None|\n", "2309.17218": "|**2023-09-29**|**When Epipolar Constraint Meets Non-local Operators in Multi-View Stereo**|Tianqi Liu et.al.|[2309.17218v1](http://arxiv.org/abs/2309.17218v1)|ICCV2023|None|**[link](https://github.com/tqtqliu/et-mvsnet)**|\n", "2309.15164": "|**2023-09-26**|**3D Reconstruction with Generalizable Neural Fields using Scene Priors**|Yang Fu et.al.|[2309.15164v2](http://arxiv.org/abs/2309.15164v2)|Project Page: https://oasisyang.github.io/neural-prior|None|None|\n", "2309.13294": "|**2023-09-23**|**MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View Stereo**|Rongxuan Tan et.al.|[2309.13294v1](http://arxiv.org/abs/2309.13294v1)|None|None|**[link](https://github.com/rongxuantan/mp-mvs)**|\n", "2309.09379": "|**2023-09-17**|**A Critical Analysis of Internal Reliability for Uncertainty Quantification of Dense Image Matching in Multi-view Stereo**|Debao Huang et.al.|[2309.09379v2](http://arxiv.org/abs/2309.09379v2)|Figure 8|ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial   Information Sciences, 2023|None|\n", "2309.00385": "|**2023-09-01**|**Dense Voxel 3D Reconstruction Using a Monocular Event Camera**|Haodong Chen et.al.|[2309.00385v1](http://arxiv.org/abs/2309.00385v1)|None|None|None|\n", "2309.00277": "|**2023-09-01**|**SparseSat-NeRF: Dense Depth Supervised Neural Radiance Fields for Sparse Satellite Images**|Lulin Zhang et.al.|[2309.00277v1](http://arxiv.org/abs/2309.00277v1)|ISPRS Annals 2023|None|**[link](https://github.com/lulinzhang/sps-nerf)**|\n", "2308.13903": "|**2023-08-26**|**Disjoint Pose and Shape for 3D Face Reconstruction**|Raja Kumar et.al.|[2308.13903v1](http://arxiv.org/abs/2308.13903v1)|ICCV workshops 2023|None|None|\n", "2308.09990": "|**2023-08-19**|**Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|Zhenlong Yuan et.al.|[2308.09990v2](http://arxiv.org/abs/2308.09990v2)|None|None|None|\n", "2308.09022": "|**2023-08-17**|**ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval**|Song Zhang et.al.|[2308.09022v1](http://arxiv.org/abs/2308.09022v1)|None|None|**[link](https://github.com/zs670980918/arai-mvsnet)**|\n", "2308.08715": "|**2023-08-17**|**V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints**|Nathaniel Burgdorfer et.al.|[2308.08715v1](http://arxiv.org/abs/2308.08715v1)|ICCV 2023|None|**[link](https://github.com/nburgdorfer/v-fuse)**|\n", "2308.07868": "|**2023-08-15**|**ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces**|Qianyi Wu et.al.|[2308.07868v2](http://arxiv.org/abs/2308.07868v2)|ICCV 2023. Project Page: https://qianyiwu.github.io/objectsdf++ Code:   https://github.com/QianyiWu/objectsdf_plus|None|**[link](https://github.com/qianyiwu/objectsdf_plus)**|\n", "2308.06974": "|**2023-08-14**|**A One Stop 3D Target Reconstruction and multilevel Segmentation Method**|Jiexiong Xu et.al.|[2308.06974v1](http://arxiv.org/abs/2308.06974v1)|None|None|**[link](https://github.com/ganlab/ostra)**|\n", "2308.04826": "|**2023-08-09**|**WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields**|Muyu Xu et.al.|[2308.04826v2](http://arxiv.org/abs/2308.04826v2)|Accepted to ICCV 2023. Project website:   https://mxuai.github.io/WaveNeRF/|None|None|\n", "2308.03492": "|**2023-08-07**|**Learning Photometric Feature Transform for Free-form Object Scan**|Xiang Feng et.al.|[2308.03492v1](http://arxiv.org/abs/2308.03492v1)|None|None|None|\n", "2308.02191": "|**2023-08-04**|**ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo**|Qiang Zhou et.al.|[2308.02191v1](http://arxiv.org/abs/2308.02191v1)|arXiv admin note: text overlap with arXiv:2203.03949 by other authors|None|None|\n", "2308.01246": "|**2023-08-02**|**Tirtha -- An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites**|Jyotirmaya Shivottam et.al.|[2308.01246v2](http://arxiv.org/abs/2308.01246v2)|Accepted at The 28th International ACM Conference on 3D Web   Technology (Web3D 2023)|None|**[link](https://github.com/smlab-niser/tirtha-public)**|\n", "2307.09160": "|**2023-07-18**|**Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells**|Xinyi Ye et.al.|[2307.09160v1](http://arxiv.org/abs/2307.09160v1)|Accepted by ICCV 2023|None|**[link](https://github.com/dive128/dmvsnet)**|\n", "2307.10233": "|**2023-07-16**|**RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo**|Yifei Shi et.al.|[2307.10233v1](http://arxiv.org/abs/2307.10233v1)|IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv   admin note: substantial text overlap with arXiv:2204.01320|None|None|\n", "2307.01097": "|**2023-07-03**|**MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion**|Shitao Tang et.al.|[2307.01097v7](http://arxiv.org/abs/2307.01097v7)|Project page, https://mvdiffusion.github.io; NeurIPS 2023   (spotlight); Compressed camera-ready version|None|**[link](https://github.com/Tangshitao/MVDiffusion)**|\n", "2306.12681": "|**2023-06-22**|**One at a Time: Progressive Multi-step Volumetric Probability Learning for Reliable 3D Scene Perception**|Bohan Li et.al.|[2306.12681v4](http://arxiv.org/abs/2306.12681v4)|AAAI2024|None|None|\n", "2306.10003": "|**2023-06-16**|**C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction**|Luoyuan Xu et.al.|[2306.10003v2](http://arxiv.org/abs/2306.10003v2)|Accepted by ICCV2023|None|None|\n", "2306.08648": "|**2023-06-14**|**SimpleMapping: Real-Time Visual-Inertial Dense Mapping with Deep Multi-View Stereo**|Yingye Xin et.al.|[2306.08648v3](http://arxiv.org/abs/2306.08648v3)|None|None|None|\n", "2306.07437": "|**2023-06-12**|**Instant Multi-View Head Capture through Learnable Registration**|Timo Bolkart et.al.|[2306.07437v1](http://arxiv.org/abs/2306.07437v1)|Conference on Computer Vision and Pattern Recognition (CVPR) 2023|None|**[link](https://github.com/TimoBolkart/TEMPEH)**|\n", "2306.00519": "|**2023-06-01**|**DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation**|Xiaoliang Ju et.al.|[2306.00519v4](http://arxiv.org/abs/2306.00519v4)|Updated: new work|None|**[link](https://github.com/akirahero/diffindscene)**|\n", "2305.19780": "|**2023-05-31**|**A technique to jointly estimate depth and depth uncertainty for unmanned aerial vehicles**|Micha\u00ebl Fonder et.al.|[2305.19780v1](http://arxiv.org/abs/2305.19780v1)|The code is available at https://github.com/michael-fonder/M4DepthU|None|**[link](https://github.com/michael-fonder/m4depthu)**|\n", "2305.17710": "|**2023-05-28**|**OccCasNet: Occlusion-aware Cascade Cost Volume for Light Field Depth Estimation**|Wentao Chao et.al.|[2305.17710v1](http://arxiv.org/abs/2305.17710v1)|None|None|**[link](https://github.com/chaowentao/occcasnet)**|\n", "2305.14918": "|**2023-05-24**|**Incremental Dense Reconstruction from Monocular Video with Guided Sparse Feature Volume Fusion**|Xingxing Zuo et.al.|[2305.14918v1](http://arxiv.org/abs/2305.14918v1)|8 pages, 5 figures, RA-L 2023|None|None|\n", "2305.11167": "|**2023-05-18**|**MVPSNet: Fast Generalizable Multi-view Photometric Stereo**|Dongxu Zhao et.al.|[2305.11167v1](http://arxiv.org/abs/2305.11167v1)|None|None|None|\n", "2305.10320": "|**2023-05-17**|**CostFormer:Cost Transformer for Cost Aggregation in Multi-view Stereo**|Weitao Chen et.al.|[2305.10320v1](http://arxiv.org/abs/2305.10320v1)|Accepted by IJCAI-23|None|None|\n", "2305.06036": "|**2023-05-10**|**FusionDepth: Complement Self-Supervised Monocular Depth Estimation with Cost Volume**|Zhuofei Huang et.al.|[2305.06036v1](http://arxiv.org/abs/2305.06036v1)|None|None|None|\n", "2304.14633": "|**2023-04-28**|**CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction**|Ziyue Feng et.al.|[2304.14633v3](http://arxiv.org/abs/2304.14633v3)|Accepted by ICCV 2023|None|None|\n", "2304.13614": "|**2023-04-26**|**Multi-View Stereo Representation Revisit: Region-Aware MVSNet**|Yisu Zhang et.al.|[2304.13614v2](http://arxiv.org/abs/2304.13614v2)|CVPR 2023|None|None|\n", "2304.10664": "|**2023-04-20**|**A Comparative Neural Radiance Field (NeRF) 3D Analysis of Camera Poses from HoloLens Trajectories and Structure from Motion**|Miriam J\u00e4ger et.al.|[2304.10664v1](http://arxiv.org/abs/2304.10664v1)|7 pages, 5 figures. Will be published in the ISPRS The International   Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences|None|None|\n", "2304.04185": "|**2023-04-09**|**BEVStereo++: Accurate Depth Estimation in Multi-view 3D Object Detection via Dynamic Temporal Stereo**|Yinhao Li et.al.|[2304.04185v1](http://arxiv.org/abs/2304.04185v1)|None|None|None|\n", "2304.04038": "|**2023-04-08**|**POEM: Reconstructing Hand in a Point Embedded Multi-view Stereo**|Lixin Yang et.al.|[2304.04038v2](http://arxiv.org/abs/2304.04038v2)|Accepted by CVPR 2023. (v2 fix typos)|None|**[link](https://github.com/lixiny/poem)**|\n", "2304.01488": "|**2023-04-04**|**End-to-End Latency Optimization of Multi-view 3D Reconstruction for Disaster Response**|Xiaojie Zhang et.al.|[2304.01488v1](http://arxiv.org/abs/2304.01488v1)|2022 10th IEEE International Conference on Mobile Cloud Computing,   Services, and Engineering (MobileCloud)|None|None|\n", "2304.01480": "|**2023-04-04**|**FineRecon: Depth-aware Feed-forward Network for Detailed 3D Reconstruction**|Noah Stier et.al.|[2304.01480v2](http://arxiv.org/abs/2304.01480v2)|ICCV 2023|None|**[link](https://github.com/apple/ml-finerecon)**|\n", "2303.17712": "|**2023-03-30**|**S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit Surfaces**|Haoyu Wu et.al.|[2303.17712v2](http://arxiv.org/abs/2303.17712v2)|ICCV 2023, Project page: https://hao-yu-wu.github.io/s-volsdf/|None|None|\n", "2303.16628": "|**2023-03-29**|**DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object Detection and Tracking**|Qing Lian et.al.|[2303.16628v2](http://arxiv.org/abs/2303.16628v2)|None|None|**[link](https://github.com/smartbot-pjlab/dort)**|\n", "2303.16447": "|**2023-03-29**|**Multi-View Azimuth Stereo via Tangent Space Consistency**|Xu Cao et.al.|[2303.16447v1](http://arxiv.org/abs/2303.16447v1)|CVPR 2023 camera-ready. Appendices after references. 16 pages, 20   figures. Project page: https://xucao-42.github.io/mvas_homepage/|None|**[link](https://github.com/xucao-42/mvas)**|\n", "2303.15840": "|**2023-03-28**|**Sparse Depth-Guided Attention for Accurate Depth Completion: A Stereo-Assisted Monitored Distillation Approach**|Jia-Wei Guo et.al.|[2303.15840v3](http://arxiv.org/abs/2303.15840v3)|7 pages, 8 figures, references added|None|None|\n", "2303.15060": "|**2023-03-27**|**TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering**|Jaehoon Choi et.al.|[2303.15060v1](http://arxiv.org/abs/2303.15060v1)|Accepted to CVPR23. Project Page: https://jh-choi.github.io/TMO/|None|None|\n", "2303.09758": "|**2023-03-17**|**Hierarchical Prior Mining for Non-local Multi-View Stereo**|Chunlin Ren et.al.|[2303.09758v1](http://arxiv.org/abs/2303.09758v1)|None|None|None|\n", "2303.08695": "|**2023-03-15**|**RefiNeRF: Modelling dynamic neural radiance fields with inconsistent or missing camera parameters**|Shuja Khalid et.al.|[2303.08695v1](http://arxiv.org/abs/2303.08695v1)|None|None|None|\n", "2303.06615": "|**2023-03-12**|**Iterative Geometry Encoding Volume for Stereo Matching**|Gangwei Xu et.al.|[2303.06615v2](http://arxiv.org/abs/2303.06615v2)|Accepted to CVPR 2023|None|**[link](https://github.com/gangweix/igev)**|\n", "2303.06418": "|**2023-03-11**|**Rethinking the Multi-view Stereo from the Perspective of Rendering-based Augmentation**|Chenjie Cao et.al.|[2303.06418v1](http://arxiv.org/abs/2303.06418v1)|This is a technical report of team Ewrfcas (Fudan University) in the   GigaMVS reconstruction competition. Our method achieved the 1st performance   in the 2022 reconstruction benchmark|None|None|\n", "2303.06042": "|**2023-03-10**|**MVImgNet: A Large-scale Dataset of Multi-view Images**|Xianggang Yu et.al.|[2303.06042v1](http://arxiv.org/abs/2303.06042v1)|To be appear in CVPR2023. Project page:   https://gaplab.cuhk.edu.cn/projects/MVImgNet/|None|None|\n", "2302.14340": "|**2023-02-28**|**HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of Indoor Scenes with Iterative Intertwined Regularization**|Zhihao Liang et.al.|[2302.14340v2](http://arxiv.org/abs/2302.14340v2)|None|None|**[link](https://github.com/gorilla-lab-scut/helixsurf)**|\n", "2302.09922": "|**2023-02-20**|**Unsupervised OmniMVS: Efficient Omnidirectional Depth Inference via Establishing Pseudo-Stereo Supervision**|Zisong Chen et.al.|[2302.09922v2](http://arxiv.org/abs/2302.09922v2)|None|None|None|\n", "2302.07182": "|**2023-02-14**|**Visibility-Aware Pixelwise View Selection for Multi-View Stereo Matching**|Zhentao Huang et.al.|[2302.07182v1](http://arxiv.org/abs/2302.07182v1)|8 pages|None|None|\n", "2301.08930": "|**2023-01-21**|**Dense RGB SLAM with Neural Implicit Maps**|Heng Li et.al.|[2301.08930v2](http://arxiv.org/abs/2301.08930v2)|Accepted by ICLR 2023; Camera-Ready Version; The code is at   poptree.github.io/DIM-SLAM|None|None|\n", "2212.12721": "|**2022-12-24**|**Polarimetric Multi-View Inverse Rendering**|Jinyu Zhao et.al.|[2212.12721v1](http://arxiv.org/abs/2212.12721v1)|Paper accepted in IEEE Transactions on Pattern Analysis and Machine   Intelligence (2022). arXiv admin note: substantial text overlap with   arXiv:2007.08830|None|None|\n", "2212.06626": "|**2022-12-13**|**DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo**|Christian Sormann et.al.|[2212.06626v1](http://arxiv.org/abs/2212.06626v1)|accepted at WACV 2023|None|None|\n", "2211.16905": "|**2022-11-30**|**Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity**|Qingsong Yan et.al.|[2211.16905v2](http://arxiv.org/abs/2211.16905v2)|Accepted at the Thirty-Seventh AAAI Conference on Artificial   Intelligence (AAAI23)|None|**[link](https://github.com/Yannnnnnnnnnnn/DispMVS_release)**|\n", "2210.11467": "|**2022-10-20**|**Multi-View Guided Multi-View Stereo**|Matteo Poggi et.al.|[2210.11467v1](http://arxiv.org/abs/2210.11467v1)|IROS 2022. First two authors contributed equally. Project page:   https://github.com/andreaconti/multi-view-guided-multi-view-stereo|None|**[link](https://github.com/andreaconti/multi-view-guided-multi-view-stereo)**|\n", "2210.07670": "|**2022-10-14**|**Multi-View Photometric Stereo Revisited**|Berk Kaya et.al.|[2210.07670v1](http://arxiv.org/abs/2210.07670v1)|Accepted for publication at IEEE/CVF WACV 2023. Draft info: 10 pages,   5 figure, and 3 tables|None|None|\n", "2210.07582": "|**2022-10-14**|**Deep PatchMatch MVS with Learned Patch Coplanarity, Geometric Consistency and Adaptive Pixel Sampling**|Jae Yong Lee et.al.|[2210.07582v1](http://arxiv.org/abs/2210.07582v1)|None|None|None|\n", "2210.02009": "|**2022-10-05**|**Multi-Camera Collaborative Depth Prediction via Consistent Structure Estimation**|Jialei Xu et.al.|[2210.02009v1](http://arxiv.org/abs/2210.02009v1)|None|None|None|\n", "2210.01055": "|**2022-10-03**|**CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-training**|Tianyu Huang et.al.|[2210.01055v3](http://arxiv.org/abs/2210.01055v3)|Accepted by ICCV2023|None|**[link](https://github.com/tyhuang0428/CLIP2Point)**|\n", "2209.10248": "|**2022-09-21**|**BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo**|Yinhao Li et.al.|[2209.10248v1](http://arxiv.org/abs/2209.10248v1)|None|None|**[link](https://github.com/megvii-basedetection/bevstereo)**|\n", "2209.06681": "|**2022-09-13**|**A Benchmark and a Baseline for Robust Multi-view Depth Estimation**|Philipp Schr\u00f6ppel et.al.|[2209.06681v1](http://arxiv.org/abs/2209.06681v1)|Accepted at 3DV 2022|None|**[link](https://github.com/lmb-freiburg/robustmvd)**|\n", "2209.00082": "|**2022-08-31**|**Multi-View Reconstruction using Signed Ray Distance Functions (SRDF)**|Pierre Zins et.al.|[2209.00082v2](http://arxiv.org/abs/2209.00082v2)|None|None|None|\n", "2208.14743": "|**2022-08-31**|**SimpleRecon: 3D Reconstruction Without 3D Convolutions**|Mohamed Sayed et.al.|[2208.14743v1](http://arxiv.org/abs/2208.14743v1)|ECCV2022 version with improved timings. 14 pages + 5 pages of   references|None|None|\n", "2208.09170": "|**2022-08-19**|**Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning**|Xiaofeng Wang et.al.|[2208.09170v1](http://arxiv.org/abs/2208.09170v1)|code: https://github.com/JeffWang987/MOVEDepth|None|**[link](https://github.com/jeffwang987/movedepth)**|\n", "2208.02541": "|**2022-08-04**|**MVSFormer: Multi-View Stereo by Learning Robust Image Features and Temperature-based Depth**|Chenjie Cao et.al.|[2208.02541v3](http://arxiv.org/abs/2208.02541v3)|None|None|**[link](https://github.com/ewrfcas/mvsformer)**|\n", "2208.00233": "|**2022-07-30**|**Learning Pseudo Front Depth for 2D Forward-Looking Sonar-based Multi-view Stereo**|Yusheng Wang et.al.|[2208.00233v1](http://arxiv.org/abs/2208.00233v1)|Accepted at IROS 2022|None|**[link](https://github.com/sollynoay/epssn)**|\n", "2207.13464": "|**2022-07-27**|**Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction**|Tristan Laidlow et.al.|[2207.13464v1](http://arxiv.org/abs/2207.13464v1)|Accepted at ICRA 2020|None|None|\n", "2207.12032": "|**2022-07-25**|**Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-view Stereo**|Shiyu Gao et.al.|[2207.12032v1](http://arxiv.org/abs/2207.12032v1)|Accepted by CGI2022|None|**[link](https://github.com/SibylGao/MSCVP-MVSNet)**|\n", "2207.11876": "|**2022-07-25**|**nLMVS-Net: Deep Non-Lambertian Multi-View Stereo**|Kohei Yamashita et.al.|[2207.11876v2](http://arxiv.org/abs/2207.11876v2)|Accepted to WACV 2023|None|None|\n", "2207.11699": "|**2022-07-24**|**Semi-supervised Deep Multi-view Stereo**|Hongbin Xu et.al.|[2207.11699v4](http://arxiv.org/abs/2207.11699v4)|This paper is accepted in ACMMM-2023. The code is released at:   https://github.com/ToughStoneX/Semi-MVS|None|None|\n", "2207.10425": "|**2022-07-21**|**KD-MVS: Knowledge Distillation Based Self-supervised Learning for Multi-view Stereo**|Yikang Ding et.al.|[2207.10425v2](http://arxiv.org/abs/2207.10425v2)|None|None|**[link](https://github.com/megvii-research/kd-mvs)**|\n", "2207.08439": "|**2022-07-18**|**Revisiting PatchMatch Multi-View Stereo for Urban 3D Reconstruction**|Marco Orsingher et.al.|[2207.08439v1](http://arxiv.org/abs/2207.08439v1)|Poster presentation at IEEE Intelligent Vehicles Symposium (IV 2022,   https://iv2022.com/)|None|None|\n", "2207.08434": "|**2022-07-18**|**Efficient View Clustering and Selection for City-Scale 3D Reconstruction**|Marco Orsingher et.al.|[2207.08434v1](http://arxiv.org/abs/2207.08434v1)|Oral presentation at ICIAP 2021 (https://www.iciap2021.org/)|None|None|\n", "2206.11358": "|**2022-06-22**|**Monocular Spherical Depth Estimation with Explicitly Connected Weak Layout Cues**|Nikolaos Zioulis et.al.|[2206.11358v1](http://arxiv.org/abs/2206.11358v1)|Project page at https://vcl3d.github.io/ExplicitLayoutDepth/|ISPRS Journal of Photogrammetry and Remote Sensing, Volume 183,   January 2022, Pages 269-285|None|\n", "2206.10360": "|**2022-06-21**|**Enhancing Multi-view Stereo with Contrastive Matching and Weighted Focal Loss**|Yikang Ding et.al.|[2206.10360v1](http://arxiv.org/abs/2206.10360v1)|5 pages, 3 figures; Accepted to ICIP2022|None|None|\n", "2206.08365": "|**2022-06-16**|**Virtual Correspondence: Humans as a Cue for Extreme-View Geometry**|Wei-Chiu Ma et.al.|[2206.08365v1](http://arxiv.org/abs/2206.08365v1)|CVPR 2022. Project page:   https://people.csail.mit.edu/weichium/virtual-correspondence/|None|None|\n", "2206.00665": "|**2022-06-01**|**MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction**|Zehao Yu et.al.|[2206.00665v2](http://arxiv.org/abs/2206.00665v2)|Project page: https://niujinshuchong.github.io/monosdf/|None|None|\n", "2205.15848": "|**2022-05-31**|**Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction**|Qiancheng Fu et.al.|[2205.15848v1](http://arxiv.org/abs/2205.15848v1)|None|None|None|\n", "2205.14320": "|**2022-05-28**|**RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo**|Changjiang Cai et.al.|[2205.14320v3](http://arxiv.org/abs/2205.14320v3)|CVPR 2023|None|None|\n", "2205.14319": "|**2022-05-28**|**WT-MVSNet: Window-based Transformers for Multi-view Stereo**|Jinli Liao et.al.|[2205.14319v1](http://arxiv.org/abs/2205.14319v1)|None|None|None|\n", "2205.12468": "|**2022-05-25**|**Multiview Textured Mesh Recovery by Differentiable Rendering**|Lixiang Lin et.al.|[2205.12468v3](http://arxiv.org/abs/2205.12468v3)|None|None|**[link](https://github.com/l1346792580123/diff)**|\n", "2205.07014": "|**2022-05-14**|**SaiNet: Stereo aware inpainting behind objects with generative networks**|Violeta Men\u00e9ndez Gonz\u00e1lez et.al.|[2205.07014v1](http://arxiv.org/abs/2205.07014v1)|Presented at AI4CC workshop at CVPR|None|None|\n", "2205.03783": "|**2022-05-08**|**Non-parametric Depth Distribution Modelling based Depth Inference for Multi-view Stereo**|Jiayu Yang et.al.|[2205.03783v1](http://arxiv.org/abs/2205.03783v1)|CVPR 2022|None|**[link](https://github.com/nvlabs/np-cvp-mvsnet)**|\n", "2205.02836": "|**2022-05-05**|**Neural 3D Scene Reconstruction with the Manhattan-world Assumption**|Haoyu Guo et.al.|[2205.02836v2](http://arxiv.org/abs/2205.02836v2)|CVPR 2022 Oral. Project page: https://zju3dv.github.io/manhattan_sdf|None|**[link](https://github.com/zju3dv/manhattan_sdf)**|\n", "2205.02481": "|**2022-05-05**|**Exploiting Correspondences with All-pairs Correlations for Multi-view Depth Estimation**|Kai Cheng et.al.|[2205.02481v1](http://arxiv.org/abs/2205.02481v1)|10 pages, 9 figures|None|None|\n", "2204.10746": "|**2022-04-22**|**Leveraging Deepfakes to Close the Domain Gap between Real and Synthetic Images in Facial Capture Pipelines**|Winnie Lin et.al.|[2204.10746v2](http://arxiv.org/abs/2204.10746v2)|None|None|None|\n", "2204.07346": "|**2022-04-15**|**MVSTER: Epipolar Transformer for Efficient Multi-View Stereo**|Xiaofeng Wang et.al.|[2204.07346v1](http://arxiv.org/abs/2204.07346v1)|Code: https://github.com/JeffWang987/MVSTER|None|**[link](https://github.com/jeffwang987/mvster)**|\n", "2204.04141": "|**2022-04-08**|**Investigating Spherical Epipolar Rectification for Multi-View Stereo 3D Reconstruction**|Mostafa Elhashash et.al.|[2204.04141v1](http://arxiv.org/abs/2204.04141v1)|to be published in ISPRS Congress 2022|None|None|\n", "2204.01320": "|**2022-04-04**|**RayMVSNet: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo**|Junhua Xi et.al.|[2204.01320v1](http://arxiv.org/abs/2204.01320v1)|cvpr 2022, 11 pages|None|None|\n", "2204.01276": "|**2022-04-04**|**Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery**|Mugalodi Rakesh et.al.|[2204.01276v1](http://arxiv.org/abs/2204.01276v1)|NeurIPS 2021|None|None|\n", "2203.14331": "|**2022-03-27**|**SuperMVS: Non-Uniform Cost Volume For High-Resolution Multi-View Stereo**|Tao Zhang et.al.|[2203.14331v2](http://arxiv.org/abs/2203.14331v2)|None|None|None|\n", "2203.13296": "|**2022-03-24**|**RayTran: 3D pose estimation and shape reconstruction of multiple objects from videos with ray-traced transformers**|Micha\u0142 J. Tyszkiewicz et.al.|[2203.13296v2](http://arxiv.org/abs/2203.13296v2)|ECCV 2022 camera ready|None|None|\n", "2203.12270": "|**2022-03-23**|**Event-Based Dense Reconstruction Pipeline**|Kun Xiao et.al.|[2203.12270v1](http://arxiv.org/abs/2203.12270v1)|None|None|None|\n", "2203.12082": "|**2022-03-22**|**PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo**|Jiachen Liu et.al.|[2203.12082v3](http://arxiv.org/abs/2203.12082v3)|CVPR 2022; source code: https://github.com/oppo-us-research/PlaneMVS|None|**[link](https://github.com/oppo-us-research/planemvs)**|\n", "2203.08435": "|**2022-03-16**|**DiFT: Differentiable Differential Feature Transform for Multi-View Stereo**|Kaizhang Kang et.al.|[2203.08435v1](http://arxiv.org/abs/2203.08435v1)|None|None|None|\n", "2203.03949": "|**2022-03-08**|**RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering**|Di Chang et.al.|[2203.03949v4](http://arxiv.org/abs/2203.03949v4)|Accepted by ECCV 2022, Project Page:   https://boese0601.github.io/rc-mvsnet/|None|**[link](https://github.com/boese0601/rc-mvsnet)**|\n", "2203.02156": "|**2022-03-04**|**PatchMVSNet: Patch-wise Unsupervised Multi-View Stereo for Weakly-Textured Surface Reconstruction**|Haonan Dong et.al.|[2203.02156v1](http://arxiv.org/abs/2203.02156v1)|None|None|None|\n", "2203.01391": "|**2022-03-02**|**DDL-MVS: Depth Discontinuity Learning for MVS Networks**|Nail Ibrahimli et.al.|[2203.01391v3](http://arxiv.org/abs/2203.01391v3)|None|None|**[link](https://github.com/Mirmix/ddlmvs)**|\n", "2202.13118": "|**2022-02-26**|**Accurate Human Body Reconstruction for Volumetric Video**|Decai Chen et.al.|[2202.13118v1](http://arxiv.org/abs/2202.13118v1)|2021 International Conference on 3D Immersion (IC3D)|None|None|\n", "2202.13071": "|**2022-02-26**|**Uncertainty-Aware Deep Multi-View Photometric Stereo**|Berk Kaya et.al.|[2202.13071v2](http://arxiv.org/abs/2202.13071v2)|Accepted for publication in IEEE/CVF CVPR 2022. (11 Pages, 6 Figures,   3 Tables)|None|None|\n", "2201.08845": "|**2022-01-21**|**Point-NeRF: Point-based Neural Radiance Fields**|Qiangeng Xu et.al.|[2201.08845v7](http://arxiv.org/abs/2201.08845v7)|Accepted to CVPR 2022 (Oral)|In Proceedings of the IEEE/CVF Conference on Computer Vision and   Pattern Recognition (pp. 5438-5448) (2022)|**[link](https://github.com/Xharlie/pointnerf)**|\n", "2201.07609": "|**2022-01-19**|**A Confidence-based Iterative Solver of Depths and Surface Normals for Deep Multi-view Stereo**|Wang Zhao et.al.|[2201.07609v1](http://arxiv.org/abs/2201.07609v1)|17 pages, 13 figures, 7 tables. ICCV 2021|None|**[link](https://github.com/thuzhaowang/idn-solver)**|\n", "2201.01501": "|**2022-01-05**|**Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation**|Rui Peng et.al.|[2201.01501v3](http://arxiv.org/abs/2201.01501v3)|CVPR 2022 Accepted|None|**[link](https://github.com/prstrive/unimvsnet)**|\n", "2201.01016": "|**2022-01-04**|**Detailed Facial Geometry Recovery from Multi-View Images by Learning an Implicit Function**|Yunze Xiao et.al.|[2201.01016v2](http://arxiv.org/abs/2201.01016v2)|AAAI 2022 Oral, updated to camera ready version|None|**[link](https://github.com/zhuhao-nju/mvfr)**|\n", "2112.09902": "|**2021-12-18**|**3D Instance Segmentation of MVS Buildings**|Jiazhou Chen et.al.|[2112.09902v2](http://arxiv.org/abs/2112.09902v2)|14 figures, 12 figures|None|None|\n", "2112.08177": "|**2021-12-15**|**Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry**|Gwangbin Bae et.al.|[2112.08177v2](http://arxiv.org/abs/2112.08177v2)|CVPR 2022 (oral)|None|**[link](https://github.com/baegwangbin/magnet)**|\n", "2112.06730": "|**2021-12-13**|**VirtualCube: An Immersive 3D Video Communication System**|Yizhong Zhang et.al.|[2112.06730v2](http://arxiv.org/abs/2112.06730v2)|Project page:   https://www.microsoft.com/en-us/research/project/virtualcube/|None|None|\n", "2112.06133": "|**2021-12-12**|**MVLayoutNet:3D layout reconstruction with multi-view panoramas**|Zhihua Hu et.al.|[2112.06133v1](http://arxiv.org/abs/2112.06133v1)|None|None|None|\n", "2112.05999": "|**2021-12-11**|**Curvature-guided dynamic scale networks for Multi-view Stereo**|Khang Truong Giang et.al.|[2112.05999v3](http://arxiv.org/abs/2112.05999v3)|Accepted to ICLR 2022|None|**[link](https://github.com/truongkhang/cds-mvsnet)**|\n", "2112.05126": "|**2021-12-09**|**IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo**|Fangjinhua Wang et.al.|[2112.05126v1](http://arxiv.org/abs/2112.05126v1)|None|None|**[link](https://github.com/fangjinhuawang/itermvs)**|\n", "2112.03243": "|**2021-12-06**|**Input-level Inductive Biases for 3D Reconstruction**|Wang Yifan et.al.|[2112.03243v2](http://arxiv.org/abs/2112.03243v2)|CVPR 2022, including supplemental material|None|None|\n", "2112.02413": "|**2021-12-04**|**PointCLIP: Point Cloud Understanding by CLIP**|Renrui Zhang et.al.|[2112.02413v1](http://arxiv.org/abs/2112.02413v1)|Open sourced, Code and Model Available|None|**[link](https://github.com/zrrskywalker/pointclip)**|\n", "2112.02338": "|**2021-12-04**|**Generalized Binary Search Network for Highly-Efficient Multi-View Stereo**|Zhenxing Mi et.al.|[2112.02338v1](http://arxiv.org/abs/2112.02338v1)|16 pages|None|**[link](https://github.com/mizhenxing/gbi-net)**|\n", "2112.01502": "|**2021-12-02**|**Dimensions of Motion: Monocular Prediction through Flow Subspaces**|Richard Strong Bowen et.al.|[2112.01502v4](http://arxiv.org/abs/2112.01502v4)|Project page at https://dimensions-of-motion.github.io/|None|None|\n", "2112.00821": "|**2021-12-01**|**FaSS-MVS -- Fast Multi-View Stereo with Surface-Aware Semi-Global Matching from UAV-borne Monocular Imagery**|Boitumelo Ruf et.al.|[2112.00821v1](http://arxiv.org/abs/2112.00821v1)|None|None|None|\n", "2112.00336": "|**2021-12-01**|**Multi-View Stereo with Transformer**|Jie Zhu et.al.|[2112.00336v1](http://arxiv.org/abs/2112.00336v1)|None|None|None|\n", "2112.00202": "|**2021-12-01**|**3DVNet: Multi-View Depth Prediction and Volumetric Refinement**|Alexander Rich et.al.|[2112.00202v1](http://arxiv.org/abs/2112.00202v1)|10 pages, 6 figures, 3 tables. Accepted to 3DV 2021|None|**[link](https://github.com/alexrich021/3dvnet)**|\n", "2111.14600": "|**2021-11-29**|**TransMVSNet: Global Context-aware Multi-view Stereo Network with Transformers**|Yikang Ding et.al.|[2111.14600v1](http://arxiv.org/abs/2111.14600v1)|None|None|**[link](https://github.com/megviirobot/transmvsnet)**|\n", "2111.14420": "|**2021-11-29**|**IB-MVS: An Iterative Algorithm for Deep Multi-View Stereo based on Binary Decisions**|Christian Sormann et.al.|[2111.14420v1](http://arxiv.org/abs/2111.14420v1)|accepted at BMVC 2021|None|None|\n", "2110.08556": "|**2021-10-16**|**Multi-View Stereo Network with attention thin volume**|Zihang Wan et.al.|[2110.08556v2](http://arxiv.org/abs/2110.08556v2)|None|None|None|\n", "2110.07283": "|**2021-10-14**|**DeepMoCap: Deep Optical Motion Capture Using Multiple Depth Sensors and Retro-Reflectors**|Anargyros Chatzitofis et.al.|[2110.07283v1](http://arxiv.org/abs/2110.07283v1)|None|Sensors, 19(2), 282, 2019|**[link](https://github.com/tofis/deepmocap)**|\n", "2110.06436": "|**2021-10-13**|**Non-local Recurrent Regularization Networks for Multi-view Stereo**|Qingshan Xu et.al.|[2110.06436v1](http://arxiv.org/abs/2110.06436v1)|None|None|None|\n", "2110.05594": "|**2021-10-11**|**Neural Radiance Fields Approach to Deep Multi-View Photometric Stereo**|Berk Kaya et.al.|[2110.05594v1](http://arxiv.org/abs/2110.05594v1)|Accepted for publication at IEEE/CVF WACV 2022. 18 pages|None|None|\n", "2110.05472": "|**2021-10-11**|**Differentiable Stereopsis: Meshes from multiple views using differentiable rendering**|Shubham Goel et.al.|[2110.05472v2](http://arxiv.org/abs/2110.05472v2)|In CVPR2022. Project webpage: https://shubham-goel.github.io/ds/|In CVPR 2022 (pp. 8635-8644)|**[link](https://github.com/shubham-goel/ds)**|\n", "2110.02948": "|**2021-10-06**|**Topologically Consistent Multi-View Face Inference Using Volumetric Sampling**|Tianye Li et.al.|[2110.02948v1](http://arxiv.org/abs/2110.02948v1)|International Conference on Computer Vision (ICCV)|None|None|\n", "2109.02740": "|**2021-09-06**|**Single-Camera 3D Head Fitting for Mixed Reality Clinical Applications**|Tejas Mane et.al.|[2109.02740v2](http://arxiv.org/abs/2109.02740v2)|None|None|None|\n", "2109.02369": "|**2021-09-06**|**Point-Based Neural Rendering with Per-View Optimization**|Georgios Kopanas et.al.|[2109.02369v2](http://arxiv.org/abs/2109.02369v2)|https://repo-sam.inria.fr/fungraph/differentiable-multi-view/|In Computer Graphics Forum, Vol. 10. Wiley Online Library, 29-43   (2021)|None|\n", "2109.01129": "|**2021-09-02**|**NerfingMVS: Guided Optimization of Neural Radiance Fields for Indoor Multi-view Stereo**|Yi Wei et.al.|[2109.01129v3](http://arxiv.org/abs/2109.01129v3)|To appear in ICCV 2021 (Oral). Project page:   https://weiyithu.github.io/NerfingMVS/|None|**[link](https://github.com/weiyithu/nerfingmvs)**|\n", "2108.12966": "|**2021-08-30**|**Digging into Uncertainty in Self-supervised Multi-view Stereo**|Hongbin Xu et.al.|[2108.12966v2](http://arxiv.org/abs/2108.12966v2)|This paper is accepted by ICCV-21 as a poster presentation|None|**[link](https://github.com/toughstonex/u-mvs)**|\n", "2108.08943": "|**2021-08-19**|**PatchMatch-RL: Deep MVS with Pixelwise Depth, Normal, and Visibility**|Jae Yong Lee et.al.|[2108.08943v1](http://arxiv.org/abs/2108.08943v1)|Accepted to ICCV 2021 for oral presentation|None|**[link](https://github.com/leejaeyong7/patchmatch-rl)**|\n", "2108.08623": "|**2021-08-19**|**VolumeFusion: Deep Depth Fusion for 3D Scene Reconstruction**|Jaesung Choe et.al.|[2108.08623v1](http://arxiv.org/abs/2108.08623v1)|ICCV 2021 Accepted|None|None|\n", "2108.03880": "|**2021-08-09**|**NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis**|Radu Alexandru Rosu et.al.|[2108.03880v2](http://arxiv.org/abs/2108.03880v2)|Accepted for International Joint Conference on Neural Networks   (IJCNN) 2022. Code available at https://github.com/AIS-Bonn/neural_mvs|None|**[link](https://github.com/ais-bonn/neural_mvs)**|\n", "2108.03824": "|**2021-08-09**|**AA-RMVSNet: Adaptive Aggregation Recurrent Multi-view Stereo Network**|Zizhuang Wei et.al.|[2108.03824v1](http://arxiv.org/abs/2108.03824v1)|None|None|**[link](https://github.com/qt-zhu/aa-rmvsnet)**|\n", "2108.02448": "|**2021-08-05**|**MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion**|Weihao Yuan et.al.|[2108.02448v2](http://arxiv.org/abs/2108.02448v2)|IEEE International Conference on Robotics and Automation (ICRA) +   IEEE Robotics and Automation Letters (RA-L). arXiv admin note: substantial   text overlap with arXiv:2001.08212|None|None|\n", "2107.13261": "|**2021-07-28**|**Improving Multi-View Stereo via Super-Resolution**|Eugenio Lomurno et.al.|[2107.13261v1](http://arxiv.org/abs/2107.13261v1)|None|None|None|\n", "2107.06130": "|**2021-07-13**|**Scalable Surface Reconstruction with Delaunay-Graph Neural Networks**|Raphael Sulzer et.al.|[2107.06130v3](http://arxiv.org/abs/2107.06130v3)|The presentation of this work at SGP 2021 is available at   https://youtu.be/KIrCDGhS10o|Computer Graphics Forum 2021|**[link](https://github.com/raphaelsulzer/dgnn)**|\n", "2107.04277": "|**2021-07-09**|**Prior-Guided Multi-View 3D Head Reconstruction**|Xueying Wang et.al.|[2107.04277v2](http://arxiv.org/abs/2107.04277v2)|13 pages, 14 figures|Received by IEEE Transactions on Multimedia (2021)|None|\n", "2107.02191": "|**2021-07-05**|**TransformerFusion: Monocular RGB Scene Reconstruction using Transformers**|Alja\u017e Bo\u017ei\u010d et.al.|[2107.02191v1](http://arxiv.org/abs/2107.02191v1)|Video: https://youtu.be/LIpTKYfKSqw|None|None|\n", "2106.15328": "|**2021-06-18**|**Deep Learning for Multi-View Stereo via Plane Sweep: A Survey**|Qingtian Zhu et.al.|[2106.15328v2](http://arxiv.org/abs/2106.15328v2)|None|None|None|\n", "2104.15119": "|**2021-04-30**|**Deep Multi-View Stereo gone wild**|Fran\u00e7ois Darmon et.al.|[2104.15119v2](http://arxiv.org/abs/2104.15119v2)|Accepted to 3DV2021|None|**[link](https://github.com/fdarmon/wild_deep_mvs)**|\n", "2104.14540": "|**2021-04-29**|**The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth**|Jamie Watson et.al.|[2104.14540v2](http://arxiv.org/abs/2104.14540v2)|CVPR 2021|None|**[link](https://github.com/nianticlabs/manydepth)**|\n", "2104.13325": "|**2021-04-27**|**MVS2D: Efficient Multi-view Stereo via Attention-Driven 2D Convolutions**|Zhenpei Yang et.al.|[2104.13325v2](http://arxiv.org/abs/2104.13325v2)|Our code is released at https://github.com/zhenpeiyang/MVS2D|None|**[link](https://github.com/zhenpeiyang/MVS2D)**|\n", "2104.10515": "|**2021-04-21**|**Real-time dense 3D Reconstruction from monocular video data captured by low-cost UAVs**|Max Hermann et.al.|[2104.10515v1](http://arxiv.org/abs/2104.10515v1)|8 pages, 4 figures|None|None|\n", "2104.08013": "|**2021-04-16**|**Data-Driven 3D Reconstruction of Dressed Humans From Sparse Views**|Pierre Zins et.al.|[2104.08013v4](http://arxiv.org/abs/2104.08013v4)|Presented at 3DV 2021. Code is released at   https://gitlab.inria.fr/pzins/data-driven-3d-reconstruction-of-dressed-humans-from-sparse-views/|3DV 2021|**[link](https://gitlab.inria.fr/pzins/data-driven-3d-reconstruction-of-dressed-humans-from-sparse-views)**|\n", "2104.06935": "|**2021-04-14**|**Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes**|Julian Chibane et.al.|[2104.06935v1](http://arxiv.org/abs/2104.06935v1)|IEEE Conference on Computer Vision and Pattern Recognition (CVPR)   2021|IEEE Conference on Computer Vision and Pattern Recognition (CVPR)   2021|None|\n", "2104.06165": "|**2021-04-13**|**PHI-MVS: Plane Hypothesis Inference Multi-view Stereo for Large-Scale Scene Reconstruction**|Shang Sun et.al.|[2104.06165v1](http://arxiv.org/abs/2104.06165v1)|None|None|None|\n", "2104.05374": "|**2021-04-12**|**Self-supervised Multi-view Stereo via Effective Co-Segmentation and Data-Augmentation**|Hongbin Xu et.al.|[2104.05374v1](http://arxiv.org/abs/2104.05374v1)|This paper is accepted by AAAI-21 with a Distinguished Paper Award|None|**[link](https://github.com/ToughStoneX/Self-Supervised-MVS)**|\n", "2104.02972": "|**2021-04-07**|**Self-supervised Learning of Depth Inference for Multi-view Stereo**|Jiayu Yang et.al.|[2104.02972v1](http://arxiv.org/abs/2104.02972v1)|CVPR 2021|None|**[link](https://github.com/JiayuYANG/Self-supervised-CVP-MVSNet)**|\n", "2103.15595": "|**2021-03-29**|**MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo**|Anpei Chen et.al.|[2103.15595v2](http://arxiv.org/abs/2103.15595v2)|Project Page: https://apchenstu.github.io/mvsnerf/   Code:https://github.com/apchenstu/mvsnerf|None|**[link](https://github.com/apchenstu/mvsnerf)**|\n", "2103.14794": "|**2021-03-27**|**Learning Efficient Photometric Feature Transform for Multi-view Stereo**|Kaizhang Kang et.al.|[2103.14794v1](http://arxiv.org/abs/2103.14794v1)|None|None|None|\n", "2103.14275": "|**2021-03-26**|**DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range**|Puyuan Yi et.al.|[2103.14275v1](http://arxiv.org/abs/2103.14275v1)|None|None|**[link](https://github.com/Tangshengku/DDR-Net)**|\n", "2012.10296": "|**2020-12-18**|**Boosting Monocular Depth Estimation with Lightweight 3D Point Fusion**|Lam Huynh et.al.|[2012.10296v2](http://arxiv.org/abs/2012.10296v2)|10 pages, 9 figures|None|None|\n", "2012.03939": "|**2020-12-06**|**Shape From Tracing: Towards Reconstructing 3D Object Geometry and SVBRDF Material from Images via Differentiable Path Tracing**|Purvi Goel et.al.|[2012.03939v1](http://arxiv.org/abs/2012.03939v1)|Will be published at 3DV 2020|None|**[link](https://github.com/brownvc/shapefromtracing)**|\n", "2012.02177": "|**2020-12-03**|**DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion**|Arda D\u00fcz\u00e7eker et.al.|[2012.02177v3](http://arxiv.org/abs/2012.02177v3)|CVPR 2021|None|**[link](https://github.com/ardaduz/deep-video-mvs)**|\n", "2012.01411": "|**2020-12-02**|**PatchmatchNet: Learned Multi-View Patchmatch Stereo**|Fangjinhua Wang et.al.|[2012.01411v1](http://arxiv.org/abs/2012.01411v1)|None|None|**[link](https://github.com/FangjinhuaWang/PatchmatchNet)**|\n", "2012.01044": "|**2020-12-02**|**A Photogrammetry-based Framework to Facilitate Image-based Modeling and Automatic Camera Tracking**|Sebastian Bullinger et.al.|[2012.01044v1](http://arxiv.org/abs/2012.01044v1)|None|In Proceedings of the 16th International Joint Conference on   Computer Vision, Imaging and Computer Graphics Theory and Applications -   Volume 1: GRAPP, 106-112, 2021|**[link](https://github.com/SBCV/Blender-Addon-Photogrammetry-Importer)**|\n", "2012.00564": "|**2020-12-01**|**Facetwise Mesh Refinement for Multi-View Stereo**|Andrea Romanoni et.al.|[2012.00564v1](http://arxiv.org/abs/2012.00564v1)|Accepted as Oral ICPR2020|None|None|\n", "2011.14761": "|**2020-11-30**|**How Good MVSNets Are at Depth Fusion**|Oleg Voynov et.al.|[2011.14761v1](http://arxiv.org/abs/2011.14761v1)|7 pages, 6 figures, 1 table. Accepted to ICMV 2020|None|None|\n", "2011.14398": "|**2020-11-29**|**RGBD-Net: Predicting color and depth images for novel views synthesis**|Phong Nguyen-Ha et.al.|[2011.14398v2](http://arxiv.org/abs/2011.14398v2)|19 pages, 15 figures. Code will be available at:   https://github.com/phongnhhn92/RGBDNet|None|None|\n", "2011.13118": "|**2020-11-26**|**Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks**|Xiaoxiao Long et.al.|[2011.13118v3](http://arxiv.org/abs/2011.13118v3)|None|None|**[link](https://github.com/xxlong0/ESTDepth)**|\n", "2011.12722": "|**2020-11-25**|**Attention Aware Cost Volume Pyramid Based Multi-view Stereo Network for 3D Reconstruction**|Anzhu Yu et.al.|[2011.12722v1](http://arxiv.org/abs/2011.12722v1)|None|None|**[link](https://github.com/ArthasMil/AACVP-MVSNet)**|\n", "2011.11814": "|**2020-11-24**|**MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera**|Felix Wimbauer et.al.|[2011.11814v3](http://arxiv.org/abs/2011.11814v3)|CVPR 2021, Project page with video can be found under   https://vision.in.tum.de/research/monorec. 14 pages, 10 figures, 5 tables|Proceedings of the IEEE/CVF Conference on Computer Vision and   Pattern Recognition (CVPR), 2021, pp. 6112-6122|**[link](https://github.com/Brummi/MonoRec)**|\n", "2011.10359": "|**2020-11-20**|**RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth Uncertainty**|Benjamin Graham et.al.|[2011.10359v1](http://arxiv.org/abs/2011.10359v1)|Presenting at 3DV 2020. Source code released at   https://github.com/facebookresearch/RidgeSfM|None|**[link](https://github.com/facebookresearch/RidgeSfM)**|\n", "2011.09114": "|**2020-11-18**|**Dehazing Cost Volume for Deep Multi-view Stereo in Scattering Media with Airlight and Scattering Coefficient Estimation**|Yuki Fujimura et.al.|[2011.09114v2](http://arxiv.org/abs/2011.09114v2)|14 pages, extended version of our ACCV2020 paper|None|**[link](https://github.com/yfujimura/DCV-release)**|\n", "2011.07233": "|**2020-11-14**|**Stable View Synthesis**|Gernot Riegler et.al.|[2011.07233v2](http://arxiv.org/abs/2011.07233v2)|Published at CVPR 2021, https://youtu.be/gqgXIY09htI|None|**[link](https://github.com/intel-isl/StableViewSynthesis)**|\n", "2011.01122": "|**2020-11-02**|**SLAM in the Field: An Evaluation of Monocular Mapping and Localization on Challenging Dynamic Agricultural Environment**|Fangwen Shu et.al.|[2011.01122v2](http://arxiv.org/abs/2011.01122v2)|accepted to WACV 2021, acknowledgment added|None|None|\n", "2010.12436": "|**2020-10-23**|**BP-MVSNet: Belief-Propagation-Layers for Multi-View-Stereo**|Christian Sormann et.al.|[2010.12436v1](http://arxiv.org/abs/2010.12436v1)|accepted at 3DV 2020|None|None|\n", "2010.08682": "|**2020-10-17**|**MeshMVS: Multi-View Stereo Guided Mesh Reconstruction**|Rakesh Shrestha et.al.|[2010.08682v3](http://arxiv.org/abs/2010.08682v3)|None|None|None|\n", "2010.07646": "|**2020-10-15**|**Empty Cities: a Dynamic-Object-Invariant Space for Visual SLAM**|Berta Bescos et.al.|[2010.07646v1](http://arxiv.org/abs/2010.07646v1)|None|None|**[link](https://github.com/bertabescos/EmptyCities_SLAM)**|\n", "2010.00928": "|**2020-10-02**|**Image-based underwater 3D reconstruction for Cultural Heritage: from image collection to 3D. Critical steps and considerations**|Dimitrios Skarlatos et.al.|[2010.00928v1](http://arxiv.org/abs/2010.00928v1)|Pre-submission version of the manuscript|None|None|\n", "2009.13278": "|**2020-09-28**|**Learning to Adapt Multi-View Stereo by Self-Supervision**|Arijit Mallick et.al.|[2009.13278v1](http://arxiv.org/abs/2009.13278v1)|19 pages, including supplementary, accepted and presented in BMVC   2020|None|None|\n", "2009.03298": "|**2020-09-07**|**Improved Modeling of 3D Shapes with Multi-view Depth Maps**|Kamal Gupta et.al.|[2009.03298v1](http://arxiv.org/abs/2009.03298v1)|None|None|None|\n", "2008.08213": "|**2020-08-19**|**DeepHandMesh: A Weakly-supervised Deep Encoder-Decoder Framework for High-fidelity Hand Mesh Modeling**|Gyeongsik Moon et.al.|[2008.08213v1](http://arxiv.org/abs/2008.08213v1)|Published at ECCV 2020 (Oral)|None|**[link](https://github.com/facebookresearch/DeepHandMesh)**|\n", "2008.07928": "|**2020-08-18**|**Visibility-aware Multi-view Stereo Network**|Jingyang Zhang et.al.|[2008.07928v2](http://arxiv.org/abs/2008.07928v2)|Accepted to BMVC 2020|None|**[link](https://github.com/jzhangbs/Vis-MVSNet)**|\n", "2007.10872": "|**2020-07-21**|**Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking**|Jianfeng Yan et.al.|[2007.10872v1](http://arxiv.org/abs/2007.10872v1)|Accepted by ECCV2020 as Spotlight|ECCV2020|**[link](https://github.com/yhw-yhw/D2HC-RMVSNet)**|\n", "2007.08830": "|**2020-07-17**|**Polarimetric Multi-View Inverse Rendering**|Jinyu Zhao et.al.|[2007.08830v1](http://arxiv.org/abs/2007.08830v1)|Paper accepted in ECCV 2020|None|None|\n", "2007.07714": "|**2020-07-15**|**PVSNet: Pixelwise Visibility-Aware Multi-View Stereo Network**|Qingshan Xu et.al.|[2007.07714v1](http://arxiv.org/abs/2007.07714v1)|None|None|None|\n", "2007.06676": "|**2020-07-13**|**UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distortion Models**|Varun Ravi Kumar et.al.|[2007.06676v4](http://arxiv.org/abs/2007.06676v4)|Minor fixes added after IROS 2020 Camera ready submission. IROS 2020   presentation video - https://www.youtube.com/watch?v=3Br2KSWZRrY|None|None|\n", "2005.00363": "|**2020-04-30**|**M^3VSNet: Unsupervised Multi-metric Multi-view Stereo Network**|Baichuan Huang et.al.|[2005.00363v2](http://arxiv.org/abs/2005.00363v2)|The original top-level version is arXiv:2004.09722v2 but I upload the   similar version to arXiv:2005.00363 mistakenly, which is overlapped with   arXiv:2004.09722v2. So the submission is to make the two addresses keeping   the same version|None|**[link](https://github.com/whubaichuan/M3VSNet)**|\n", "2004.12260": "|**2020-04-26**|**Learning to Autofocus**|Charles Herrmann et.al.|[2004.12260v3](http://arxiv.org/abs/2004.12260v3)|CVPR 2020|None|None|\n", "2004.09722": "|**2020-04-21**|**M^3VSNet: Unsupervised Multi-metric Multi-view Stereo Network**|Baichuan Huang et.al.|[2004.09722v2](http://arxiv.org/abs/2004.09722v2)|Welcome to communicate with the author by the repo   https://github.com/whubaichuan/M3VSNet|None|**[link](https://github.com/whubaichuan/M3VSNet)**|\n", "2004.01294": "|**2020-04-02**|**Novel View Synthesis of Dynamic Scenes with Globally Coherent Depths from a Monocular Camera**|Jae Shin Yoon et.al.|[2004.01294v1](http://arxiv.org/abs/2004.01294v1)|This paper is accepted to CVPR 2020|None|None|\n", "2003.13017": "|**2020-03-29**|**Fast-MVSNet: Sparse-to-Dense Multi-View Stereo With Learned Propagation and Gauss-Newton Refinement**|Zehao Yu et.al.|[2003.13017v1](http://arxiv.org/abs/2003.13017v1)|Accepted by CVPR2020|None|**[link](https://github.com/svip-lab/FastMVSNet)**|\n", "2003.12642": "|**2020-03-27**|**Deep 3D Capture: Geometry and Reflectance from Sparse Multi-View Images**|Sai Bi et.al.|[2003.12642v2](http://arxiv.org/abs/2003.12642v2)|Accepted to CVPR 2020|None|None|\n", "2003.08933": "|**2020-03-19**|**DELTAS: Depth Estimation by Learning Triangulation And densification of Sparse points**|Ayan Sinha et.al.|[2003.08933v2](http://arxiv.org/abs/2003.08933v2)|ECCV 2020|None|**[link](https://github.com/magicleap/DELTAS)**|\n", "2003.00711": "|**2020-03-02**|**A-TVSNet: Aggregated Two-View Stereo Network for Multi-View Stereo Depth Estimation**|Sizhang Dai et.al.|[2003.00711v1](http://arxiv.org/abs/2003.00711v1)|None|None|**[link](https://github.com/daiszh/A-TVSNet)**|\n", "2003.00637": "|**2020-03-02**|**A Novel Recurrent Encoder-Decoder Structure for Large-Scale Multi-view Stereo Reconstruction from An Open Aerial Dataset**|Jin Liu et.al.|[2003.00637v3](http://arxiv.org/abs/2003.00637v3)|None|None|None|\n", "2002.09085": "|**2020-02-21**|**Leveraging Photogrammetric Mesh Models for Aerial-Ground Feature Point Matching Toward Integrated 3D Reconstruction**|Qing Zhu et.al.|[2002.09085v2](http://arxiv.org/abs/2002.09085v2)|Accepted for publication in ISPRS Journal of Photogrammetry and   Remote Sensing|None|**[link](https://github.com/saedrna/RenderMatch)**|\n", "2001.08212": "|**2020-01-22**|**Active Perception with A Monocular Camera for Multiscopic Vision**|Weihao Yuan et.al.|[2001.08212v1](http://arxiv.org/abs/2001.08212v1)|8 pages|None|**[link](https://github.com/weihaosky/MFuseNet)**|\n", "2001.07791": "|**2020-01-21**|**Depth Completion Using a View-constrained Deep Prior**|Pallabi Ghosh et.al.|[2001.07791v3](http://arxiv.org/abs/2001.07791v3)|None|None|None|\n", "1912.11746": "|**2019-12-26**|**Learning Inverse Depth Regression for Multi-View Stereo with Correlation Cost Volume**|Qingshan Xu et.al.|[1912.11746v1](http://arxiv.org/abs/1912.11746v1)|Accepted by AAAI-2020|None|**[link](https://github.com/GhiXu/CIDER)**|\n", "1912.11744": "|**2019-12-26**|**Planar Prior Assisted PatchMatch Multi-View Stereo**|Qingshan Xu et.al.|[1912.11744v1](http://arxiv.org/abs/1912.11744v1)|Accepted by AAAI-2020|None|**[link](https://github.com/GhiXu/ACMP)**|\n", "1912.06378": "|**2019-12-13**|**Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching**|Xiaodong Gu et.al.|[1912.06378v3](http://arxiv.org/abs/1912.06378v3)|Accepted by CVPR2020 Oral|None|**[link](https://github.com/alibaba/cascade-stereo)**|\n", "1912.03001": "|**2019-12-06**|**Pyramid Multi-view Stereo Net with Self-adaptive View Aggregation**|Hongwei Yi et.al.|[1912.03001v2](http://arxiv.org/abs/1912.03001v2)|Accepted by ECCV2020 as a Poster|ECCV2020|**[link](https://github.com/yhw-yhw/PVAMVSNet)**|\n", "1912.01306": "|**2019-12-03**|**Joint Graph-based Depth Refinement and Normal Estimation**|Mattia Rossi et.al.|[1912.01306v2](http://arxiv.org/abs/1912.01306v2)|None|None|None|\n", "1912.00439": "|**2019-12-01**|**DeepC-MVS: Deep Confidence Prediction for Multi-View Stereo Reconstruction**|Andreas Kuhn et.al.|[1912.00439v3](http://arxiv.org/abs/1912.00439v3)|changes in V3: re-worked confidence prediction scheme, re-organized   text, updated experiments; changes in V2: a reference was updated|None|None|\n", "1911.12012": "|**2019-11-27**|**Deep Stereo using Adaptive Thin Volume Representation with Uncertainty Awareness**|Shuo Cheng et.al.|[1911.12012v2](http://arxiv.org/abs/1911.12012v2)|Accepted to CVPR 2020 (Oral)|None|None|\n", "1911.10444": "|**2019-11-24**|**Normal Assisted Stereo Depth Estimation**|Uday Kusupati et.al.|[1911.10444v3](http://arxiv.org/abs/1911.10444v3)|None|None|**[link](https://github.com/udaykusupati/Normal-Assisted-Stereo)**|\n", "1911.10127": "|**2019-11-22**|**BlendedMVS: A Large-scale Dataset for Generalized Multi-view Stereo Networks**|Yao Yao et.al.|[1911.10127v2](http://arxiv.org/abs/1911.10127v2)|Accepted to CVPR2020|None|**[link](https://github.com/YoYo000/BlendedMVS)**|\n", "1910.08259": "|**2019-10-18**|**Eye in the Sky: Drone-Based Object Tracking and 3D Localization**|Haotian Zhang et.al.|[1910.08259v1](http://arxiv.org/abs/1910.08259v1)|Accepted to ACMMM2019|None|None|\n", "1910.02989": "|**2019-10-07**|**Leveraging Vision Reconstruction Pipelines for Satellite Imagery**|Kai Zhang et.al.|[1910.02989v2](http://arxiv.org/abs/1910.02989v2)|Project Page: https://kai-46.github.io/VisSat/|None|None|\n", "1909.03101": "|**2019-09-06**|**Self-supervised Dense 3D Reconstruction from Monocular Endoscopic Video**|Xingtong Liu et.al.|[1909.03101v1](http://arxiv.org/abs/1909.03101v1)|None|None|None|\n", "1908.11526": "|**2019-08-30**|**MVS^2: Deep Unsupervised Multi-view Stereo with Multi-View Symmetry**|Yuchao Dai et.al.|[1908.11526v1](http://arxiv.org/abs/1908.11526v1)|Accepted by International Conference on 3D Vision (3DV 2019) as ORAL   presentation|None|None|\n", "1908.08814": "|**2019-08-23**|**Multi-Spectral Visual Odometry without Explicit Stereo Matching**|Weichen Dai et.al.|[1908.08814v1](http://arxiv.org/abs/1908.08814v1)|None|None|None|\n", "1908.06257": "|**2019-08-17**|**OmniMVS: End-to-End Learning for Omnidirectional Stereo Matching**|Changhee Won et.al.|[1908.06257v1](http://arxiv.org/abs/1908.06257v1)|Accepted by ICCV 2019|None|**[link](https://github.com/hyu-cvlab/omnimvs-pytorch)**|\n", "1908.04422": "|**2019-08-12**|**Point-Based Multi-View Stereo Network**|Rui Chen et.al.|[1908.04422v1](http://arxiv.org/abs/1908.04422v1)|Accepted as ICCV 2019 oral presentation|None|**[link](https://github.com/callmeray/PointMVSNet)**|\n", "1908.01301": "|**2019-08-04**|**Adversarial View-Consistent Learning for Monocular Depth Estimation**|Yixuan Liu et.al.|[1908.01301v1](http://arxiv.org/abs/1908.01301v1)|BMVC 2019 Spotlight|None|None|\n", "1906.08650": "|**2019-06-20**|**3D Instance Segmentation via Multi-Task Metric Learning**|Jean Lahoud et.al.|[1906.08650v2](http://arxiv.org/abs/1906.08650v2)|None|None|None|\n", "1906.00932": "|**2019-06-03**|**Y-GAN: A Generative Adversarial Network for Depthmap Estimation from Multi-camera Stereo Images**|Miguel Alonso Jr et.al.|[1906.00932v1](http://arxiv.org/abs/1906.00932v1)|Accepted for Presentation at the ICML 2019 LatinX in AI Research   Workshop|None|None|\n", "1905.08502": "|**2019-05-21**|**Mesh-based Camera Pairs Selection and Occlusion-Aware Masking for Mesh Refinement**|Andrea Romanoni et.al.|[1905.08502v1](http://arxiv.org/abs/1905.08502v1)|Accepted for publication in Pattern Recognition Letters|None|None|\n", "1904.11111": "|**2019-04-25**|**Learning the Depths of Moving People by Watching Frozen People**|Zhengqi Li et.al.|[1904.11111v1](http://arxiv.org/abs/1904.11111v1)|CVPR 2019 (Oral)|None|None|\n", "1904.08366": "|**2019-04-17**|**Render4Completion: Synthesizing Multi-View Depth Maps for 3D Shape Completion**|Tao Hu et.al.|[1904.08366v4](http://arxiv.org/abs/1904.08366v4)|ICCV 2019 workshop on Geometry meets Deep Learning|None|None|\n", "1904.08103": "|**2019-04-17**|**Multi-Scale Geometric Consistency Guided Multi-View Stereo**|Qingshan Xu et.al.|[1904.08103v1](http://arxiv.org/abs/1904.08103v1)|Accepted by CVPR2019|None|None|\n", "1903.10929": "|**2019-03-26**|**TAPA-MVS: Textureless-Aware PAtchMatch Multi-View Stereo**|Andrea Romanoni et.al.|[1903.10929v1](http://arxiv.org/abs/1903.10929v1)|None|None|None|\n", "1903.04814": "|**2019-03-12**|**Image Classification base on PCA of Multi-view Deep Representation**|Yaoqi Sun et.al.|[1903.04814v1](http://arxiv.org/abs/1903.04814v1)|None|None|None|\n", "1902.10733": "|**2019-02-27**|**Shallow Water Bathymetry Mapping from UAV Imagery based on Machine Learning**|Panagiotis Agrafiotis et.al.|[1902.10733v3](http://arxiv.org/abs/1902.10733v3)|8 pages, 9 figures|Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W10,   9-16, 2019|None|\n", "1902.10556": "|**2019-02-27**|**Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference**|Yao Yao et.al.|[1902.10556v1](http://arxiv.org/abs/1902.10556v1)|Accepted by CVPR2019|None|**[link](https://github.com/YoYo000/MVSNet)**|\n", "1902.07766": "|**2019-02-20**|**Dense Depth Estimation in Monocular Endoscopy with Self-supervised Learning Methods**|Xingtong Liu et.al.|[1902.07766v2](http://arxiv.org/abs/1902.07766v2)|Accepted to IEEE Transactions on Medical Imaging|None|**[link](https://github.com/lppllppl920/EndoscopyDepthEstimation-Pytorch)**|\n", "1901.03910": "|**2019-01-12**|**NRMVS: Non-Rigid Multi-View Stereo**|Matthias Innmann et.al.|[1901.03910v1](http://arxiv.org/abs/1901.03910v1)|None|None|None|\n", "1812.09366": "|**2018-12-21**|**Wireless Software Synchronization of Multiple Distributed Cameras**|Sameer Ansari et.al.|[1812.09366v2](http://arxiv.org/abs/1812.09366v2)|Main: 9 pages, 10 figures. Supplemental: 3 pages, 5 figures|None|None|\n", "1811.10720": "|**2018-11-26**|**IGNOR: Image-guided Neural Object Rendering**|Justus Thies et.al.|[1811.10720v2](http://arxiv.org/abs/1811.10720v2)|Video: https://youtu.be/s79HG9yn7QM|None|None|\n", "1811.01984": "|**2018-11-05**|**A Differential Volumetric Approach to Multi-View Photometric Stereo**|Fotios Logothetis et.al.|[1811.01984v2](http://arxiv.org/abs/1811.01984v2)|None|None|None|\n", "1809.11073": "|**2018-09-28**|**Extrinsic camera calibration method and its performance evaluation**|Jacek Komorowski et.al.|[1809.11073v1](http://arxiv.org/abs/1809.11073v1)|arXiv admin note: text overlap with arXiv:1809.11066|None|None|\n", "1809.11069": "|**2018-09-28**|**Face Recognition Based on Sequence of Images**|Jacek Komorowski et.al.|[1809.11069v1](http://arxiv.org/abs/1809.11069v1)|None|None|None|\n", "1809.09195": "|**2018-09-24**|**Towards Automated Post-Earthquake Inspections with Deep Learning-based Condition-Aware Models**|Vedhus Hoskere et.al.|[1809.09195v1](http://arxiv.org/abs/1809.09195v1)|None|None|None|\n", "1807.05653": "|**2018-07-16**|**Learning and Matching Multi-View Descriptors for Registration of Point Clouds**|Lei Zhou et.al.|[1807.05653v2](http://arxiv.org/abs/1807.05653v2)|None|None|None|\n", "1806.11269": "|**2018-06-29**|**Action Recognition for Depth Video using Multi-view Dynamic Images**|Yang Xiao et.al.|[1806.11269v3](http://arxiv.org/abs/1806.11269v3)|accepted by Information Sciences|None|**[link](https://github.com/3huo/MVDI)**|\n", "1806.09521": "|**2018-06-25**|**Self-supervised Learning for Dense Depth Estimation in Monocular Endoscopy**|Xingtong Liu et.al.|[1806.09521v2](http://arxiv.org/abs/1806.09521v2)|11 pages, 5 figures|None|None|\n", "1805.06558": "|**2018-05-17**|**Recurrent Neural Network for Learning DenseDepth and Ego-Motion from Video**|Rui Wang et.al.|[1805.06558v1](http://arxiv.org/abs/1805.06558v1)|None|None|None|\n", "1804.08302": "|**2018-04-23**|**Deep cross-domain building extraction for selective depth estimation from oblique aerial imagery**|Boitumelo Ruf et.al.|[1804.08302v3](http://arxiv.org/abs/1804.08302v3)|Accepted in the ISPRS Annals of the Photogrammetry, Remote Sensing   and Spatial Information Science|ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., IV-1,   125-132, 2018|None|\n", "1804.05261": "|**2018-04-14**|**Physics-driven Fire Modeling from Multi-view Images**|Garoe Dorta et.al.|[1804.05261v1](http://arxiv.org/abs/1804.05261v1)|None|None|**[link](https://github.com/Garoe/bath-fire-shader)**|\n", "1804.00650": "|**2018-04-02**|**DeepMVS: Learning Multi-view Stereopsis**|Po-Han Huang et.al.|[1804.00650v1](http://arxiv.org/abs/1804.00650v1)|CVPR 2018. Project page: https://phuang17.github.io/DeepMVS/ Code:   https://github.com/phuang17/DeepMVS|None|**[link](https://github.com/phuang17/DeepMVS)**|\n", "1804.00607": "|**2018-04-02**|**MegaDepth: Learning Single-View Depth Prediction from Internet Photos**|Zhengqi Li et.al.|[1804.00607v4](http://arxiv.org/abs/1804.00607v4)|updated paper for 'MegaDepth: Learning Single-View Depth Prediction   from Internet Photos', CVPR, 2018|None|None|\n", "1803.08323": "|**2018-03-22**|**Prioritized Multi-View Stereo Depth Map Generation Using Confidence Prediction**|Christian Mostegel et.al.|[1803.08323v1](http://arxiv.org/abs/1803.08323v1)|This paper was accepted to ISPRS Journal of Photogrammetry and Remote   Sensing   (https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing)   on March 21, 2018. The official version will be made available on   ScienceDirect (https://www.sciencedirect.com)|None|None|\n", "1803.07702": "|**2018-03-21**|**Robust Depth Estimation from Auto Bracketed Images**|Sunghoon Im et.al.|[1803.07702v1](http://arxiv.org/abs/1803.07702v1)|To appear in CVPR 2018. Total 9 pages|None|None|\n", "1801.05606": "|**2018-01-17**|**Multi-View Stereo 3D Edge Reconstruction**|Andrea Bignoli et.al.|[1801.05606v1](http://arxiv.org/abs/1801.05606v1)|Accepted for WACV 2018|None|**[link](https://github.com/abignoli/EdgeGraph3D)**|\n", "1801.01466": "|**2018-01-04**|**A Large Dataset for Improving Patch Matching**|Rahul Mitra et.al.|[1801.01466v3](http://arxiv.org/abs/1801.01466v3)|None|None|**[link](https://github.com/rmitra/PS-Dataset)**|\n", "1711.10312": "|**2017-11-28**|**Super-Resolution for Overhead Imagery Using DenseNets and Adversarial Learning**|Marc Bosch et.al.|[1711.10312v1](http://arxiv.org/abs/1711.10312v1)|9 pages, 9 figures, WACV 2018 submission|None|None|\n", "1709.07599": "|**2017-09-22**|**High-Resolution Shape Completion Using Deep Neural Networks for Global Structure and Local Geometry Inference**|Xiaoguang Han et.al.|[1709.07599v1](http://arxiv.org/abs/1709.07599v1)|8 pages paper, 11 pages supplementary material, ICCV spotlight paper|None|None|\n", "1709.05745": "|**2017-09-18**|**Joint Estimation of Camera Pose, Depth, Deblurring, and Super-Resolution from a Blurred Image Sequence**|Haesol Park et.al.|[1709.05745v1](http://arxiv.org/abs/1709.05745v1)|accepted to ICCV 2017|None|None|\n", "1708.07878": "|**2017-08-25**|**Stereo DSO: Large-Scale Direct Sparse Visual Odometry with Stereo Cameras**|Rui Wang et.al.|[1708.07878v1](http://arxiv.org/abs/1708.07878v1)|ICCV 2017|None|None|\n", "1705.09314": "|**2017-05-25**|**Plan3D: Viewpoint and Trajectory Optimization for Aerial Multi-View Stereo Reconstruction**|Benjamin Hepp et.al.|[1705.09314v2](http://arxiv.org/abs/1705.09314v2)|31 pages, 12 figures, 9 tables|None|None|\n", "1705.01010": "|**2017-05-02**|**Active Image-based Modeling with a Toy Drone**|Rui Huang et.al.|[1705.01010v3](http://arxiv.org/abs/1705.01010v3)|To be published on International Conference on Robotics and   Automation 2018, Brisbane, Australia. Project Page:   https://huangrui815.github.io/active-image-based-modeling/ The author's   personal page: http://www.sfu.ca/~rha55/|None|None|\n", "1705.00949": "|**2017-05-02**|**Scalable Surface Reconstruction from Point Clouds with Extreme Scale and Density Diversity**|Christian Mostegel et.al.|[1705.00949v1](http://arxiv.org/abs/1705.00949v1)|This paper was accepted to the IEEE Conference on Computer Vision and   Pattern Recognition (CVPR), 2017. The copyright was transfered to IEEE   (ieee.org). The official version of the paper will be made available on IEEE   Xplore (R) (ieeexplore.ieee.org). This version of the paper also contains the   supplementary material, which will not appear IEEE Xplore (R)|None|None|\n", "1701.06854": "|**2017-01-24**|**Improved Descriptors for Patch Matching and Reconstruction**|Rahul Mitra et.al.|[1701.06854v4](http://arxiv.org/abs/1701.06854v4)|9 pages, ICCV Workshop on Compact and Efficient Feature   Representation and Learning (CEFRL), 2017|None|None|\n", "1611.07245": "|**2016-11-22**|**Single-View and Multi-View Depth Fusion**|Jos\u00e9 M. F\u00e1cil et.al.|[1611.07245v2](http://arxiv.org/abs/1611.07245v2)|Accepted for publication in IEEE Robotics and Automation Letters|None|None|\n", "1610.04308": "|**2016-10-14**|**Recurrent 3D Attentional Networks for End-to-End Active Object Recognition**|Min Liu et.al.|[1610.04308v4](http://arxiv.org/abs/1610.04308v4)|None|None|None|\n", "1609.06536": "|**2016-09-21**|**Production-Level Facial Performance Capture Using Deep Convolutional Neural Networks**|Samuli Laine et.al.|[1609.06536v2](http://arxiv.org/abs/1609.06536v2)|Final SCA 2017 version|None|None|\n", "1609.01345": "|**2016-09-05**|**Efficient Volumetric Fusion of Airborne and Street-Side Data for Urban Reconstruction**|Andr\u00e1s B\u00f3dis-Szomor\u00fa et.al.|[1609.01345v1](http://arxiv.org/abs/1609.01345v1)|To appear in ICPR 2016|None|None|\n", "1605.01923": "|**2016-05-06**|**UAV-based Autonomous Image Acquisition with Multi-View Stereo Quality Assurance by Confidence Prediction**|Christian Mostegel et.al.|[1605.01923v1](http://arxiv.org/abs/1605.01923v1)|This paper was accepted to the 7th International Workshop on Computer   Vision in Vehicle Technology (CVVT 2016) and will appear in IEEE Conference   on Computer Vision and Pattern Recognition Workshops (CVPRW), 2016. The   copyright was transferred to IEEE (ieee.org). The paper will be available on   IEEE Xplore(ieeexplore.ieee.org). This version of the paper also contains the   supplementary material|None|None|\n", "1604.06258": "|**2016-04-21**|**Automatic 3D Reconstruction of Manifold Meshes via Delaunay Triangulation and Mesh Sweeping**|Andrea Romanoni et.al.|[1604.06258v1](http://arxiv.org/abs/1604.06258v1)|in IEEE Winter Conference on Applications of Computer Vision (WACV)   2016|None|None|\n", "1604.02885": "|**2016-04-11**|**Semantic 3D Reconstruction with Continuous Regularization and Ray Potentials Using a Visibility Consistency Constraint**|Nikolay Savinov et.al.|[1604.02885v3](http://arxiv.org/abs/1604.02885v3)|Accepted as a spotlight oral paper by CVPR 2016. Code at   https://github.com/nsavinov/ray_potentials/|None|**[link](https://github.com/nsavinov/ray_potentials)**|\n", "1505.00389": "|**2015-05-03**|**Detail-preserving and Content-aware Variational Multi-view Stereo Reconstruction**|Zhaoxin Li et.al.|[1505.00389v1](http://arxiv.org/abs/1505.00389v1)|14 pages,16 figures. Submitted to IEEE Transaction on image   processing|None|None|\n", "1503.04598": "|**2015-03-16**|**PiMPeR: Piecewise Dense 3D Reconstruction from Multi-View and Multi-Illumination Images**|Reza Sabzevari et.al.|[1503.04598v2](http://arxiv.org/abs/1503.04598v2)|None|None|None|\n"}, "Depth Estimation": {"2406.14226": "|**2024-06-20**|**Uncertainty and Self-Supervision in Single-View Depth**|Javier Rodriguez-Puigvert et.al.|[2406.14226v1](http://arxiv.org/abs/2406.14226v1)|Doctoral thesis|None|None|\n", "2406.13344": "|**2024-06-19**|**WaterMono: Teacher-Guided Anomaly Masking and Enhancement Boosting for Robust Underwater Self-Supervised Monocular Depth Estimation**|Yilin Ding et.al.|[2406.13344v1](http://arxiv.org/abs/2406.13344v1)|None|None|**[link](https://github.com/oucvisiongroup/watermono)**|\n", "2406.12849": "|**2024-06-18**|**Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation**|Ning-Hsu Wang et.al.|[2406.12849v1](http://arxiv.org/abs/2406.12849v1)|Project page: https://albert100121.github.io/Depth-Anywhere/|None|None|\n", "2406.12671": "|**2024-06-18**|**GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models**|Yongtao Ge et.al.|[2406.12671v2](http://arxiv.org/abs/2406.12671v2)|Code and Benchmark are available at:   https://github.com/aim-uofa/GeoBench|None|**[link](https://github.com/aim-uofa/geobench)**|\n", "2406.12095": "|**2024-06-17**|**DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features**|Letian Wang et.al.|[2406.12095v1](http://arxiv.org/abs/2406.12095v1)|None|None|None|\n", "2406.12048": "|**2024-06-17**|**MEDeA: Multi-view Efficient Depth Adjustment**|Mikhail Artemyev et.al.|[2406.12048v1](http://arxiv.org/abs/2406.12048v1)|None|None|None|\n", "2406.11003": "|**2024-06-16**|**3D Gaze Tracking for Studying Collaborative Interactions in Mixed-Reality Environments**|Eduardo Davalos et.al.|[2406.11003v1](http://arxiv.org/abs/2406.11003v1)|9 pages, 8 figures, conference, submitted to ICMI 2024|None|None|\n", "2406.10722": "|**2024-06-15**|**GenMM: Geometrically and Temporally Consistent Multimodal Data Generation for Video and LiDAR**|Bharat Singh et.al.|[2406.10722v1](http://arxiv.org/abs/2406.10722v1)|None|None|None|\n", "2406.10447": "|**2024-06-14**|**The BabyView dataset: High-resolution egocentric videos of infants' and young children's everyday experiences**|Bria Long et.al.|[2406.10447v1](http://arxiv.org/abs/2406.10447v1)|9 pages, 2 figures, 4 tables and SI. Submitted to NeurIPS Datasets   and Benchmarks|None|None|\n", "2406.10078": "|**2024-06-14**|**D-NPC: Dynamic Neural Point Clouds for Non-Rigid View Synthesis from Monocular Video**|Moritz Kappel et.al.|[2406.10078v1](http://arxiv.org/abs/2406.10078v1)|16 pages, 5 figures, 10 tables. Project page:   https://moritzkappel.github.io/projects/dnpc|None|None|\n", "2406.10068": "|**2024-06-14**|**DurLAR: A High-fidelity 128-channel LiDAR Dataset with Panoramic Ambient and Reflectivity Imagery for Multi-modal Autonomous Driving Applications**|Li Li et.al.|[2406.10068v1](http://arxiv.org/abs/2406.10068v1)|Accepted by 3DV 2021; 13 pages, 14 figures; Dataset at   https://github.com/l1997i/durlar|Proc. Int. Conf. on 3D Vision (3DV 2021)|**[link](https://github.com/l1997i/DurLAR)**|\n", "2406.09782": "|**2024-06-14**|**Unsupervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion**|Runze Liu et.al.|[2406.09782v1](http://arxiv.org/abs/2406.09782v1)|None|None|None|\n", "2406.09414": "|**2024-06-13**|**Depth Anything V2**|Lihe Yang et.al.|[2406.09414v1](http://arxiv.org/abs/2406.09414v1)|Project page: https://depth-anything-v2.github.io|None|**[link](https://github.com/DepthAnything/Depth-Anything-V2)**|\n", "2406.09394": "|**2024-06-13**|**WonderWorld: Interactive 3D Scene Generation from a Single Image**|Hong-Xing Yu et.al.|[2406.09394v2](http://arxiv.org/abs/2406.09394v2)|Project website: https://WonderWorld-2024.github.io/|None|None|\n", "2406.09374": "|**2024-06-13**|**Scale-Invariant Monocular Depth Estimation via SSI Depth**|S. Mahdi H. Miangoleh et.al.|[2406.09374v1](http://arxiv.org/abs/2406.09374v1)|To appear in Proc. SIGGRAPH, 2024. Project webpage:   https://yaksoy.github.io/sidepth/|None|None|\n", "2406.08928": "|**2024-06-13**|**Multiple Prior Representation Learning for Self-Supervised Monocular Depth Estimation via Hybrid Transformer**|Guodong Sun et.al.|[2406.08928v1](http://arxiv.org/abs/2406.08928v1)|28 pages, 12 figures|None|**[link](https://github.com/mvme-hbut/mprlnet)**|\n", "2406.08816": "|**2024-06-13**|**ToSA: Token Selective Attention for Efficient Vision Transformers**|Manish Kumar Singh et.al.|[2406.08816v1](http://arxiv.org/abs/2406.08816v1)|Accepted at CVPRW 2024|None|None|\n", "2406.07741": "|**2024-06-11**|**Back to the Color: Learning Depth to Specific Color Transformation for Unsupervised Depth Estimation**|Yufan Zhu et.al.|[2406.07741v2](http://arxiv.org/abs/2406.07741v2)|None|None|**[link](https://github.com/BlueEg/back2color)**|\n", "2406.07667": "|**2024-06-11**|**PLT-D3: A High-fidelity Dynamic Driving Simulation Dataset for Stereo Depth and Scene Flow**|Joshua Tokarsky et.al.|[2406.07667v1](http://arxiv.org/abs/2406.07667v1)|None|None|None|\n", "2406.07032": "|**2024-06-11**|**RS-DFM: A Remote Sensing Distributed Foundation Model for Diverse Downstream Tasks**|Zhechao Wang et.al.|[2406.07032v1](http://arxiv.org/abs/2406.07032v1)|None|None|None|\n", "2406.06679": "|**2024-06-10**|**PatchRefiner: Leveraging Synthetic Data for Real-Domain High-Resolution Monocular Metric Depth Estimation**|Zhenyu Li et.al.|[2406.06679v1](http://arxiv.org/abs/2406.06679v1)|None|None|None|\n", "2406.05857": "|**2024-06-09**|**Self-supervised Adversarial Training of Monocular Depth Estimation against Physical-World Attacks**|Zhiyuan Cheng et.al.|[2406.05857v1](http://arxiv.org/abs/2406.05857v1)|Accepted in TPAMI'24. Extended from our ICLR'23 publication   (arXiv:2301.13487). arXiv admin note: substantial text overlap with   arXiv:2301.13487|None|**[link](https://github.com/Bob-cheng/DepthModelHardening)**|\n", "2406.05852": "|**2024-06-09**|**RefGaussian: Disentangling Reflections from 3D Gaussian Splatting for Realistic Rendering**|Rui Zhang et.al.|[2406.05852v1](http://arxiv.org/abs/2406.05852v1)|None|None|None|\n", "2406.04861": "|**2024-06-07**|**Normal-guided Detail-Preserving Neural Implicit Functions for High-Fidelity 3D Surface Reconstruction**|Aarya Patel et.al.|[2406.04861v1](http://arxiv.org/abs/2406.04861v1)|Original version. Project page with images and code:   https://sn-nir.github.io/|None|None|\n", "2406.04647": "|**2024-06-07**|**UVCPNet: A UAV-Vehicle Collaborative Perception Network for 3D Object Detection**|Yuchao Wang et.al.|[2406.04647v1](http://arxiv.org/abs/2406.04647v1)|None|None|None|\n", "2406.04532": "|**2024-06-06**|**MambaDepth: Enhancing Long-range Dependency for Self-Supervised Fine-Structured Monocular Depth Estimation**|Ionu\u0163 Grigore et.al.|[2406.04532v1](http://arxiv.org/abs/2406.04532v1)|None|None|None|\n", "2406.04343": "|**2024-06-06**|**Flash3D: Feed-Forward Generalisable 3D Scene Reconstruction from a Single Image**|Stanislaw Szymanowicz et.al.|[2406.04343v1](http://arxiv.org/abs/2406.04343v1)|Project page: https://www.robots.ox.ac.uk/~vgg/research/flash3d/|None|None|\n", "2406.04301": "|**2024-06-06**|**Neural Surface Reconstruction from Sparse Views Using Epipolar Geometry**|Kaichen Zhou et.al.|[2406.04301v1](http://arxiv.org/abs/2406.04301v1)|None|None|None|\n", "2406.02552": "|**2024-06-04**|**VHS: High-Resolution Iterative Stereo Matching with Visual Hull Priors**|Markus Plack et.al.|[2406.02552v1](http://arxiv.org/abs/2406.02552v1)|None|None|None|\n", "2406.01843": "|**2024-06-03**|**L-MAGIC: Language Model Assisted Generation of Images with Coherence**|Zhipeng Cai et.al.|[2406.01843v1](http://arxiv.org/abs/2406.01843v1)|accepted to CVPR 2024|None|**[link](https://github.com/intellabs/mmpano)**|\n", "2406.01493": "|**2024-06-03**|**Learning Temporally Consistent Video Depth from Video Diffusion Priors**|Jiahao Shao et.al.|[2406.01493v2](http://arxiv.org/abs/2406.01493v2)|None|None|None|\n", "2406.00929": "|**2024-06-03**|**Self-Supervised Geometry-Guided Initialization for Robust Monocular Visual Odometry**|Takayuki Kanai et.al.|[2406.00929v1](http://arxiv.org/abs/2406.00929v1)|8 pages. 5 figures. This work has been submitted to the IEEE for   possible publication. Copyright may be transferred without notice, after   which this version may no longer be accessible|None|None|\n", "2406.00434": "|**2024-06-01**|**MoDGS: Dynamic Gaussian Splatting from Causually-captured Monocular Videos**|Qingming Liu et.al.|[2406.00434v1](http://arxiv.org/abs/2406.00434v1)|None|None|None|\n", "2405.19657": "|**2024-05-30**|**Uncertainty-guided Optimal Transport in Depth Supervised Sparse-View 3D Gaussian**|Wei Sun et.al.|[2405.19657v1](http://arxiv.org/abs/2405.19657v1)|10pages|None|None|\n", "2405.17704": "|**2024-05-27**|**Consistency Regularisation for Unsupervised Domain Adaptation in Monocular Depth Estimation**|Amir El-Ghoussani et.al.|[2405.17704v1](http://arxiv.org/abs/2405.17704v1)|Accepted to Conference on Lifelong Learning Agents (CoLLAs) 2024|None|None|\n", "2405.17426": "|**2024-05-27**|**Benchmarking and Improving Bird's Eye View Perception Robustness in Autonomous Driving**|Shaoyuan Xie et.al.|[2405.17426v1](http://arxiv.org/abs/2405.17426v1)|Preprint; 17 pages, 13 figures, 11 tables; Code at this https URL:   https://github.com/Daniel-xsy/RoboBEV|None|**[link](https://github.com/Daniel-xsy/RoboBEV)**|\n", "2405.17315": "|**2024-05-27**|**All-day Depth Completion**|Vadim Ezhov et.al.|[2405.17315v1](http://arxiv.org/abs/2405.17315v1)|8 pages, 4 figures|None|None|\n", "2405.17251": "|**2024-05-27**|**GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping**|Junyoung Seo et.al.|[2405.17251v1](http://arxiv.org/abs/2405.17251v1)|Project page: https://GenWarp-NVS.github.io|None|None|\n", "2405.17140": "|**2024-05-27**|**SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing**|Yong-Qiang Mao et.al.|[2405.17140v1](http://arxiv.org/abs/2405.17140v1)|None|None|None|\n", "2405.17102": "|**2024-05-27**|**DINO-SD: Champion Solution for ICRA 2024 RoboDepth Challenge**|Yifan Mao et.al.|[2405.17102v1](http://arxiv.org/abs/2405.17102v1)|Outstanding Champion in the RoboDepth Challenge (ICRA24)   https://robodrive-24.github.io/|None|None|\n", "2405.17097": "|**2024-05-27**|**Evaluation of Multi-task Uncertainties in Joint Semantic Segmentation and Monocular Depth Estimation**|Steven Landgraf et.al.|[2405.17097v1](http://arxiv.org/abs/2405.17097v1)|Submitted to Forum Bildverarbeitung 2024. arXiv admin note:   substantial text overlap with arXiv:2402.10580|None|None|\n", "2405.16960": "|**2024-05-27**|**DCPI-Depth: Explicitly Infusing Dense Correspondence Prior to Unsupervised Monocular Depth Estimation**|Mengtan Zhang et.al.|[2405.16960v1](http://arxiv.org/abs/2405.16960v1)|13 pages, 7 figures|None|None|\n", "2405.16873": "|**2024-05-27**|**ContrastAlign: Toward Robust BEV Feature Alignment via Contrastive Learning for Multi-Modal 3D Object Detection**|Ziying Song et.al.|[2405.16873v2](http://arxiv.org/abs/2405.16873v2)|None|None|None|\n", "2405.16858": "|**2024-05-27**|**Estimating Depth of Monocular Panoramic Image with Teacher-Student Model Fusing Equirectangular and Spherical Representations**|Jingguo Liu et.al.|[2405.16858v1](http://arxiv.org/abs/2405.16858v1)|None|None|None|\n", "2405.16544": "|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr\u00f6m et.al.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|21 pages|None|**[link](https://github.com/eriksandstroem/splat-slam)**|\n", "2405.15299": "|**2024-05-24**|**Transparent Object Depth Completion**|Yifan Zhou et.al.|[2405.15299v1](http://arxiv.org/abs/2405.15299v1)|None|None|None|\n", "2405.15176": "|**2024-05-24**|**MonoDETRNext: Next-generation Accurate and Efficient Monocular 3D Object Detection Method**|Pan Liao et.al.|[2405.15176v1](http://arxiv.org/abs/2405.15176v1)|None|None|None|\n", "2405.14959": "|**2024-05-23**|**EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting**|Jiaxu Wang et.al.|[2405.14959v2](http://arxiv.org/abs/2405.14959v2)|None|None|**[link](https://github.com/mercerai/evggs)**|\n", "2405.14520": "|**2024-05-23**|**Ghost-Stereo: GhostNet-based Cost Volume Enhancement and Aggregation for Stereo Matching Networks**|Xingguang Jiang et.al.|[2405.14520v1](http://arxiv.org/abs/2405.14520v1)|None|None|None|\n", "2405.14195": "|**2024-05-23**|**Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning**|Zhenyu Wei et.al.|[2405.14195v1](http://arxiv.org/abs/2405.14195v1)|None|None|None|\n", "2405.12759": "|**2024-05-21**|**Cross-spectral Gated-RGB Stereo Depth Estimation**|Samuel Brucker et.al.|[2405.12759v1](http://arxiv.org/abs/2405.12759v1)|None|None|None|\n", "2405.12006": "|**2024-05-20**|**Depth Reconstruction with Neural Signed Distance Fields in Structured Light Systems**|Rukun Qiao et.al.|[2405.12006v1](http://arxiv.org/abs/2405.12006v1)|10 pages, 8 figures, accepted by 3DV 2024|None|None|\n", "2405.11867": "|**2024-05-20**|**Depth Prompting for Sensor-Agnostic Depth Estimation**|Jin-Hwi Park et.al.|[2405.11867v1](http://arxiv.org/abs/2405.11867v1)|Accepted at CVPR 2024|None|None|\n", "2405.11564": "|**2024-05-19**|**CRF360D: Monocular 360 Depth Estimation via Spherical Fully-Connected CRFs**|Zidong Cao et.al.|[2405.11564v1](http://arxiv.org/abs/2405.11564v1)|None|None|None|\n", "2405.11158": "|**2024-05-18**|**Dusk Till Dawn: Self-supervised Nighttime Stereo Depth Estimation using Visual Foundation Models**|Madhu Vankadari et.al.|[2405.11158v1](http://arxiv.org/abs/2405.11158v1)|The paper is published at ICRA 2024|None|**[link](https://github.com/madhubabuv/dtd)**|\n", "2405.10575": "|**2024-05-17**|**Accurate Training Data for Occupancy Map Prediction in Automated Driving Using Evidence Theory**|Jonas K\u00e4lble et.al.|[2405.10575v1](http://arxiv.org/abs/2405.10575v1)|None|None|**[link](https://github.com/boschresearch/evidential-occupancy)**|\n", "2405.10244": "|**2024-05-16**|**Towards Task-Compatible Compressible Representations**|Anderson de Andrade et.al.|[2405.10244v1](http://arxiv.org/abs/2405.10244v1)|To be published in ICME Workshops 2024|None|**[link](https://github.com/adeandrade/research)**|\n", "2405.09964": "|**2024-05-16**|**KPNDepth: Depth Estimation of Lane Images under Complex Rainy Environment**|Zhengxu Shi et.al.|[2405.09964v1](http://arxiv.org/abs/2405.09964v1)|None|None|None|\n", "2405.08911": "|**2024-05-14**|**CLIP with Quality Captions: A Strong Pretraining for Vision Tasks**|Pavan Kumar Anasosalu Vasu et.al.|[2405.08911v1](http://arxiv.org/abs/2405.08911v1)|None|None|None|\n", "2405.08816": "|**2024-05-14**|**The RoboDrive Challenge: Drive Anytime Anywhere in Any Condition**|Lingdong Kong et.al.|[2405.08816v2](http://arxiv.org/abs/2405.08816v2)|ICRA 2024; 32 pages, 24 figures, 5 tables; Code at   https://robodrive-24.github.io/|None|None|\n", "2405.07847": "|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|None|None|None|\n", "2405.06749": "|**2024-05-10**|**Ensuring UAV Safety: A Vision-only and Real-time Framework for Collision Avoidance Through Object Detection, Tracking, and Distance Estimation**|Vasileios Karampinis et.al.|[2405.06749v2](http://arxiv.org/abs/2405.06749v2)|accepted at ICUAS 2024|None|None|\n", "2405.06241": "|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|This work has been submitted to the IEEE for possible publication.   Copyright may be transferred without notice, after which this version may no   longer be accessible|None|None|\n", "2405.03659": "|**2024-05-06**|**A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose**|Kaiwen Jiang et.al.|[2405.03659v2](http://arxiv.org/abs/2405.03659v2)|None|None|None|\n", "2405.02004": "|**2024-05-03**|**M${^2}$Depth: Self-supervised Two-Frame Multi-camera Metric Depth Estimation**|Yingshuang Zou et.al.|[2405.02004v1](http://arxiv.org/abs/2405.02004v1)|None|None|None|\n", "2405.01113": "|**2024-05-02**|**Domain-Transferred Synthetic Data Generation for Improving Monocular Depth Estimation**|Seungyeop Lee et.al.|[2405.01113v1](http://arxiv.org/abs/2405.01113v1)|None|None|None|\n", "2405.00630": "|**2024-05-01**|**Depth Priors in Removal Neural Radiance Fields**|Zhihao Guo et.al.|[2405.00630v2](http://arxiv.org/abs/2405.00630v2)|16 pages|None|None|\n", "2404.19758": "|**2024-04-30**|**Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting**|Paul Engstler et.al.|[2404.19758v1](http://arxiv.org/abs/2404.19758v1)|Project page: https://research.paulengstler.com/invisible-stitch/|None|None|\n", "2404.19294": "|**2024-04-30**|**Masked Spatial Propagation Network for Sparsity-Adaptive Depth Refinement**|Jinyoung Jun et.al.|[2404.19294v1](http://arxiv.org/abs/2404.19294v1)|None|None|**[link](https://github.com/jyjunmcl/mspn_sdr)**|\n", "2404.19015": "|**2024-04-29**|**Simple-RF: Regularizing Sparse Input Radiance Fields with Simpler Solutions**|Nagabhushan Somraj et.al.|[2404.19015v3](http://arxiv.org/abs/2404.19015v3)|The source code for our model can be found on our project page:   https://nagabhushansn95.github.io/publications/2024/Simple-RF.html. arXiv   admin note: substantial text overlap with arXiv:2309.03955|None|None|\n", "2404.17883": "|**2024-04-27**|**Underwater Variable Zoom: Depth-Guided Perception Network for Underwater Image Enhancement**|Zhixiong Huang et.al.|[2404.17883v3](http://arxiv.org/abs/2404.17883v3)|None|None|**[link](https://github.com/windysprint/uvz)**|\n", "2404.17335": "|**2024-04-26**|**A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation**|Xin Zhang et.al.|[2404.17335v2](http://arxiv.org/abs/2404.17335v2)|16 pages|None|None|\n", "2404.16831": "|**2024-04-25**|**The Third Monocular Depth Estimation Challenge**|Jaime Spencer et.al.|[2404.16831v2](http://arxiv.org/abs/2404.16831v2)|To appear in CVPRW2024|None|None|\n", "2404.16571": "|**2024-04-25**|**MonoPCC: Photometric-invariant Cycle Constraint for Monocular Depth Estimation of Endoscopic Images**|Zhiwei Wang et.al.|[2404.16571v2](http://arxiv.org/abs/2404.16571v2)|11 pages, 10 figures|None|None|\n", "2404.16386": "|**2024-04-25**|**Promoting CNNs with Cross-Architecture Knowledge Distillation for Efficient Monocular Depth Estimation**|Zhimeng Zheng et.al.|[2404.16386v1](http://arxiv.org/abs/2404.16386v1)|None|None|None|\n", "2404.14979": "|**2024-04-23**|**SGFormer: Spherical Geometry Transformer for 360 Depth Estimation**|Junsong Zhang et.al.|[2404.14979v1](http://arxiv.org/abs/2404.14979v1)|None|None|None|\n", "2404.14908": "|**2024-04-23**|**Mining Supervision for Dynamic Regions in Self-Supervised Monocular Depth Estimation**|Hoang Chuong Nguyen et.al.|[2404.14908v1](http://arxiv.org/abs/2404.14908v1)|Accepted to CVPR2024|None|**[link](https://github.com/hoangchuongnguyen/mono-consistent-depth)**|\n", "2404.13854": "|**2024-04-22**|**Self-Supervised Monocular Depth Estimation in the Dark: Towards Data Distribution Compensation**|Haolin Yang et.al.|[2404.13854v1](http://arxiv.org/abs/2404.13854v1)|Accepted by IJCAI2024|None|None|\n", "2404.13679": "|**2024-04-21**|**GScream: Learning 3D Geometry and Feature Consistent Gaussian Splatting for Object Removal**|Yuxin Wang et.al.|[2404.13679v1](http://arxiv.org/abs/2404.13679v1)|Project Page: https://w-ted.github.io/publications/gscream|None|None|\n", "2404.13437": "|**2024-04-20**|**High-fidelity Endoscopic Image Synthesis by Utilizing Depth-guided Neural Surfaces**|Baoru Huang et.al.|[2404.13437v1](http://arxiv.org/abs/2404.13437v1)|None|None|None|\n", "2404.12501": "|**2024-04-18**|**SPIdepth: Strengthened Pose Information for Self-supervised Monocular Depth Estimation**|Mykola Lavreniuk et.al.|[2404.12501v1](http://arxiv.org/abs/2404.12501v1)|None|None|None|\n", "2404.12390": "|**2024-04-18**|**BLINK: Multimodal Large Language Models Can See but Not Perceive**|Xingyu Fu et.al.|[2404.12390v3](http://arxiv.org/abs/2404.12390v3)|Multimodal Benchmark, Project Url: https://zeyofu.github.io/blink/|None|None|\n", "2404.10992": "|**2024-04-17**|**How to deal with glare for improved perception of Autonomous Vehicles**|Muhammad Z. Alam et.al.|[2404.10992v1](http://arxiv.org/abs/2404.10992v1)|14 pages, 9 figures, Accepted IEEE TIV|None|None|\n", "2404.09831": "|**2024-04-15**|**Digging into contrastive learning for robust depth estimation with diffusion models**|Jiyuan Wang et.al.|[2404.09831v3](http://arxiv.org/abs/2404.09831v3)|8 pages,6 figures|None|None|\n", "2404.09469": "|**2024-04-15**|**Virtually Enriched NYU Depth V2 Dataset for Monocular Depth Estimation: Do We Need Artificial Augmentation?**|Dmitry Ignatov et.al.|[2404.09469v1](http://arxiv.org/abs/2404.09469v1)|None|Proceedings of the IEEE Conference on Computer Vision and Pattern   Recognition Workshops, pages 6177-6186, 2024|**[link](https://github.com/abrain-one/anyu)**|\n", "2404.09308": "|**2024-04-14**|**In My Perspective, In My Hands: Accurate Egocentric 2D Hand Pose and Action Recognition**|Wiktor Mucha et.al.|[2404.09308v1](http://arxiv.org/abs/2404.09308v1)|Accepted at: The 18th IEEE International Conference on Automatic Face   and Gesture Recognition|None|None|\n", "2404.10534": "|**2024-04-12**|**Into the Fog: Evaluating Multiple Object Tracking Robustness**|Nadezda Kirillova et.al.|[2404.10534v1](http://arxiv.org/abs/2404.10534v1)|None|None|**[link](https://github.com/nadezola/intothefog_mot17)**|\n", "2404.08540": "|**2024-04-12**|**On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation**|Agneet Chatterjee et.al.|[2404.08540v1](http://arxiv.org/abs/2404.08540v1)|Accepted to CVPR 2024. Project webpage:   https://agneetchatterjee.com/robustness_depth_lang/|None|**[link](https://github.com/agneet42/robustness_depth_lang)**|\n", "2404.07686": "|**2024-04-11**|**Depth Estimation using Weighted-loss and Transfer Learning**|Muhammad Adeel Hafeez et.al.|[2404.07686v1](http://arxiv.org/abs/2404.07686v1)|None|None|None|\n", "2404.07603": "|**2024-04-11**|**GLID: Pre-training a Generalist Encoder-Decoder Vision Model**|Jihao Liu et.al.|[2404.07603v1](http://arxiv.org/abs/2404.07603v1)|CVPR 2024|None|None|\n", "2404.07600": "|**2024-04-11**|**Implicit and Explicit Language Guidance for Diffusion-based Visual Perception**|Hefeng Wang et.al.|[2404.07600v2](http://arxiv.org/abs/2404.07600v2)|None|None|None|\n", "2404.07545": "|**2024-04-11**|**Stereo-LiDAR Depth Estimation with Deformable Propagation and Learned Disparity-Depth Conversion**|Ang Li et.al.|[2404.07545v1](http://arxiv.org/abs/2404.07545v1)|Accepted in ICRA 2024. 8 pages, 6 figures|None|**[link](https://github.com/sjtu-visys/sdg-depth)**|\n", "2404.07176": "|**2024-04-10**|**Self-supervised Monocular Depth Estimation on Water Scenes via Specular Reflection Prior**|Zhengyang Lu et.al.|[2404.07176v1](http://arxiv.org/abs/2404.07176v1)|16 pages, 8 figures|None|None|\n", "2404.06753": "|**2024-04-10**|**MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D Reconstruction of Indoor Scenes from Monocular RGB Views**|Runfa Li et.al.|[2404.06753v1](http://arxiv.org/abs/2404.06753v1)|None|None|None|\n", "2404.06605": "|**2024-04-09**|**RoadBEV: Road Surface Reconstruction in Bird's Eye View**|Tong Zhao et.al.|[2404.06605v2](http://arxiv.org/abs/2404.06605v2)|Dataset page: https://thu-rsxd.com/rsrd Code:   https://github.com/ztsrxh/RoadBEV|None|**[link](https://github.com/ztsrxh/roadbev)**|\n", "2404.06425": "|**2024-04-09**|**ZeST: Zero-Shot Material Transfer from a Single Image**|Ta-Ying Cheng et.al.|[2404.06425v1](http://arxiv.org/abs/2404.06425v1)|Project Page: https://ttchengab.github.io/zest|None|None|\n", "2404.06337": "|**2024-04-09**|**Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences**|Axel Barroso-Laguna et.al.|[2404.06337v1](http://arxiv.org/abs/2404.06337v1)|None|Proceedings of the IEEE/CVF Conference on Computer Vision and   Pattern Recognition (CVPR), 2024|**[link](https://github.com/nianticlabs/mickey)**|\n", "2404.06165": "|**2024-04-09**|**Enhanced Radar Perception via Multi-Task Learning: Towards Refined Data for Sensor Fusion Applications**|Huawei Sun et.al.|[2404.06165v1](http://arxiv.org/abs/2404.06165v1)|Accepted by IEEE Intelligent Vehicles Symposium (IV 2024)|None|None|\n", "2404.06050": "|**2024-04-09**|**Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes**|Tianchen Deng et.al.|[2404.06050v1](http://arxiv.org/abs/2404.06050v1)|None|None|None|\n", "2404.04653": "|**2024-04-06**|**HawkDrive: A Transformer-driven Visual Perception System for Autonomous Driving in Night Scene**|Ziang Guo et.al.|[2404.04653v2](http://arxiv.org/abs/2404.04653v2)|Accepted by IEEE IV 2024|None|None|\n", "2404.04561": "|**2024-04-06**|**Co-Occ: Coupling Explicit Feature Fusion with Volume Rendering Regularization for Multi-Modal 3D Semantic Occupancy Prediction**|Jingyi Pan et.al.|[2404.04561v3](http://arxiv.org/abs/2404.04561v3)|Accepted by IEEE Robotics and Automation Letters (RA-L)|IEEE Robotics and Automation Letters, Volume 9 Issue 6, 5687 -   5694, June 2024|None|\n", "2404.04319": "|**2024-04-05**|**SpatialTracker: Tracking Any 2D Pixels in 3D Space**|Yuxi Xiao et.al.|[2404.04319v1](http://arxiv.org/abs/2404.04319v1)|Accepted to CVPR 2024 (selected as highlight paper). Project page:   https://henry123-boy.github.io/SpaTracker/|None|None|\n", "2404.03658": "|**2024-04-04**|**Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning**|Rui Li et.al.|[2404.03658v1](http://arxiv.org/abs/2404.03658v1)|CVPR 2024. Project page: https://ruili3.github.io/kyn|None|**[link](https://github.com/ruili3/Know-Your-Neighbors)**|\n", "2404.03656": "|**2024-04-04**|**MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation**|Hanzhe Hu et.al.|[2404.03656v1](http://arxiv.org/abs/2404.03656v1)|Project page: https://mvd-fusion.github.io/|None|None|\n", "2404.03635": "|**2024-04-04**|**WorDepth: Variational Language Prior for Monocular Depth Estimation**|Ziyao Zeng et.al.|[2404.03635v4](http://arxiv.org/abs/2404.03635v4)|None|None|**[link](https://github.com/adonis-galaxy/wordepth)**|\n", "2404.03190": "|**2024-04-04**|**Adaptive Discrete Disparity Volume for Self-supervised Monocular Depth Estimation**|Jianwei Ren et.al.|[2404.03190v1](http://arxiv.org/abs/2404.03190v1)|None|None|None|\n", "2404.03181": "|**2024-04-04**|**MonoCD: Monocular 3D Object Detection with Complementary Depths**|Longfei Yan et.al.|[2404.03181v1](http://arxiv.org/abs/2404.03181v1)|Accepted to CVPR 2024|None|**[link](https://github.com/elvintanhust/monocd)**|\n", "2404.02225": "|**2024-04-02**|**CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement**|Di Qiu et.al.|[2404.02225v1](http://arxiv.org/abs/2404.02225v1)|None|None|None|\n", "2404.01925": "|**2024-04-02**|**Improving Bird's Eye View Semantic Segmentation by Task Decomposition**|Tianhao Zhao et.al.|[2404.01925v1](http://arxiv.org/abs/2404.01925v1)|Accepted by CVPR 2024|None|None|\n", "2404.00924": "|**2024-04-01**|**BadPart: Unified Black-box Adversarial Patch Attacks against Pixel-wise Regression Tasks**|Zhiyuan Cheng et.al.|[2404.00924v3](http://arxiv.org/abs/2404.00924v3)|Paper accepted at ICML 2024|None|**[link](https://github.com/bob-cheng/badpart)**|\n", "2404.00923": "|**2024-04-01**|**MM3DGS SLAM: Multi-modal 3D Gaussian Splatting for SLAM Using Vision, Depth, and Inertial Measurements**|Lisong C. Sun et.al.|[2404.00923v1](http://arxiv.org/abs/2404.00923v1)|Project Webpage: https://vita-group.github.io/MM3DGS-SLAM|None|None|\n", "2404.00678": "|**2024-03-31**|**OmniSDF: Scene Reconstruction using Omnidirectional Signed Distance Functions and Adaptive Binoctrees**|Hakyeong Kim et.al.|[2404.00678v1](http://arxiv.org/abs/2404.00678v1)|None|Proceedings of the IEEE/CVF Conference on Computer Vision and   Pattern Recognition (CVPR) 2024|None|\n", "2404.00373": "|**2024-03-30**|**The Devil is in the Edges: Monocular Depth Estimation with Edge-aware Consistency Fusion**|Pengzhi Li et.al.|[2404.00373v1](http://arxiv.org/abs/2404.00373v1)|17 pages, 19 figures|None|None|\n", "2404.00360": "|**2024-03-30**|**Reusable Architecture Growth for Continual Stereo Matching**|Chenghao Zhang et.al.|[2404.00360v1](http://arxiv.org/abs/2404.00360v1)|Extended version of CVPR 2022 paper \"Continual Stereo Matching of   Continuous Driving Scenes with Growing Architecture\" - Accepted to TPAMI in   2024|None|None|\n", "2404.00345": "|**2024-03-30**|**MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview and Text**|Takayuki Hara et.al.|[2404.00345v1](http://arxiv.org/abs/2404.00345v1)|Project Page: https://hara012.github.io/MaGRITTe-project|None|None|\n", "2404.00149": "|**2024-03-29**|**VSRD: Instance-Aware Volumetric Silhouette Rendering for Weakly Supervised 3D Object Detection**|Zihua Liu et.al.|[2404.00149v1](http://arxiv.org/abs/2404.00149v1)|CVPR 2024|None|**[link](https://github.com/skmhrk1209/VSRD)**|\n", "2403.20034": "|**2024-03-29**|**NeSLAM: Neural Implicit Mapping and Self-Supervised Feature Tracking With Depth Completion and Denoising**|Tianchen Deng et.al.|[2403.20034v1](http://arxiv.org/abs/2403.20034v1)|None|None|**[link](https://github.com/dtc111111/neslam)**|\n", "2403.19549": "|**2024-03-28**|**GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM**|Ganlin Zhang et.al.|[2403.19549v3](http://arxiv.org/abs/2403.19549v3)|None|None|**[link](https://github.com/zhangganlin/gloire-slam)**|\n", "2403.19495": "|**2024-03-28**|**CoherentGS: Sparse Novel View Synthesis with Coherent 3D Gaussians**|Avinash Paliwal et.al.|[2403.19495v1](http://arxiv.org/abs/2403.19495v1)|Project page: https://people.engr.tamu.edu/nimak/Papers/CoherentGS|None|None|\n", "2403.19294": "|**2024-03-28**|**FlowDepth: Decoupling Optical Flow for Self-Supervised Monocular Depth Estimation**|Yiyang Sun et.al.|[2403.19294v1](http://arxiv.org/abs/2403.19294v1)|None|None|None|\n", "2403.19265": "|**2024-03-28**|**Neural Fields for 3D Tracking of Anatomy and Surgical Instruments in Monocular Laparoscopic Video Clips**|Beerend G. A. Gerats et.al.|[2403.19265v1](http://arxiv.org/abs/2403.19265v1)|None|None|None|\n", "2403.18913": "|**2024-03-27**|**UniDepth: Universal Monocular Metric Depth Estimation**|Luigi Piccinelli et.al.|[2403.18913v1](http://arxiv.org/abs/2403.18913v1)|None|None|**[link](https://github.com/lpiccinelli-eth/unidepth)**|\n", "2403.18807": "|**2024-03-27**|**ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation**|Suraj Patni et.al.|[2403.18807v4](http://arxiv.org/abs/2403.18807v4)|IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)   2024|None|**[link](https://github.com/aradhye2002/ecodepth)**|\n", "2403.18762": "|**2024-03-27**|**ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place Recognition**|Weidong Xie et.al.|[2403.18762v1](http://arxiv.org/abs/2403.18762v1)|8 pages, 11 figures, conference|None|**[link](https://github.com/haomo-ai/modalink)**|\n", "2403.18443": "|**2024-03-27**|**$\\mathrm{F^2Depth}$: Self-supervised Indoor Monocular Depth Estimation via Optical Flow Consistency and Feature Map Synthesis**|Xiaotong Guo et.al.|[2403.18443v1](http://arxiv.org/abs/2403.18443v1)|None|None|None|\n", "2403.17931": "|**2024-03-26**|**Track Everything Everywhere Fast and Robustly**|Yunzhou Song et.al.|[2403.17931v1](http://arxiv.org/abs/2403.17931v1)|project page: https://timsong412.github.io/FastOmniTrack/|None|None|\n", "2403.17915": "|**2024-03-26**|**Leveraging Near-Field Lighting for Monocular Depth Estimation from Endoscopy Videos**|Akshay Paruchuri et.al.|[2403.17915v1](http://arxiv.org/abs/2403.17915v1)|26 pages, 7 tables, 7 figures|None|None|\n", "2403.17822": "|**2024-03-26**|**DN-Splatter: Depth and Normal Priors for Gaussian Splatting and Meshing**|Matias Turkulainen et.al.|[2403.17822v1](http://arxiv.org/abs/2403.17822v1)|None|None|**[link](https://github.com/maturk/dn-splatter)**|\n", "2403.17301": "|**2024-03-26**|**Physical 3D Adversarial Attacks against Monocular Depth Estimation in Autonomous Driving**|Junhao Zheng et.al.|[2403.17301v2](http://arxiv.org/abs/2403.17301v2)|Accepted by CVPR 2024|None|**[link](https://github.com/gandolfczjh/3d2fool)**|\n", "2403.16410": "|**2024-03-25**|**Spike-NeRF: Neural Radiance Field Based On Spike Camera**|Yijia Guo et.al.|[2403.16410v1](http://arxiv.org/abs/2403.16410v1)|This paper is accepted by ICME2024|None|None|\n", "2403.16376": "|**2024-03-25**|**Elite360D: Towards Efficient 360 Depth Estimation via Semantic- and Distance-Aware Bi-Projection Fusion**|Hao Ai et.al.|[2403.16376v2](http://arxiv.org/abs/2403.16376v2)|8 pages, accepted by CVPR2024|None|None|\n", "2405.01558": "|**2024-03-24**|**Configurable Learned Holography**|Yicheng Zhan et.al.|[2405.01558v2](http://arxiv.org/abs/2405.01558v2)|14 pages, 5 figures|None|None|\n", "2403.15787": "|**2024-03-23**|**Depth Estimation fusing Image and Radar Measurements with Uncertain Directions**|Masaya Kotani et.al.|[2403.15787v1](http://arxiv.org/abs/2403.15787v1)|Accepted to IJCNN 2024 (International Joint Conference on Neural   Networks)|None|None|\n", "2403.15551": "|**2024-03-22**|**Language-Based Depth Hints for Monocular Depth Estimation**|Dylan Auty et.al.|[2403.15551v1](http://arxiv.org/abs/2403.15551v1)|8 pages, 1 figure. Work originally done in June 2022|None|None|\n", "2404.15506": "|**2024-03-22**|**Metric3D v2: A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface Normal Estimation**|Mu Hu et.al.|[2404.15506v1](http://arxiv.org/abs/2404.15506v1)|Our project page is at https://JUGGHM.github.io/Metric3Dv2. arXiv   admin note: substantial text overlap with arXiv:2307.10984|None|None|\n", "2403.14494": "|**2024-03-21**|**Learning to Project for Cross-Task Knowledge Distillation**|Dylan Auty et.al.|[2403.14494v1](http://arxiv.org/abs/2403.14494v1)|None|None|None|\n", "2403.13788": "|**2024-03-20**|**DepthFM: Fast Monocular Depth Estimation with Flow Matching**|Ming Gui et.al.|[2403.13788v1](http://arxiv.org/abs/2403.13788v1)|None|None|None|\n", "2403.13043": "|**2024-03-19**|**When Do We Not Need Larger Vision Models?**|Baifeng Shi et.al.|[2403.13043v1](http://arxiv.org/abs/2403.13043v1)|Code: https://github.com/bfshi/scaling_on_scales|None|**[link](https://github.com/bfshi/scaling_on_scales)**|\n", "2403.12953": "|**2024-03-19**|**FutureDepth: Learning to Predict the Future Improves Video Depth Estimation**|Rajeev Yasarla et.al.|[2403.12953v1](http://arxiv.org/abs/2403.12953v1)|None|None|None|\n", "2403.12431": "|**2024-03-19**|**Geometric Constraints in Deep Learning Frameworks: A Survey**|Vibhas K Vats et.al.|[2403.12431v1](http://arxiv.org/abs/2403.12431v1)|A preprint|None|None|\n", "2403.11848": "|**2024-03-18**|**GraphBEV: Towards Robust BEV Feature Alignment for Multi-Modal 3D Object Detection**|Ziying Song et.al.|[2403.11848v2](http://arxiv.org/abs/2403.11848v2)|None|None|None|\n", "2403.11515": "|**2024-03-18**|**SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption of Monocular Depth Estimation in Autonomous Navigation Applications**|Amira Guesmi et.al.|[2403.11515v1](http://arxiv.org/abs/2403.11515v1)|None|None|None|\n", "2403.11270": "|**2024-03-17**|**Bilateral Propagation Network for Depth Completion**|Jie Tang et.al.|[2403.11270v2](http://arxiv.org/abs/2403.11270v2)|Accepted by CVPR 2024|None|**[link](https://github.com/kakaxi314/bp-net)**|\n", "2403.10662": "|**2024-03-15**|**SwinMTL: A Shared Architecture for Simultaneous Depth Estimation and Semantic Segmentation from Monocular Camera Images**|Pardis Taghavi et.al.|[2403.10662v1](http://arxiv.org/abs/2403.10662v1)|None|None|**[link](https://github.com/pardistaghavi/swinmtl)**|\n", "2403.10452": "|**2024-03-15**|**Robust Shape Fitting for 3D Scene Abstraction**|Florian Kluger et.al.|[2403.10452v1](http://arxiv.org/abs/2403.10452v1)|Accepted for publication in Transactions on Pattern Analysis and   Machine Intelligence (PAMI). arXiv admin note: substantial text overlap with   arXiv:2105.02047|None|**[link](https://github.com/fkluger/cuboids_revisited)**|\n", "2403.10252": "|**2024-03-15**|**Region-aware Distribution Contrast: A Novel Approach to Multi-Task Partially Supervised Learning**|Meixuan Li et.al.|[2403.10252v1](http://arxiv.org/abs/2403.10252v1)|None|None|None|\n", "2403.09230": "|**2024-03-14**|**Improving Distant 3D Object Detection Using 2D Box Supervision**|Zetong Yang et.al.|[2403.09230v1](http://arxiv.org/abs/2403.09230v1)|Accepted by CVPR 2024|None|None|\n", "2403.08556": "|**2024-03-13**|**SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model**|Yihao Liu et.al.|[2403.08556v1](http://arxiv.org/abs/2403.08556v1)|Project Page: xuefeng-cvr.github.io/SM4Depth|None|**[link](https://github.com/1hao-liu/sm4depth)**|\n", "2403.08368": "|**2024-03-13**|**METER: a mobile vision transformer architecture for monocular depth estimation**|L. Papa et.al.|[2403.08368v1](http://arxiv.org/abs/2403.08368v1)|None|IEEE Transactions on Circuits and Systems for Video Technology,   2023|**[link](https://github.com/lorenzopapa5/meter)**|\n", "2403.08125": "|**2024-03-12**|**Q-SLAM: Quadric Representations for Monocular SLAM**|Chensheng Peng et.al.|[2403.08125v1](http://arxiv.org/abs/2403.08125v1)|None|None|None|\n", "2403.07535": "|**2024-03-12**|**Adaptive Fusion of Single-View and Multi-View Depth for Autonomous Driving**|JunDa Cheng et.al.|[2403.07535v1](http://arxiv.org/abs/2403.07535v1)|Accepted to CVPR 2024|None|**[link](https://github.com/junda24/afnet)**|\n", "2403.07516": "|**2024-03-12**|**D4D: An RGBD diffusion model to boost monocular depth estimation**|L. Papa et.al.|[2403.07516v1](http://arxiv.org/abs/2403.07516v1)|None|None|**[link](https://github.com/lorenzopapa5/diffusion4d)**|\n", "2403.07326": "|**2024-03-12**|**SGE: Structured Light System Based on Gray Code with an Event Camera**|Xingyu Lu et.al.|[2403.07326v1](http://arxiv.org/abs/2403.07326v1)|None|None|None|\n", "2403.06529": "|**2024-03-11**|**Confidence-Aware RGB-D Face Recognition via Virtual Depth Synthesis**|Zijian Chen et.al.|[2403.06529v2](http://arxiv.org/abs/2403.06529v2)|9 pages, 5 figures|None|None|\n", "2403.05895": "|**2024-03-09**|**DO3D: Self-supervised Learning of Decomposed Object-aware 3D Motion and Depth from Monocular Videos**|Xiuzhe Wu et.al.|[2403.05895v1](http://arxiv.org/abs/2403.05895v1)|24 pages, 14 figures, Tech Report|None|None|\n", "2403.05329": "|**2024-03-08**|**OccFusion: Depth Estimation Free Multi-sensor Fusion for 3D Occupancy Prediction**|Ji Zhang et.al.|[2403.05329v1](http://arxiv.org/abs/2403.05329v1)|None|None|None|\n", "2403.05056": "|**2024-03-08**|**Stealing Stable Diffusion Prior for Robust Monocular Depth Estimation**|Yifan Mao et.al.|[2403.05056v1](http://arxiv.org/abs/2403.05056v1)|None|None|**[link](https://github.com/hitcslj/ssd)**|\n", "2403.03468": "|**2024-03-06**|**Multi-task Learning for Real-time Autonomous Driving Leveraging Task-adaptive Attention Generator**|Wonhyeok Choi et.al.|[2403.03468v1](http://arxiv.org/abs/2403.03468v1)|Accepted at ICRA 2024|None|None|\n", "2403.03408": "|**2024-03-06**|**Scene Depth Estimation from Traditional Oriental Landscape Paintings**|Sungho Kang et.al.|[2403.03408v2](http://arxiv.org/abs/2403.03408v2)|None|None|None|\n", "2403.02037": "|**2024-03-04**|**Scalable Vision-Based 3D Object Detection and Monocular Depth Estimation for Autonomous Driving**|Yuxuan Liu et.al.|[2403.02037v1](http://arxiv.org/abs/2403.02037v1)|HKUST PhD Thesis; https://github.com/Owen-Liuyuxuan/visionfactory|None|**[link](https://github.com/owen-liuyuxuan/visionfactory)**|\n", "2403.01683": "|**2024-03-04**|**DD-VNB: A Depth-based Dual-Loop Framework for Real-time Visually Navigated Bronchoscopy**|Qingyao Tian et.al.|[2403.01683v2](http://arxiv.org/abs/2403.01683v2)|None|None|None|\n", "2403.01569": "|**2024-03-03**|**Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV**|Jaime Spencer et.al.|[2403.01569v1](http://arxiv.org/abs/2403.01569v1)|None|None|**[link](https://github.com/jspenmar/slowtv_monodepth)**|\n", "2403.01440": "|**2024-03-03**|**Pyramid Feature Attention Network for Monocular Depth Prediction**|Yifang Xu et.al.|[2403.01440v1](http://arxiv.org/abs/2403.01440v1)|6 pages, 5 figures|None|None|\n", "2403.01370": "|**2024-03-03**|**Depth Estimation Algorithm Based on Transformer-Encoder and Feature Fusion**|Linhan Xia et.al.|[2403.01370v1](http://arxiv.org/abs/2403.01370v1)|ICAACE2024|None|None|\n", "2403.01105": "|**2024-03-02**|**Depth Information Assisted Collaborative Mutual Promotion Network for Single Image Dehazing**|Yafei Zhang et.al.|[2403.01105v1](http://arxiv.org/abs/2403.01105v1)|None|None|**[link](https://github.com/zhoushen1/diacmpn)**|\n", "2402.18925": "|**2024-02-29**|**PCDepth: Pattern-based Complementary Learning for Monocular Depth Estimation by Best of Both Worlds**|Haotian Liu et.al.|[2402.18925v1](http://arxiv.org/abs/2402.18925v1)|Under Review|None|None|\n", "2402.18181": "|**2024-02-28**|**CFDNet: A Generalizable Foggy Stereo Matching Network with Contrastive Feature Distillation**|Zihua Liu et.al.|[2402.18181v2](http://arxiv.org/abs/2402.18181v2)|None|IEEE International Conference on Robotics and Automation   (ICRA2024)|None|\n", "2402.18175": "|**2024-02-28**|**Self-Supervised Spatially Variant PSF Estimation for Aberration-Aware Depth-from-Defocus**|Zhuofeng Wu et.al.|[2402.18175v1](http://arxiv.org/abs/2402.18175v1)|None|International Conference on Acoustics, Speech, and Signal   Processing (ICASSP), 2024|None|\n", "2402.17319": "|**2024-02-27**|**A Vanilla Multi-Task Framework for Dense Visual Prediction Solution to 1st VCL Challenge -- Multi-Task Robustness Track**|Zehui Chen et.al.|[2402.17319v1](http://arxiv.org/abs/2402.17319v1)|Technical Report|None|None|\n", "2402.14354": "|**2024-02-22**|**GAM-Depth: Self-Supervised Indoor Depth Estimation Leveraging a Gradient-Aware Mask and Semantic Constraints**|Anqi Cheng et.al.|[2402.14354v1](http://arxiv.org/abs/2402.14354v1)|To be published in 2024 IEEE International Conference on Robotics and   Automation (ICRA)|None|**[link](https://github.com/anqicheng1234/gam-depth)**|\n", "2402.14340": "|**2024-02-22**|**TIE-KD: Teacher-Independent and Explainable Knowledge Distillation for Monocular Depth Estimation**|Sangwon Choi et.al.|[2402.14340v1](http://arxiv.org/abs/2402.14340v1)|13 pages, 8 figures, under review for a journal|None|**[link](https://github.com/hpc-lab-koreatech/tie-kd)**|\n", "2402.13848": "|**2024-02-21**|**Zero-BEV: Zero-shot Projection of Any First-Person Modality to BEV Maps**|Gianluca Monaci et.al.|[2402.13848v2](http://arxiv.org/abs/2402.13848v2)|None|None|None|\n", "2402.11840": "|**2024-02-19**|**An Endoscopic Chisel: Intraoperative Imaging Carves 3D Anatomical Models**|Jan Emily Mangulabnan et.al.|[2402.11840v1](http://arxiv.org/abs/2402.11840v1)|None|None|None|\n", "2402.11826": "|**2024-02-19**|**Unveiling the Depths: A Multi-Modal Fusion Framework for Challenging Scenarios**|Jialei Xu et.al.|[2402.11826v1](http://arxiv.org/abs/2402.11826v1)|None|None|None|\n", "2402.11791": "|**2024-02-19**|**SDGE: Stereo Guided Depth Estimation for 360$^\\circ$ Camera Sets**|Jialei Xu et.al.|[2402.11791v4](http://arxiv.org/abs/2402.11791v4)|None|None|None|\n", "2402.11507": "|**2024-02-18**|**MAL: Motion-Aware Loss with Temporal and Distillation Hints for Self-Supervised Depth Estimation**|Yup-Jiang Dong et.al.|[2402.11507v1](http://arxiv.org/abs/2402.11507v1)|Accepted by ICRA 2024; Project homepage:   https://yuejiangdong.github.io/MotionAwareLoss/|None|None|\n", "2402.10580": "|**2024-02-16**|**Efficient Multi-task Uncertainties for Joint Semantic Segmentation and Monocular Depth Estimation**|Steven Landgraf et.al.|[2402.10580v1](http://arxiv.org/abs/2402.10580v1)|17 pages, 5 figures, 10 tables, submitted to peer-reviewed journal|None|None|\n", "2402.10061": "|**2024-02-15**|**X-maps: Direct Depth Lookup for Event-based Structured Light Systems**|Wieland Morgenstern et.al.|[2402.10061v1](http://arxiv.org/abs/2402.10061v1)|Accepted at the CVPR 2023 Workshop on Event-based Vision:   https://tub-rip.github.io/eventvision2023/|2023 IEEE/CVF Conference on Computer Vision and Pattern   Recognition Workshops (CVPRW), Vancouver, BC, Canada, 2023, pp. 4007-4015|None|\n", "2402.08931": "|**2024-02-14**|**Depth-aware Volume Attention for Texture-less Stereo Matching**|Tong Zhao et.al.|[2402.08931v2](http://arxiv.org/abs/2402.08931v2)|10 pages, 6 figures|None|**[link](https://github.com/ztsrxh/DVANet)**|\n", "2402.06539": "|**2024-02-09**|**Hybridnet for depth estimation and semantic segmentation**|Dalila S\u00e1nchez-Escobedo et.al.|[2402.06539v1](http://arxiv.org/abs/2402.06539v1)|2018 IEEE International Conference on Acoustics, Speech and Signal   Processing (ICASSP). IEEE, 2018|None|None|\n", "2402.05869": "|**2024-02-08**|**Adaptive Surface Normal Constraint for Geometric Estimation from Monocular Images**|Xiaoxiao Long et.al.|[2402.05869v2](http://arxiv.org/abs/2402.05869v2)|Accepted by TPAMI. arXiv admin note: substantial text overlap with   arXiv:2103.15483|None|None|\n", "2402.04883": "|**2024-02-07**|**Toward Accurate Camera-based 3D Object Detection via Cascade Depth Estimation and Calibration**|Chaoqun Wang et.al.|[2402.04883v1](http://arxiv.org/abs/2402.04883v1)|Accepted to ICRA2024|None|None|\n", "2402.03795": "|**2024-02-06**|**Energy-based Domain-Adaptive Segmentation with Depth Guidance**|Jinjing Zhu et.al.|[2402.03795v1](http://arxiv.org/abs/2402.03795v1)|None|None|None|\n", "2402.03762": "|**2024-02-06**|**MoD-SLAM: Monocular Dense Mapping for Unbounded 3D Scene Reconstruction**|Heng Zhou et.al.|[2402.03762v5](http://arxiv.org/abs/2402.03762v5)|None|None|None|\n", "2402.03501": "|**2024-02-05**|**An Inpainting-Infused Pipeline for Attire and Background Replacement**|Felipe Rodrigues Perche-Mahlow et.al.|[2402.03501v1](http://arxiv.org/abs/2402.03501v1)|None|None|None|\n", "2402.03251": "|**2024-02-05**|**CLIP Can Understand Depth**|Dunam Kim et.al.|[2402.03251v1](http://arxiv.org/abs/2402.03251v1)|None|None|None|\n", "2402.02096": "|**2024-02-03**|**Decomposition-based and Interference Perception for Infrared and Visible Image Fusion in Complex Scenes**|Xilai Li et.al.|[2402.02096v1](http://arxiv.org/abs/2402.02096v1)|None|None|None|\n", "2402.02067": "|**2024-02-03**|**RIDERS: Radar-Infrared Depth Estimation for Robust Sensing**|Han Li et.al.|[2402.02067v1](http://arxiv.org/abs/2402.02067v1)|13 pages, 13 figures|None|**[link](https://github.com/mmocking/riders)**|\n", "2402.01915": "|**2024-02-02**|**Robust Inverse Graphics via Probabilistic Inference**|Tuan Anh Le et.al.|[2402.01915v2](http://arxiv.org/abs/2402.01915v2)|ICML submission. Reworked main body, new appendix figures|None|**[link](https://github.com/tensorflow/probability)**|\n", "2402.01456": "|**2024-02-02**|**Convolution kernel adaptation to calibrated fisheye**|Bruno Berenguel-Baeta et.al.|[2402.01456v1](http://arxiv.org/abs/2402.01456v1)|Previously presented at BMVC: https://proceedings.bmvc2023.org/721/|None|**[link](https://github.com/sbrunoberenguel/calibratedconvolutions)**|\n", "2402.00575": "|**2024-02-01**|**Diffusion-based Light Field Synthesis**|Ruisheng Gao et.al.|[2402.00575v1](http://arxiv.org/abs/2402.00575v1)|11 pages,9 figures|None|None|\n", "2401.16600": "|**2024-01-29**|**Depth Anything in Medical Images: A Comparative Study**|John J. Han et.al.|[2401.16600v1](http://arxiv.org/abs/2401.16600v1)|10 pages, 2 figures, 3 tables|None|None|\n", "2401.16416": "|**2024-01-29**|**Endo-4DGS: Endoscopic Monocular Scene Reconstruction with 4D Gaussian Splatting**|Yiming Huang et.al.|[2401.16416v4](http://arxiv.org/abs/2401.16416v4)|None|None|**[link](https://github.com/lastbasket/endo-4dgs)**|\n", "2401.14401": "|**2024-01-25**|**Range-Agnostic Multi-View Depth Estimation With Keyframe Selection**|Andrea Conti et.al.|[2401.14401v1](http://arxiv.org/abs/2401.14401v1)|3DV 2024 Project Page   https://andreaconti.github.io/projects/range_agnostic_multi_view_depth GitHub   Page https://github.com/andreaconti/ramdepth.git|None|**[link](https://github.com/andreaconti/ramdepth)**|\n", "2401.13786": "|**2024-01-24**|**FoVA-Depth: Field-of-View Agnostic Depth Estimation for Cross-Dataset Generalization**|Daniel Lichy et.al.|[2401.13786v1](http://arxiv.org/abs/2401.13786v1)|3DV 2024 (Oral); Project Website:   https://research.nvidia.com/labs/lpr/fova-depth/|None|None|\n", "2401.12561": "|**2024-01-23**|**EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction**|Yifan Liu et.al.|[2401.12561v2](http://arxiv.org/abs/2401.12561v2)|None|None|**[link](https://github.com/yifliu3/EndoGaussian)**|\n", "2401.12422": "|**2024-01-23**|**InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D Occupancy Prediction**|Zhenxing Ming et.al.|[2401.12422v2](http://arxiv.org/abs/2401.12422v2)|None|None|**[link](https://github.com/danielming123/inversematrixvt3d)**|\n", "2401.12414": "|**2024-01-23**|**Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling Autonomy**|Ramchander Bhaskara et.al.|[2401.12414v1](http://arxiv.org/abs/2401.12414v1)|Software: https://github.com/nasa-jpl/guiss. IEEE Aerospace   Conference 2024|None|**[link](https://github.com/nasa-jpl/guiss)**|\n", "2401.12019": "|**2024-01-22**|**Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered by Multiple Disparity Consistency**|Woonghyun Ka et.al.|[2401.12019v2](http://arxiv.org/abs/2401.12019v2)|ICASSP 2024. The first two authors are equally contributed|None|None|\n", "2401.11673": "|**2024-01-22**|**MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo**|Chenjie Cao et.al.|[2401.11673v1](http://arxiv.org/abs/2401.11673v1)|Accepted to ICLR2024|ICLR(International Conference on Learning Representations) 2024|**[link](https://github.com/maybelx/mvsformerplusplus)**|\n", "2401.10891": "|**2024-01-19**|**Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data**|Lihe Yang et.al.|[2401.10891v2](http://arxiv.org/abs/2401.10891v2)|Accepted by CVPR 2024. Project page: https://depth-anything.github.io|None|**[link](https://github.com/LiheYoung/Depth-Anything)**|\n", "2401.07218": "|**2024-01-14**|**Self-supervised Event-based Monocular Depth Estimation using Cross-modal Consistency**|Junyu Zhu et.al.|[2401.07218v1](http://arxiv.org/abs/2401.07218v1)|Accepted by IROS2023|None|None|\n", "2401.06278": "|**2024-01-11**|**A Study on Self-Supervised Pretraining for Vision Problems in Gastrointestinal Endoscopy**|Edward Sanderson et.al.|[2401.06278v2](http://arxiv.org/abs/2401.06278v2)|None|None|**[link](https://github.com/esandml/ssl4gie)**|\n", "2401.06013": "|**2024-01-11**|**Surgical-DINO: Adapter Learning of Foundation Models for Depth Estimation in Endoscopic Surgery**|Beilei Cui et.al.|[2401.06013v2](http://arxiv.org/abs/2401.06013v2)|Accepted by IPCAI 2024 (IJCAR Special Issue)|None|**[link](https://github.com/beileicui/surgicaldino)**|\n", "2401.05335": "|**2024-01-10**|**InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes**|Mohamad Shahbazi et.al.|[2401.05335v1](http://arxiv.org/abs/2401.05335v1)|None|None|None|\n", "2401.04325": "|**2024-01-09**|**RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale**|Han Li et.al.|[2401.04325v2](http://arxiv.org/abs/2401.04325v2)|None|None|**[link](https://github.com/mmocking/radarcam-depth)**|\n", "2401.03771": "|**2024-01-08**|**NeRFmentation: NeRF-based Augmentation for Monocular Depth Estimation**|Casimir Feldmann et.al.|[2401.03771v1](http://arxiv.org/abs/2401.03771v1)|None|None|None|\n", "2401.03203": "|**2024-01-06**|**Hi-Map: Hierarchical Factorized Radiance Field for High-Fidelity Monocular Dense Mapping**|Tongyan Hua et.al.|[2401.03203v1](http://arxiv.org/abs/2401.03203v1)|None|None|None|\n", "2401.01075": "|**2024-01-02**|**Depth-discriminative Metric Learning for Monocular 3D Object Detection**|Wonhyeok Choi et.al.|[2401.01075v1](http://arxiv.org/abs/2401.01075v1)|Accepted at NeurIPS 2023|None|None|\n", "2401.00604": "|**2023-12-31**|**SteinDreamer: Variance Reduction for Text-to-3D Score Distillation via Stein Identity**|Peihao Wang et.al.|[2401.00604v2](http://arxiv.org/abs/2401.00604v2)|Project page: https://vita-group.github.io/SteinDreamer/|None|None|\n", "2312.15970": "|**2023-12-26**|**Learning Deformable Hypothesis Sampling for Accurate PatchMatch Multi-View Stereo**|Hongjie Li et.al.|[2312.15970v1](http://arxiv.org/abs/2312.15970v1)|None|None|**[link](https://github.com/geo-tell/ds-pmnet)**|\n", "2312.15268": "|**2023-12-23**|**MGDepth: Motion-Guided Cost Volume For Self-Supervised Monocular Depth In Dynamic Scenarios**|Kaichen Zhou et.al.|[2312.15268v1](http://arxiv.org/abs/2312.15268v1)|None|None|None|\n", "2312.14919": "|**2023-12-22**|**Lift-Attend-Splat: Bird's-eye-view camera-lidar fusion using transformers**|James Gunn et.al.|[2312.14919v3](http://arxiv.org/abs/2312.14919v3)|Updated method figure; camera ready|None|None|\n", "2312.14733": "|**2023-12-22**|**Harnessing Diffusion Models for Visual Perception with Meta Prompts**|Qiang Wan et.al.|[2312.14733v1](http://arxiv.org/abs/2312.14733v1)|None|None|**[link](https://github.com/fudan-zvg/meta-prompts)**|\n", "2312.14697": "|**2023-12-22**|**Pola4All: survey of polarimetric applications and an open-source toolkit to analyze polarization**|Joaquin Rodriguez et.al.|[2312.14697v1](http://arxiv.org/abs/2312.14697v1)|None|None|**[link](https://github.com/vibot-lab/pola4all_jei_2023)**|\n", "2312.14132": "|**2023-12-21**|**DUSt3R: Geometric 3D Vision Made Easy**|Shuzhe Wang et.al.|[2312.14132v1](http://arxiv.org/abs/2312.14132v1)|None|None|**[link](https://github.com/naver/dust3r)**|\n", "2312.13252": "|**2023-12-20**|**Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model**|Saurabh Saxena et.al.|[2312.13252v1](http://arxiv.org/abs/2312.13252v1)|None|None|None|\n", "2312.13066": "|**2023-12-20**|**PPEA-Depth: Progressive Parameter-Efficient Adaptation for Self-Supervised Monocular Depth Estimation**|Yue-Jiang Dong et.al.|[2312.13066v2](http://arxiv.org/abs/2312.13066v2)|Accepted by AAAI 2024 Project homepage:   https://yuejiangdong.github.io/PPEADepth/|None|None|\n", "2312.12471": "|**2023-12-19**|**Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion**|Fan Zhang et.al.|[2312.12471v1](http://arxiv.org/abs/2312.12471v1)|10 pages|None|**[link](https://github.com/zkawfanx/atlantis)**|\n", "2312.11037": "|**2023-12-18**|**SinMPI: Novel View Synthesis from a Single Image with Expanded Multiplane Images**|Guo Pu et.al.|[2312.11037v1](http://arxiv.org/abs/2312.11037v1)|10 pages|None|**[link](https://github.com/trickygo/sinmpi)**|\n", "2312.10986": "|**2023-12-18**|**Long-Tailed 3D Detection via 2D Late Fusion**|Yechi Ma et.al.|[2312.10986v3](http://arxiv.org/abs/2312.10986v3)|None|None|None|\n", "2312.10118": "|**2023-12-15**|**From-Ground-To-Objects: Coarse-to-Fine Self-supervised Monocular Depth Estimation of Dynamic Objects with Ground Contact Prior**|Jaeho Moon et.al.|[2312.10118v1](http://arxiv.org/abs/2312.10118v1)|None|None|None|\n", "2312.09243": "|**2023-12-14**|**OccNeRF: Advancing 3D Occupancy Prediction in LiDAR-Free Environments**|Chubin Zhang et.al.|[2312.09243v2](http://arxiv.org/abs/2312.09243v2)|Code: https://github.com/LinShan-Bin/OccNeRF|None|**[link](https://github.com/linshan-bin/occnerf)**|\n", "2312.09242": "|**2023-12-14**|**Text2Immersion: Generative Immersive Scene with 3D Gaussians**|Hao Ouyang et.al.|[2312.09242v1](http://arxiv.org/abs/2312.09242v1)|Project page: https://ken-ouyang.github.io/text2immersion/index.html|None|None|\n", "2312.08594": "|**2023-12-14**|**CT-MVSNet: Efficient Multi-View Stereo with Cross-scale Transformer**|Sicheng Wang et.al.|[2312.08594v2](http://arxiv.org/abs/2312.08594v2)|Accepted at the 30th International Conference on Multimedia   Modeling(MMM'24 Oral)|None|**[link](https://github.com/wscstrive/ct-mvsnet)**|\n", "2312.08548": "|**2023-12-13**|**EVP: Enhanced Visual Perception using Inverse Multi-Attentive Feature Refinement and Regularized Image-Text Alignment**|Mykola Lavreniuk et.al.|[2312.08548v1](http://arxiv.org/abs/2312.08548v1)|None|None|**[link](https://github.com/lavreniuk/evp)**|\n", "2312.08004": "|**2023-12-13**|**Instance-aware Multi-Camera 3D Object Detection with Structural Priors Mining and Self-Boosting Learning**|Yang Jiao et.al.|[2312.08004v1](http://arxiv.org/abs/2312.08004v1)|Accepted to AAAI 2024|None|None|\n", "2312.06021": "|**2023-12-10**|**GenDepth: Generalizing Monocular Depth Estimation for Arbitrary Camera Parameters via Ground Plane Embedding**|Karlo Koledi\u0107 et.al.|[2312.06021v1](http://arxiv.org/abs/2312.06021v1)|None|None|None|\n", "2312.05190": "|**2023-12-08**|**Fine Dense Alignment of Image Bursts through Camera Pose and Depth Estimation**|Bruno Lecouat et.al.|[2312.05190v1](http://arxiv.org/abs/2312.05190v1)|None|None|None|\n", "2312.04530": "|**2023-12-07**|**Camera Height Doesn't Change: Unsupervised Training for Metric Monocular Road-Scene Depth Estimation**|Genki Kinoshita et.al.|[2312.04530v2](http://arxiv.org/abs/2312.04530v2)|None|None|None|\n", "2312.02284": "|**2023-12-04**|**PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation**|Zhenyu Li et.al.|[2312.02284v1](http://arxiv.org/abs/2312.02284v1)|None|None|**[link](https://github.com/zhyever/PatchFusion)**|\n", "2312.02155": "|**2023-12-04**|**GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for Real-time Human Novel View Synthesis**|Shunyuan Zheng et.al.|[2312.02155v3](http://arxiv.org/abs/2312.02155v3)|Accepted by CVPR 2024 (Highlight). Project page:   https://shunyuanzheng.github.io/GPS-Gaussian|None|**[link](https://github.com/aipixel/gps-gaussian)**|\n", "2312.02145": "|**2023-12-04**|**Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation**|Bingxin Ke et.al.|[2312.02145v2](http://arxiv.org/abs/2312.02145v2)|CVPR 2024 camera ready|None|**[link](https://github.com/prs-eth/marigold)**|\n", "2312.02116": "|**2023-12-04**|**GIVT: Generative Infinite-Vocabulary Transformers**|Michael Tschannen et.al.|[2312.02116v3](http://arxiv.org/abs/2312.02116v3)|v2: add related NLP work, loss details. v3: Improved GMM formulation,   added adapter module, larger models, better image generation results. Code   and model checkpoints are available at:   https://github.com/google-research/big_vision|None|**[link](https://github.com/google-research/big_vision)**|\n", "2312.01696": "|**2023-12-04**|**BEVNeXt: Reviving Dense BEV Frameworks for 3D Object Detection**|Zhenxin Li et.al.|[2312.01696v2](http://arxiv.org/abs/2312.01696v2)|None|None|None|\n", "2312.01283": "|**2023-12-03**|**Deeper into Self-Supervised Monocular Indoor Depth Estimation**|Chao Fan et.al.|[2312.01283v1](http://arxiv.org/abs/2312.01283v1)|None|None|**[link](https://github.com/fcntes/indoordepth)**|\n", "2312.02190": "|**2023-12-02**|**Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D**|Karran Pandey et.al.|[2312.02190v2](http://arxiv.org/abs/2312.02190v2)|Project Webpage: https://diffusionhandles.github.io/|None|None|\n", "2312.00944": "|**2023-12-01**|**Enhancing Diffusion Models with 3D Perspective Geometry Constraints**|Rishi Upadhyay et.al.|[2312.00944v1](http://arxiv.org/abs/2312.00944v1)|Project Webpage: http://visual.ee.ucla.edu/diffusionperspective.htm/|None|None|\n", "2312.00451": "|**2023-12-01**|**FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting**|Zehao Zhu et.al.|[2312.00451v2](http://arxiv.org/abs/2312.00451v2)|Project page: https://zehaozhu.github.io/FSGS/|None|None|\n", "2311.18664": "|**2023-11-30**|**Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy**|Pedro Esteban Chavarrias Solano et.al.|[2311.18664v1](http://arxiv.org/abs/2311.18664v1)|19 pages|None|None|\n", "2311.16945": "|**2023-11-28**|**UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras in Autonomous Driving**|Kai Cheng et.al.|[2311.16945v2](http://arxiv.org/abs/2311.16945v2)|See the project page for code, data:   https://kcheng1021.github.io/ucnerf.github.io|None|None|\n", "2311.16664": "|**2023-11-28**|**DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes**|Zhuopeng Li et.al.|[2311.16664v1](http://arxiv.org/abs/2311.16664v1)|None|None|None|\n", "2311.13398": "|**2023-11-22**|**Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images**|Jaeyoung Chung et.al.|[2311.13398v3](http://arxiv.org/abs/2311.13398v3)|10 pages, 5 figures; Project page: robot0321.github.io/DepthRegGS|None|None|\n", "2311.13045": "|**2023-11-21**|**Camera-Independent Single Image Depth Estimation from Defocus Blur**|Lahiru Wijayasingha et.al.|[2311.13045v1](http://arxiv.org/abs/2311.13045v1)|None|None|**[link](https://github.com/sleekeagle/defocus_camind)**|\n", "2311.12754": "|**2023-11-21**|**SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction**|Yuanhui Huang et.al.|[2311.12754v2](http://arxiv.org/abs/2311.12754v2)|Code is available at: https://github.com/huang-yh/SelfOcc|None|**[link](https://github.com/huang-yh/selfocc)**|\n", "2311.12682": "|**2023-11-21**|**Transferring to Real-World Layouts: A Depth-aware Framework for Scene Adaptation**|Mu Chen et.al.|[2311.12682v1](http://arxiv.org/abs/2311.12682v1)|None|None|None|\n", "2311.10042": "|**2023-11-16**|**Depth Insight -- Contribution of Different Features to Indoor Single-image Depth Estimation**|Yihong Wu et.al.|[2311.10042v1](http://arxiv.org/abs/2311.10042v1)|None|None|None|\n", "2311.09361": "|**2023-11-15**|**RENI++ A Rotation-Equivariant, Scale-Invariant, Natural Illumination Prior**|James A. D. Gardner et.al.|[2311.09361v1](http://arxiv.org/abs/2311.09361v1)|Project Repo - https://github.com/JADGardner/ns_reni. arXiv admin   note: substantial text overlap with arXiv:2206.03858|None|**[link](https://github.com/jadgardner/ns_reni)**|\n", "2311.09093": "|**2023-11-15**|**Applications of Computer Vision in Autonomous Vehicles: Methods, Challenges and Future Directions**|Xingshuai Dong et.al.|[2311.09093v3](http://arxiv.org/abs/2311.09093v3)|None|None|None|\n", "2311.08129": "|**2023-11-14**|**Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application**|Langqing Shi et.al.|[2311.08129v1](http://arxiv.org/abs/2311.08129v1)|None|None|None|\n", "2311.07198": "|**2023-11-13**|**MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model**|Shuwei Shao et.al.|[2311.07198v1](http://arxiv.org/abs/2311.07198v1)|10 pages, 8 figures|None|**[link](https://github.com/shuweishao/monodiffusion)**|\n", "2311.07166": "|**2023-11-13**|**NDDepth: Normal-Distance Assisted Monocular Depth Estimation and Completion**|Shuwei Shao et.al.|[2311.07166v1](http://arxiv.org/abs/2311.07166v1)|Extension of previous work arXiv:2309.10592|None|**[link](https://github.com/ShuweiShao/NDDepth)**|\n", "2311.06137": "|**2023-11-10**|**MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty**|R\u00e9mi Marsal et.al.|[2311.06137v1](http://arxiv.org/abs/2311.06137v1)|Accepted at WACV 2024|None|**[link](https://github.com/cea-list/monoprob)**|\n", "2311.05770": "|**2023-11-09**|**PolyMaX: General Dense Prediction with Mask Transformer**|Xuan Yang et.al.|[2311.05770v1](http://arxiv.org/abs/2311.05770v1)|WACV 2024|None|**[link](https://github.com/google-research/deeplab2)**|\n", "2311.05021": "|**2023-11-08**|**Leveraging a realistic synthetic database to learn Shape-from-Shading for estimating the colon depth in colonoscopy images**|Josu\u00e9 Ruano et.al.|[2311.05021v1](http://arxiv.org/abs/2311.05021v1)|None|Ruano, J., Gomez, M., Romero, E., & Manzanera, A. (2024).   Leveraging a realistic synthetic database to learn Shape-from-Shading for   estimating the colon depth in colonoscopy images. Computerized Medical   Imaging and Graphics, 102390|None|\n", "2311.03938": "|**2023-11-07**|**Analysis of NaN Divergence in Training Monocular Depth Estimation Model**|Bum Jun Kim et.al.|[2311.03938v1](http://arxiv.org/abs/2311.03938v1)|10 pages, 3 figures|None|None|\n", "2311.03427": "|**2023-11-06**|**TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding**|Shuo Wang et.al.|[2311.03427v1](http://arxiv.org/abs/2311.03427v1)|WACV 2024|None|**[link](https://github.com/tb2-sy/tsp-transformer)**|\n", "2311.02393": "|**2023-11-04**|**Continual Learning of Unsupervised Monocular Depth from Videos**|Hemang Chawla et.al.|[2311.02393v1](http://arxiv.org/abs/2311.02393v1)|Accepted at IEEE/CVF Winter Conference on Applications of Computer   Vision (WACV 2024)|None|**[link](https://github.com/neurai-lab/cude-monodepthcl)**|\n", "2311.01886": "|**2023-11-03**|**Bridging the Gap between Multi-focus and Multi-modal: A Focused Integration Framework for Multi-modal Image Fusion**|Xilai Li et.al.|[2311.01886v2](http://arxiv.org/abs/2311.01886v2)|Accepted to IEEE/CVF Winter Conference on Applications of Computer   Vision (WACV) 2024|None|**[link](https://github.com/ixilai/mfif-mmif)**|\n", "2311.01034": "|**2023-11-02**|**Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation**|Xueting Hu et.al.|[2311.01034v1](http://arxiv.org/abs/2311.01034v1)|Accepted by WACV 2024|None|None|\n", "2310.18887": "|**2023-10-29**|**Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes**|Yihong Sun et.al.|[2310.18887v1](http://arxiv.org/abs/2310.18887v1)|NeurIPS 2023|None|None|\n", "2310.17156": "|**2023-10-26**|**Learning depth from monocular video sequences**|Zhenwei Luo et.al.|[2310.17156v1](http://arxiv.org/abs/2310.17156v1)|None|None|None|\n", "2310.17154": "|**2023-10-26**|**Deep Imbalanced Regression via Hierarchical Classification Adjustment**|Haipeng Xiong et.al.|[2310.17154v1](http://arxiv.org/abs/2310.17154v1)|14 pages, 5 figures|None|None|\n", "2310.16831": "|**2023-10-25**|**PERF: Panoramic Neural Radiance Field from a Single Panorama**|Guangcong Wang et.al.|[2310.16831v2](http://arxiv.org/abs/2310.16831v2)|Project Page: https://perf-project.github.io/ , Code:   https://github.com/perf-project/PeRF|None|**[link](https://github.com/perf-project/PeRF)**|\n", "2310.16750": "|**2023-10-25**|**Metrically Scaled Monocular Depth Estimation through Sparse Priors for Underwater Robots**|Luca Ebner et.al.|[2310.16750v1](http://arxiv.org/abs/2310.16750v1)|Submitted to ICRA 2024|None|**[link](https://github.com/ebnerluca/uw_depth)**|\n", "2310.16457": "|**2023-10-25**|**Towards Explainability in Monocular Depth Estimation**|Vasileios Arampatzakis et.al.|[2310.16457v1](http://arxiv.org/abs/2310.16457v1)|None|None|None|\n", "2310.16167": "|**2023-10-24**|**iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis**|Yash Kant et.al.|[2310.16167v1](http://arxiv.org/abs/2310.16167v1)|Accepted to SIGGRAPH Asia, 2023 (Conference Papers)|None|None|\n", "2310.15422": "|**2023-10-24**|**G2-MonoDepth: A General Framework of Generalized Depth Inference from Monocular RGB+X Data**|Haotian Wang et.al.|[2310.15422v1](http://arxiv.org/abs/2310.15422v1)|18 pages, 16 figures|None|**[link](https://github.com/wang-xjtu/g2-monodepth)**|\n", "2310.15171": "|**2023-10-23**|**RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions**|Lingdong Kong et.al.|[2310.15171v1](http://arxiv.org/abs/2310.15171v1)|NeurIPS 2023; 45 pages, 25 figures, 13 tables; Code at   https://github.com/ldkong1205/RoboDepth|None|**[link](https://github.com/ldkong1205/robodepth)**|\n", "2310.14437": "|**2023-10-22**|**Mobile AR Depth Estimation: Challenges & Prospects -- Extended Version**|Ashkan Ganj et.al.|[2310.14437v1](http://arxiv.org/abs/2310.14437v1)|None|None|None|\n", "2310.14364": "|**2023-10-22**|**A Quantitative Evaluation of Dense 3D Reconstruction of Sinus Anatomy from Monocular Endoscopic Video**|Jan Emily Mangulabnan et.al.|[2310.14364v1](http://arxiv.org/abs/2310.14364v1)|None|None|None|\n", "2310.14239": "|**2023-10-22**|**Guidance system for Visually Impaired Persons using Deep Learning and Optical flow**|Shwetang Dubey et.al.|[2310.14239v1](http://arxiv.org/abs/2310.14239v1)|None|None|None|\n", "2310.11645": "|**2023-10-18**|**Towards Abdominal 3-D Scene Rendering from Laparoscopy Surgical Videos using NeRFs**|Khoa Tuan Nguyen et.al.|[2310.11645v1](http://arxiv.org/abs/2310.11645v1)|The Version of Record of this contribution is published in MLMI 2023   Part I, and is available online at   https://doi.org/10.1007/978-3-031-45673-2_9|None|None|\n", "2310.11178": "|**2023-10-17**|**FocDepthFormer: Transformer with LSTM for Depth Estimation from Focus**|Xueyang Kang et.al.|[2310.11178v1](http://arxiv.org/abs/2310.11178v1)|20 pages, 18 figures, journal paper|None|None|\n", "2310.08587": "|**2023-10-12**|**Pseudo-Generalized Dynamic View Synthesis from a Video**|Xiaoming Zhao et.al.|[2310.08587v3](http://arxiv.org/abs/2310.08587v3)|ICLR 2024; Originally titled as \"Is Generalized Dynamic Novel View   Synthesis from Monocular Videos Possible Today?\"; Project page:   https://xiaoming-zhao.github.io/projects/pgdvs|None|None|\n", "2310.08044": "|**2023-10-12**|**EC-Depth: Exploring the consistency of self-supervised monocular depth estimation in challenging scenes**|Ziyang Song et.al.|[2310.08044v2](http://arxiv.org/abs/2310.08044v2)|Project page: https://ruijiezhu94.github.io/ECDepth_page|None|**[link](https://github.com/RuijieZhu94/EC-Depth)**|\n", "2310.07212": "|**2023-10-11**|**Multi-Task Learning-Enabled Automatic Vessel Draft Reading for Intelligent Maritime Surveillance**|Jingxiang Qu et.al.|[2310.07212v1](http://arxiv.org/abs/2310.07212v1)|12 pages,11 figures, submitted to IEEE T-ITS|None|None|\n", "2310.05556": "|**2023-10-09**|**WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth Estimation under Adverse Weather Conditions**|Jiyuan Wang et.al.|[2310.05556v2](http://arxiv.org/abs/2310.05556v2)|6 pages, accept by ICRA 2024|ICRA 2024|**[link](https://github.com/wangjiyuan9/weatherdepth)**|\n", "2310.04837": "|**2023-10-07**|**Federated Self-Supervised Learning of Monocular Depth Estimators for Autonomous Vehicles**|Elton F. de S. Soares et.al.|[2310.04837v1](http://arxiv.org/abs/2310.04837v1)|16 pages, 8 figures, journal preprint|None|None|\n", "2310.04551": "|**2023-10-06**|**MeSa: Masked, Geometric, and Supervised Pre-training for Monocular Depth Estimation**|Muhammad Osama Khan et.al.|[2310.04551v1](http://arxiv.org/abs/2310.04551v1)|None|None|None|\n", "2310.03967": "|**2023-10-06**|**Sub-token ViT Embedding via Stochastic Resonance Transformers**|Dong Lao et.al.|[2310.03967v2](http://arxiv.org/abs/2310.03967v2)|None|None|**[link](https://github.com/donglao/srt)**|\n", "2310.03420": "|**2023-10-05**|**FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators**|Haiping Wang et.al.|[2310.03420v2](http://arxiv.org/abs/2310.03420v2)|CameraReady version for ICLR 2024. Project Page:   https://whu-usi3dv.github.io/FreeReg/|None|**[link](https://github.com/WHU-USI3DV/FreeReg)**|\n", "2310.02262": "|**2023-10-03**|**RSRD: A Road Surface Reconstruction Dataset and Benchmark for Safe and Comfortable Autonomous Driving**|Tong Zhao et.al.|[2310.02262v1](http://arxiv.org/abs/2310.02262v1)|None|None|None|\n", "2310.01843": "|**2023-10-03**|**Selective Feature Adapter for Dense Vision Transformers**|Xueqing Deng et.al.|[2310.01843v1](http://arxiv.org/abs/2310.01843v1)|None|None|None|\n", "2310.01833": "|**2023-10-03**|**Skin the sheep not only once: Reusing Various Depth Datasets to Drive the Learning of Optical Flow**|Sheng-Chi Huang et.al.|[2310.01833v1](http://arxiv.org/abs/2310.01833v1)|None|None|None|\n", "2310.00986": "|**2023-10-02**|**Multi-task Learning with 3D-Aware Regularization**|Wei-Hong Li et.al.|[2310.00986v1](http://arxiv.org/abs/2310.00986v1)|3D-aware Multi-task Learning, Code will be available at   https://github.com/VICO-UoE/MTPSL|None|**[link](https://github.com/vico-uoe/mtpsl)**|\n", "2310.00390": "|**2023-09-30**|**InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists**|Yulu Gan et.al.|[2310.00390v3](http://arxiv.org/abs/2310.00390v3)|ICLR 2024; Code is available at https://github.com/AlaaLab/InstructCV|None|**[link](https://github.com/AlaaLab/InstructCV)**|\n", "2309.17399": "|**2023-09-29**|**IFAST: Weakly Supervised Interpretable Face Anti-spoofing from Single-shot Binocular NIR Images**|Jiancheng Huang et.al.|[2309.17399v1](http://arxiv.org/abs/2309.17399v1)|None|None|None|\n", "2309.17059": "|**2023-09-29**|**GSDC Transformer: An Efficient and Effective Cue Fusion for Monocular Multi-Frame Depth Estimation**|Naiyu Fang et.al.|[2309.17059v2](http://arxiv.org/abs/2309.17059v2)|None|None|None|\n", "2310.00031": "|**2023-09-29**|**Text-image Alignment for Diffusion-based Perception**|Neehar Kondapaneni et.al.|[2310.00031v3](http://arxiv.org/abs/2310.00031v3)|Project page: https://www.vision.caltech.edu/tadp/, Code page:   github.com/damaggu/TADP|None|**[link](https://github.com/damaggu/tadp)**|\n", "2309.16301": "|**2023-09-28**|**Gated Cross-Attention Network for Depth Completion**|Xiaogang Jia et.al.|[2309.16301v2](http://arxiv.org/abs/2309.16301v2)|None|None|None|\n", "2309.15751": "|**2023-09-27**|**InfraParis: A multi-modal and multi-task autonomous driving dataset**|Gianni Franchi et.al.|[2309.15751v2](http://arxiv.org/abs/2309.15751v2)|15 pages, 7 figures. Accepted at WACV 2024|None|**[link](https://github.com/ENSTA-U2IS-AI/Multimodal_Deep_segmentation)**|\n", "2309.15505": "|**2023-09-27**|**Finite Scalar Quantization: VQ-VAE Made Simple**|Fabian Mentzer et.al.|[2309.15505v2](http://arxiv.org/abs/2309.15505v2)|Code:   https://github.com/google-research/google-research/tree/master/fsq|None|**[link](https://github.com/google-research/google-research)**|\n", "2309.15313": "|**2023-09-26**|**M$^{3}$3D: Learning 3D priors using Multi-Modal Masked Autoencoders for 2D image and video understanding**|Muhammad Abdullah Jamal et.al.|[2309.15313v1](http://arxiv.org/abs/2309.15313v1)|None|None|None|\n", "2309.16019": "|**2023-09-26**|**GasMono: Geometry-Aided Self-Supervised Monocular Depth Estimation for Indoor Scenes**|Chaoqiang Zhao et.al.|[2309.16019v1](http://arxiv.org/abs/2309.16019v1)|ICCV 2023. Code: https://github.com/zxcqlf/GasMono|None|**[link](https://github.com/zxcqlf/gasmono)**|\n", "2309.14744": "|**2023-09-26**|**ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation**|Zizhang Wu et.al.|[2309.14744v1](http://arxiv.org/abs/2309.14744v1)|accepted by CoRL 2023|None|None|\n", "2309.14137": "|**2023-09-25**|**IEBins: Iterative Elastic Bins for Monocular Depth Estimation**|Shuwei Shao et.al.|[2309.14137v1](http://arxiv.org/abs/2309.14137v1)|Accepted by NeurIPS 2023|None|**[link](https://github.com/shuweishao/iebins)**|\n", "2309.13851": "|**2023-09-25**|**DISeR: Designing Imaging Systems with Reinforcement Learning**|Tzofi Klinghoffer et.al.|[2309.13851v1](http://arxiv.org/abs/2309.13851v1)|ICCV 2023. Project Page: https://tzofi.github.io/diser|None|None|\n", "2309.13516": "|**2023-09-24**|**InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation**|Cho-Ying Wu et.al.|[2309.13516v2](http://arxiv.org/abs/2309.13516v2)|Add Depth-Anything|None|**[link](https://github.com/DepthComputation/InSpaceType_Benchmark)**|\n", "2309.12842": "|**2023-09-22**|**SRFNet: Monocular Depth Estimation with Fine-grained Structure via Spatial Reliability-oriented Fusion of Frames and Events**|Tianbo Pan et.al.|[2309.12842v1](http://arxiv.org/abs/2309.12842v1)|None|None|None|\n", "2309.12172": "|**2023-09-21**|**SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset**|Sagar M. Waghmare et.al.|[2309.12172v1](http://arxiv.org/abs/2309.12172v1)|10 pages plus additional references. 13 figures|None|None|\n", "2309.11119": "|**2023-09-20**|**BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird's Eye View Map Construction**|Minsu Kim et.al.|[2309.11119v4](http://arxiv.org/abs/2309.11119v4)|None|None|None|\n", "2309.11081": "|**2023-09-20**|**Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation**|Heeseung Yun et.al.|[2309.11081v1](http://arxiv.org/abs/2309.11081v1)|Published to ICCV2023|None|**[link](https://github.com/hs-yn/daps)**|\n", "2309.10592": "|**2023-09-19**|**NDDepth: Normal-Distance Assisted Monocular Depth Estimation**|Shuwei Shao et.al.|[2309.10592v2](http://arxiv.org/abs/2309.10592v2)|Accepted by ICCV 2023 (Oral)|None|None|\n", "2309.09975": "|**2023-09-18**|**GEDepth: Ground Embedding for Monocular Depth Estimation**|Xiaodong Yang et.al.|[2309.09975v1](http://arxiv.org/abs/2309.09975v1)|ICCV 2023|None|**[link](https://github.com/qcraftai/gedepth)**|\n", "2309.09724": "|**2023-09-18**|**Robust Geometry-Preserving Depth Estimation Using Differentiable Rendering**|Chi Zhang et.al.|[2309.09724v1](http://arxiv.org/abs/2309.09724v1)|Accepted by ICCV2023|None|None|\n", "2309.09272": "|**2023-09-17**|**Deep Neighbor Layer Aggregation for Lightweight Self-Supervised Monocular Depth Estimation**|Wang Boya et.al.|[2309.09272v2](http://arxiv.org/abs/2309.09272v2)|None|None|**[link](https://github.com/boyagesmile/dna-depth)**|\n", "2310.06164": "|**2023-09-16**|**DEUX: Active Exploration for Learning Unsupervised Depth Perception**|Marvin Chanc\u00e1n et.al.|[2310.06164v1](http://arxiv.org/abs/2310.06164v1)|None|None|None|\n", "2309.08424": "|**2023-09-15**|**X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Distillation and Boundary Correction**|Cao Dinh Duc et.al.|[2309.08424v2](http://arxiv.org/abs/2309.08424v2)|Accepted to BMVC 2023|None|**[link](https://github.com/caodinhduc/x-pdnet-official)**|\n", "2309.08033": "|**2023-09-14**|**Depth Estimation from a Single Optical Encoded Image using a Learned Colored-Coded Aperture**|Jhon Lopez et.al.|[2309.08033v1](http://arxiv.org/abs/2309.08033v1)|None|None|None|\n", "2309.06547": "|**2023-09-12**|**AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous Driving**|Ahmed Rida Sekkat et.al.|[2309.06547v2](http://arxiv.org/abs/2309.06547v2)|None|None|None|\n", "2309.05254": "|**2023-09-11**|**Towards Better Data Exploitation in Self-Supervised Monocular Depth Estimation**|Jinfeng Liu et.al.|[2309.05254v3](http://arxiv.org/abs/2309.05254v3)|8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters   (RA-L 2023)|None|**[link](https://github.com/LiuJF1226/BDEdepth)**|\n", "2309.04147": "|**2023-09-08**|**Robot Localization and Mapping Final Report -- Sequential Adversarial Learning for Self-Supervised Deep Visual Odometry**|Akankshya Kar et.al.|[2309.04147v1](http://arxiv.org/abs/2309.04147v1)|None|None|None|\n", "2309.03955": "|**2023-09-07**|**SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions**|Nagabhushan Somraj et.al.|[2309.03955v2](http://arxiv.org/abs/2309.03955v2)|SIGGRAPH Asia 2023|None|None|\n", "2310.00011": "|**2023-09-07**|**Joint Self-supervised Depth and Optical Flow Estimation towards Dynamic Objects**|Zhengyang Lu et.al.|[2310.00011v1](http://arxiv.org/abs/2310.00011v1)|None|None|None|\n", "2309.03185": "|**2023-09-06**|**Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields**|Lily Goli et.al.|[2309.03185v1](http://arxiv.org/abs/2309.03185v1)|None|None|**[link](https://github.com/BayesRays/BayesRays)**|\n", "2309.00933": "|**2023-09-02**|**Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation**|Zhengming Zhou et.al.|[2309.00933v1](http://arxiv.org/abs/2309.00933v1)|Accepted to ICCV 2023|None|**[link](https://github.com/zm-zhou/tio-depth_pytorch)**|\n", "2309.00526": "|**2023-09-01**|**SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation**|Youhong Wang et.al.|[2309.00526v1](http://arxiv.org/abs/2309.00526v1)|14 pages, 9 figures|None|None|\n", "2308.15085": "|**2023-08-29**|**Learning to Upsample by Learning to Sample**|Wenze Liu et.al.|[2308.15085v1](http://arxiv.org/abs/2308.15085v1)|Accepted by ICCV 2023|None|**[link](https://github.com/tiny-smart/dysample)**|\n", "2308.14400": "|**2023-08-28**|**Semi-Supervised Semantic Depth Estimation using Symbiotic Transformer and NearFarMix Augmentation**|Md Awsafur Rahman et.al.|[2308.14400v1](http://arxiv.org/abs/2308.14400v1)|Accepted at WACV 2024|None|None|\n", "2308.14108": "|**2023-08-27**|**Depth self-supervision for single image novel view synthesis**|Giovanni Minelli et.al.|[2308.14108v1](http://arxiv.org/abs/2308.14108v1)|None|None|**[link](https://github.com/johnminelli/twowaysynth)**|\n", "2308.14005": "|**2023-08-27**|**Calibrating Panoramic Depth Estimation for Practical Localization and Mapping**|Junho Kim et.al.|[2308.14005v2](http://arxiv.org/abs/2308.14005v2)|Accepted to ICCV 2023|None|**[link](https://github.com/82magnolia/panoramic-depth-calibration)**|\n", "2308.12937": "|**2023-08-24**|**Panoptic-Depth Color Map for Combination of Depth and Image Segmentation**|Jia-Quan Yu et.al.|[2308.12937v1](http://arxiv.org/abs/2308.12937v1)|None|None|None|\n", "2308.11776": "|**2023-08-22**|**WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation on Surgical Videos with Unknown Camera Parameters**|Ange Lou et.al.|[2308.11776v2](http://arxiv.org/abs/2308.11776v2)|Accepted by SPIE 2024|None|None|\n", "2308.11774": "|**2023-08-22**|**SAMSNeRF: Segment Anything Model (SAM) Guides Dynamic Surgical Scene Reconstruction by Neural Radiance Field (NeRF)**|Ange Lou et.al.|[2308.11774v2](http://arxiv.org/abs/2308.11774v2)|Accepted by SPIE 2024|None|None|\n", "2308.10603": "|**2023-08-21**|**A step towards understanding why classification helps regression**|Silvia L. Pintea et.al.|[2308.10603v1](http://arxiv.org/abs/2308.10603v1)|Accepted at ICCV-2023|None|**[link](https://github.com/silvialaurapintea/reg-cls)**|\n", "2308.10569": "|**2023-08-21**|**Real-time Monocular Depth Estimation on Embedded Systems**|Cheng Feng et.al.|[2308.10569v2](http://arxiv.org/abs/2308.10569v2)|7 pages, ICIP2024 Accepted|None|None|\n", "2308.10525": "|**2023-08-21**|**LightDepth: Single-View Depth Self-Supervision from Illumination Decline**|Javier Rodr\u00edguez-Puigvert et.al.|[2308.10525v2](http://arxiv.org/abs/2308.10525v2)|None|None|None|\n", "2308.10001": "|**2023-08-19**|**AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization**|Kun Wang et.al.|[2308.10001v2](http://arxiv.org/abs/2308.10001v2)|Accepted by AAAI-24|None|None|\n", "2308.09990": "|**2023-08-19**|**Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo**|Zhenlong Yuan et.al.|[2308.09990v2](http://arxiv.org/abs/2308.09990v2)|None|None|None|\n", "2308.09711": "|**2023-08-18**|**Robust Monocular Depth Estimation under Challenging Conditions**|Stefano Gasperini et.al.|[2308.09711v1](http://arxiv.org/abs/2308.09711v1)|ICCV 2023. Source code and data: https://md4all.github.io|None|None|\n", "2308.09065": "|**2023-08-17**|**Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression**|Xuanlong Yu et.al.|[2308.09065v2](http://arxiv.org/abs/2308.09065v2)|23 pages with main paper and supplymentary material. Accepted at AAAI   2024|None|**[link](https://github.com/ensta-u2is/dido)**|\n", "2308.09022": "|**2023-08-17**|**ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval**|Song Zhang et.al.|[2308.09022v1](http://arxiv.org/abs/2308.09022v1)|None|None|**[link](https://github.com/zs670980918/arai-mvsnet)**|\n", "2308.08333": "|**2023-08-16**|**Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN**|Jiawei Yao et.al.|[2308.08333v3](http://arxiv.org/abs/2308.08333v3)|None|None|None|\n", "2308.07225": "|**2023-08-14**|**DS-Depth: Dynamic and Static Depth Estimation via a Fusion Cost Volume**|Xingyu Miao et.al.|[2308.07225v1](http://arxiv.org/abs/2308.07225v1)|None|None|**[link](https://github.com/xingy038/ds-depth)**|\n", "2308.06160": "|**2023-08-11**|**DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models**|Weijia Wu et.al.|[2308.06160v2](http://arxiv.org/abs/2308.06160v2)|None|Proc. Advances In Neural Information Processing Systems (NeurIPS   2023)|**[link](https://github.com/showlab/datasetdm)**|\n", "2308.06072": "|**2023-08-11**|**Out-of-Distribution Detection for Monocular Depth Estimation**|Julia Hornauer et.al.|[2308.06072v1](http://arxiv.org/abs/2308.06072v1)|Accepted to ICCV 2023|None|**[link](https://github.com/jhornauer/mde_ood)**|\n", "2308.05733": "|**2023-08-10**|**FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models**|Guangkai Xu et.al.|[2308.05733v1](http://arxiv.org/abs/2308.05733v1)|Accepted to ICCV 2023. Project webpage is at:   https://aim-uofa.github.io/FrozenRecon/|None|None|\n", "2308.05605": "|**2023-08-10**|**Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network**|Wencheng Han et.al.|[2308.05605v1](http://arxiv.org/abs/2308.05605v1)|ICCV2023|None|**[link](https://github.com/wencheng256/daccn)**|\n", "2308.03193": "|**2023-08-06**|**Syn-Mediverse: A Multimodal Synthetic Dataset for Intelligent Scene Understanding of Healthcare Facilities**|Rohit Mohan et.al.|[2308.03193v1](http://arxiv.org/abs/2308.03193v1)|None|None|None|\n", "2308.02716": "|**2023-08-04**|**EndoDepthL: Lightweight Endoscopic Monocular Depth Estimation with CNN-Transformer**|Yangke Li et.al.|[2308.02716v2](http://arxiv.org/abs/2308.02716v2)|None|None|None|\n", "2308.02283": "|**2023-08-04**|**Diffusion-Augmented Depth Prediction with Sparse Annotations**|Jiaqi Li et.al.|[2308.02283v1](http://arxiv.org/abs/2308.02283v1)|Accepted by ACM MM'2023|None|None|\n", "2308.02153": "|**2023-08-04**|**Robust Self-Supervised Extrinsic Self-Calibration**|Takayuki Kanai et.al.|[2308.02153v2](http://arxiv.org/abs/2308.02153v2)|Project page: https://sites.google.com/view/tri-sesc|The IEEE/RSJ International Conference on Intelligent Robots and   Systems (IROS), 2023|None|\n", "2308.01088": "|**2023-08-02**|**Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks**|Gianluca Amprimo et.al.|[2308.01088v1](http://arxiv.org/abs/2308.01088v1)|None|None|**[link](https://github.com/gianluca-amprimo/gmh-d)**|\n", "2307.16509": "|**2023-07-31**|**Digging Into Uncertainty-based Pseudo-label for Robust Stereo Matching**|Zhelun Shen et.al.|[2307.16509v1](http://arxiv.org/abs/2307.16509v1)|Accepted by TPAMI|None|**[link](https://github.com/gallenszl/ucfnet)**|\n", "2307.15061": "|**2023-07-27**|**The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation**|Lingdong Kong et.al.|[2307.15061v1](http://arxiv.org/abs/2307.15061v1)|Technical Report; 65 pages, 34 figures, 24 tables; Code at   https://github.com/ldkong1205/RoboDepth|None|**[link](https://github.com/ldkong1205/robodepth)**|\n", "2307.15052": "|**2023-07-27**|**Learning Depth Estimation for Transparent and Mirror Surfaces**|Alex Costanzino et.al.|[2307.15052v1](http://arxiv.org/abs/2307.15052v1)|Accepted at ICCV 2023. Project Page:   https://cvlab-unibo.github.io/Depth4ToM|None|None|\n", "2307.14786": "|**2023-07-27**|**Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning**|Junwen He et.al.|[2307.14786v2](http://arxiv.org/abs/2307.14786v2)|to be published in ICCV 2023|None|**[link](https://github.com/jwh97nn/DeepDPS)**|\n", "2307.14624": "|**2023-07-27**|**FS-Depth: Focal-and-Scale Depth Estimation from a Single Image in Unseen Indoor Scene**|Chengrui Wei et.al.|[2307.14624v1](http://arxiv.org/abs/2307.14624v1)|None|None|None|\n", "2307.14620": "|**2023-07-27**|**NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection**|Chenfeng Xu et.al.|[2307.14620v1](http://arxiv.org/abs/2307.14620v1)|Accepted by ICCV 2023|None|**[link](https://github.com/open-mmlab/mmdetection3d)**|\n", "2307.14460": "|**2023-07-26**|**MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation**|Reiner Birkl et.al.|[2307.14460v1](http://arxiv.org/abs/2307.14460v1)|14 pages, 2 figures|None|**[link](https://github.com/isl-org/MiDaS)**|\n", "2307.14336": "|**2023-07-26**|**MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation**|Rajeev Yasarla et.al.|[2307.14336v2](http://arxiv.org/abs/2307.14336v2)|Accepted at ICCV 2023|None|None|\n", "2307.13756": "|**2023-07-25**|**PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single View**|Jingjia Shi et.al.|[2307.13756v2](http://arxiv.org/abs/2307.13756v2)|To be published in Proceedings of IEEE International Conference on   Computer Vision (ICCV 2023). Camera Ready Version. Codes:   https://github.com/SJingjia/PlaneRecTR , Video: https://youtu.be/YBB7totHGJg|None|**[link](https://github.com/sjingjia/planerectr)**|\n", "2307.12761": "|**2023-07-24**|**LiDAR Meta Depth Completion**|Wolfgang Boettcher et.al.|[2307.12761v2](http://arxiv.org/abs/2307.12761v2)|Accepted at IROS 2023, v2 has updated author list and fixed a figure   caption|None|**[link](https://github.com/wbkit/reslan)**|\n", "2307.12274": "|**2023-07-23**|**FDCT: Fast Depth Completion for Transparent Objects**|Tianan Li et.al.|[2307.12274v2](http://arxiv.org/abs/2307.12274v2)|9pages,7figures|IEEE Robotics and Automation Letters (RA-L), 2023|**[link](https://github.com/nonmy/fdct)**|\n", "2307.10984": "|**2023-07-20**|**Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image**|Wei Yin et.al.|[2307.10984v1](http://arxiv.org/abs/2307.10984v1)|Accepted to ICCV 2023. Won the championship in the 2nd Monocular   Depth Estimation Challenge. The code is available at   https://github.com/YvanYin/Metric3D|None|**[link](https://github.com/yvanyin/metric3d)**|\n", "2307.10934": "|**2023-07-20**|**OCTraN: 3D Occupancy Convolutional Transformer Network in Unstructured Traffic Scenarios**|Aditya Nalgunda Ganesh et.al.|[2307.10934v1](http://arxiv.org/abs/2307.10934v1)|This work was accepted as a spotlight presentation at the   Transformers for Vision Workshop @CVPR 2023|None|None|\n", "2307.10713": "|**2023-07-20**|**Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV**|Jaime Spencer et.al.|[2307.10713v1](http://arxiv.org/abs/2307.10713v1)|Accepted to ICCV2023|None|**[link](https://github.com/jspenmar/slowtv_monodepth)**|\n", "2307.09929": "|**2023-07-19**|**Measuring and Modeling Uncertainty Degree for Monocular Depth Estimation**|Mochu Xiang et.al.|[2307.09929v1](http://arxiv.org/abs/2307.09929v1)|None|None|None|\n", "2307.08695": "|**2023-07-17**|**Neural Video Depth Stabilizer**|Yiran Wang et.al.|[2307.08695v2](http://arxiv.org/abs/2307.08695v2)|Accepted by ICCV2023|None|**[link](https://github.com/raymondwang987/nvds)**|\n", "2307.08357": "|**2023-07-17**|**Self-supervised Monocular Depth Estimation: Let's Talk About The Weather**|Kieran Saunders et.al.|[2307.08357v1](http://arxiv.org/abs/2307.08357v1)|ICCV'23|None|None|\n", "2307.08198": "|**2023-07-17**|**On Point Affiliation in Feature Upsampling**|Wenze Liu et.al.|[2307.08198v1](http://arxiv.org/abs/2307.08198v1)|17 pages. Extended version of NeurIPS 2022 paper \"SAPA:   Similarity-Aware Point Affiliation for Feature Upsampling\" at   arXiv:2209.12866v1. arXiv admin note: text overlap with arXiv:2209.12866|None|**[link](https://github.com/tiny-smart/sapa)**|\n", "2307.08027": "|**2023-07-16**|**Multi-Object Discovery by Low-Dimensional Object Motion**|Sadra Safadoust et.al.|[2307.08027v1](http://arxiv.org/abs/2307.08027v1)|ICCV 2023|None|None|\n", "2307.10233": "|**2023-07-16**|**RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo**|Yifei Shi et.al.|[2307.10233v1](http://arxiv.org/abs/2307.10233v1)|IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv   admin note: substantial text overlap with arXiv:2204.01320|None|None|\n", "2307.05129": "|**2023-07-11**|**DFR: Depth from Rotation by Uncalibrated Image Rectification with Latitudinal Motion Assumption**|Yongcong Zhang et.al.|[2307.05129v1](http://arxiv.org/abs/2307.05129v1)|None|None|**[link](https://github.com/zhangtaxue/dfr)**|\n", "2307.05561": "|**2023-07-09**|**TransPose: A Transformer-based 6D Object Pose Estimation Network with Depth Refinement**|Mahmoud Abdulsalam et.al.|[2307.05561v1](http://arxiv.org/abs/2307.05561v1)|None|None|None|\n", "2307.03602": "|**2023-07-07**|**Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal**|Matvei Panteleev et.al.|[2307.03602v1](http://arxiv.org/abs/2307.03602v1)|None|None|None|\n", "2307.02270": "|**2023-07-05**|**SVDM: Single-View Diffusion Model for Pseudo-Stereo 3D Object Detection**|Yuguang Shi et.al.|[2307.02270v1](http://arxiv.org/abs/2307.02270v1)|arXiv admin note: text overlap with arXiv:2203.02112,   arXiv:2303.01469 by other authors|None|None|\n", "2307.01425": "|**2023-07-04**|**Consistent Multimodal Generation via A Unified GAN Framework**|Zhen Zhu et.al.|[2307.01425v1](http://arxiv.org/abs/2307.01425v1)|In review|None|None|\n", "2306.17723": "|**2023-06-30**|**FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis**|Seunghyeon Seo et.al.|[2306.17723v4](http://arxiv.org/abs/2306.17723v4)|ICCV 2023. Project Page: https://shawn615.github.io/flipnerf/|None|**[link](https://github.com/shawn615/FlipNeRF)**|\n", "2306.17253": "|**2023-06-29**|**Towards Zero-Shot Scale-Aware Monocular Depth Estimation**|Vitor Guizilini et.al.|[2306.17253v1](http://arxiv.org/abs/2306.17253v1)|Project page: https://sites.google.com/view/tri-zerodepth|None|None|\n", "2306.15128": "|**2023-06-27**|**MIMIC: Masked Image Modeling with Image Correspondences**|Kalyani Marathe et.al.|[2306.15128v4](http://arxiv.org/abs/2306.15128v4)|None|None|**[link](https://github.com/raivnlab/mimic)**|\n", "2306.14538": "|**2023-06-26**|**Learnable Differencing Center for Nighttime Depth Perception**|Zhiqiang Yan et.al.|[2306.14538v4](http://arxiv.org/abs/2306.14538v4)|8 pages|None|None|\n", "2306.13240": "|**2023-06-22**|**Continuous Online Extrinsic Calibration of Fisheye Camera and LiDAR**|Jack Borer et.al.|[2306.13240v1](http://arxiv.org/abs/2306.13240v1)|4 pages|None|None|\n", "2306.11822": "|**2023-06-20**|**Self-supervised Multi-task Learning Framework for Safety and Health-Oriented Connected Driving Environment Perception using Onboard Camera**|Shaocheng Jia et.al.|[2306.11822v1](http://arxiv.org/abs/2306.11822v1)|None|None|None|\n", "2306.11598": "|**2023-06-20**|**BEVScope: Enhancing Self-Supervised Depth Estimation Leveraging Bird's-Eye-View in Dynamic Scenarios**|Yucheng Mao et.al.|[2306.11598v1](http://arxiv.org/abs/2306.11598v1)|None|None|None|\n", "2306.11334": "|**2023-06-20**|**Depth and DOF Cues Make A Better Defocus Blur Detector**|Yuxin Jin et.al.|[2306.11334v1](http://arxiv.org/abs/2306.11334v1)|Code: https://github.com/yuxinjin-whu/D-DFFNet|None|**[link](https://github.com/yuxinjin-whu/d-dffnet)**|\n", "2306.10988": "|**2023-06-19**|**Tame a Wild Camera: In-the-Wild Monocular Camera Calibration**|Shengjie Zhu et.al.|[2306.10988v2](http://arxiv.org/abs/2306.10988v2)|None|NeurIPS 2023|**[link](https://github.com/shngjz/wildcamera)**|\n", "2306.10921": "|**2023-06-19**|**Understanding Depth Map Progressively: Adaptive Distance Interval Separation for Monocular 3d Object Detection**|Xianhui Cheng et.al.|[2306.10921v1](http://arxiv.org/abs/2306.10921v1)|None|None|None|\n", "2306.10003": "|**2023-06-16**|**C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction**|Luoyuan Xu et.al.|[2306.10003v2](http://arxiv.org/abs/2306.10003v2)|Accepted by ICCV2023|None|None|\n", "2306.08528": "|**2023-06-14**|**Predict to Detect: Prediction-guided 3D Object Detection using Sequential Images**|Sanmin Kim et.al.|[2306.08528v3](http://arxiv.org/abs/2306.08528v3)|ICCV 2023, Code: https://github.com/sanmin0312/P2D|None|**[link](https://github.com/sanmin0312/P2D)**|\n", "2306.05682": "|**2023-06-09**|**Lightweight Monocular Depth Estimation via Token-Sharing Transformer**|Dong-Jae Lee et.al.|[2306.05682v1](http://arxiv.org/abs/2306.05682v1)|ICRA 2023|None|None|\n", "2306.05416": "|**2023-06-08**|**Tracking Objects with 3D Representation from Videos**|Jiawei He et.al.|[2306.05416v1](http://arxiv.org/abs/2306.05416v1)|Technical report|None|None|\n", "2306.05238": "|**2023-06-08**|**SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth**|Zelin Liu et.al.|[2306.05238v2](http://arxiv.org/abs/2306.05238v2)|12 pages, 8 figures|None|**[link](https://github.com/hustvl/sparsetrack)**|\n", "2306.05061": "|**2023-06-08**|**A Dynamic Feature Interaction Framework for Multi-task Visual Perception**|Yuling Xi et.al.|[2306.05061v1](http://arxiv.org/abs/2306.05061v1)|Accepted by International Journal of Computer Vision. arXiv admin   note: text overlap with arXiv:2011.09796|None|None|\n", "2306.02878": "|**2023-06-05**|**Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on Dataset Mixtures with Uncalibrated Stereo Data**|Nikolay Patakin et.al.|[2306.02878v1](http://arxiv.org/abs/2306.02878v1)|None|CVPR 2022|None|\n", "2306.01667": "|**2023-06-02**|**Towards In-context Scene Understanding**|Ivana Bala\u017eevi\u0107 et.al.|[2306.01667v2](http://arxiv.org/abs/2306.01667v2)|None|None|None|\n"}}